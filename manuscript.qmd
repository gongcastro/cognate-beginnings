---
title: "The role of cross-linguistic lexical similarity on bilingual word acquisition"
editor: source
author:
    - name: Gonzalo Garcia-Castro
      corresponding: true
      affiliations:
        - name: Center for Brain and Cognition, Universitat Pompeu Fabra
    - name: Daniela S. Ávila-Varela
      affiliations:
        - name: Center for Brain and Cognition, Universitat Pompeu Fabra
    - name: Ignacio Castillejo
      affiliations:
        - name: Departamento de Psicología, Universidad Autónoma de Madrid
    - name: Núria Sebastian-Galles
      affiliations:
        - name: Center for Brain and Cognition, Universitat Pompeu Fabra

pagetitle: Cross-linguistic similarity and  word acquisition
abstract: |
    Bilinguals face the challenging task of learning words from languages with overlapping phonologies. Floccia et al. (2018) reported larger vocabulary sizes for 24-month-old bilinguals that were learning languages that shared a greater amount of cognates (e.g., English-Dutch). The mechanisms underlying this effect remain unknown. We explore two compatible scenarios. First, we test whether cognates are learnt earlier than non-cognates. This would account for the difference in vocabulary size associated to the amount of shared cognates across languages. Second, we explore the possibility that the word-forms of one language interact with those form the other language, scaffolding the acquisition of their translation equivalents when their phonologies overlap. This mechanism, in line with the parallel activation account of bilingual speech perception, would provide a plausible explanation to why cognates are acquired ealier by bilinguals. We developed an online tool to collect parental reports of receptive and productive vocabularies from children learning Catalan and/or Spanish, and present data on receptive and productive vocabulary of bilingual toddlers aged 10 to 36 months.
thanks: |
    This research was supported by grants from the Spanish Ministerio de Ciencia, Innovación y Universidades (PGC2018-101831-B-I00 and PRE2019-088165), and the Catalan Government [ICREA (Catalan Institution for Research and Advanced Studies) Academia 2019 award]. Gonzalo Garcia-Castro was supported by a fellowship of the Spanish Ministerio de Ciencia, Innovación y Universidades (FPI 2019). The authors declare no conflicts of interest with regard to the funding source of this study. We are grateful to Chiara Santolin, Alicia Franco-Martínez, Cristina Rodríguez-Prada, and Ege E. Özer for their help-ful feedback. We thank Xavier Mayoral, Silvia Blanch, and Cristina Cuadrado for their technical support. We also thank Cristina Dominguez and Katia Pistrin for their efforts in recruiting infants. We would like to thank the clinics Quirón and Sagrada Familia that allowed us to recruit participants in their premises. We also thank all families and infants who participated in the experiments. Data collection was half-way when the COVID-19 pandemic started. We would like to pay special tribute to the families that collaborated with us under these difficult circumstances.
keywords: lexical acquisition, vocabulary, bilingualism
toc: false
number-sections: true
fig-dpi: 1000
csl: apa.csl
bibliography: manuscript/references.bib
google-scholar: true
format:
  pdf:
    pdf-engine: xelatex
    geometry:
      - top=30mm
      - left=20mm
      - heightrounded
    keep-tex: true
    linestretch: 1.25
---

```{r}
#| label: setup
#| include: false
knitr::opts_chunk$set(
    echo = FALSE,
    fig.align = "center",
    message = FALSE,
    warning = FALSE,
    cache.extra = knitr::rand_seed,
    out.width = "100%",
    dpi = 800,
    results = "asis"
)
```

```{r}
#| label: packages
#| echo: false
#| message: false
#| warning: false
#| include: false
# load packages
library(brms) 
library(conflicted)
library(dplyr) 
library(forcats)
library(ggplot2) 
library(ggsci)
library(gt) 
library(here) 
library(janitor)
library(knitr)
library(lubridate)
library(multilex)
library(patchwork) 
library(papaja) 
library(purrr)
library(scales) 
library(stringr)
library(tidybayes) 
library(tidyr) 
library(tibble)

# load and process objects
tar_load(participants)
tar_load(items)
tar_load(multilex_data)
tar_load(model_log_liks)
tar_load(model_loos)
tar_load(model_fit_1)
tar_load(rope_coefs)
tar_load(rope_interval)
tar_load(df)
tar_load(posterior_description)

participants <- participants %>% 
    left_join(select(multilex_data$logs, id, time, edu_parent))
items <- items %>% 
    left_join(select(pool, item, language, category, class))
# set global options
options(
    knitr.kable.NA = "-",
    knitr.duplicate.label = "allow",
    gt.html_tag_check = FALSE,
    ggplot2.discrete.fill = ggsci::pal_d3()(4),
    ggplot2.discrete.colour = ggsci::pal_d3()(4),
    ggplot2.continuous.fill = ggplot2::scale_color_gradient,
    ggplot2.continuous.colour = ggplot2::scale_color_gradient
)

# set custom ggplot2 theme
theme_set(theme_custom())

# resolve namespace conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
```

# Introduction {#introduction}

The foundations of word learning are in place early in age: before the end of their first year of life infants start directing their gaze to some objects when hearing their labels, according to both experimental data [@jusczyk1995infants; @tincoff1999some; @bergelson2012months; @bergelson2015early] and parental reports [e.g., @fenson2007macarthur]. During the last half of their second year, they acquire new words at an increasingly fast rate [@goldfield1990early; @fenson1994variability; @mayor2011statistical; @bloom2002children; @bergelson2020comprehension]. These early stages of lexical acquisition are characterised by substantial variation across children, reflected, for instance, on the variation on the number of words they know [i.e. vocabulary size, @fenson1994variability; @frank2021variability] or on the proportion of those words that fall into the category of nouns, as opposed to verbs, adjectives, or function words [e.g., @nelson1973structure, bates1994developmental].

Despite this variability, children's trajectories of vocabulary growth seem quite stable across languages. @tardif2008baby collected data about the first ten words acquired by 10 to 16 month-old infants living in the United States, Hong Kong, and Beijing. Since birth, these infants had been learning English, Cantonese and Mandarin, respectively. The authors found a common pattern across the three groups: their first ten words referred to roughly the same concepts, namely relatives/caretakers (*daddy*, *mommy*), social routines (*bye*, *uh-oh*) or animals (*woof-woof*). These results were later extended by @frank2021variability to a wider diversity languages, also reporting that such cross-language commonalities are stronger at earlier stages of lexical acquisition, compared to later stages. Most of the literature on early word acquisition, however, has been conducted on monolingual children, and neglects the problem of how bilinguals--who represent a substantial proportion of the population in most societies--acquire words at early ages.

There is evidence that bilinguals know, on average, less words in each of their languages than monolinguals, but also that both groups know a similar amount of words when the two languages are aggregated. For example, @hoff2012dual found that English-Spanish bilingual toddlers in South Florida knew less words in English than monolinguals, who only learnt English. Both groups knew a similar total amount of words when both English and Spanish vocabularies were counted together, pointing to the importance of collecting data on both languages when assessing bilinguals' communicative development. Other studies have provided converging evidence that bilinguals know a similar--or even larger--number of words than monolinguals, only when the languages are aggregated [@oller2002language; @pearson1994patterns; @pearson1993lexical; @patterson2004comparing; @patterson2004bilingual; @smithson2014bilingualism; @petitto2001bilingual; @gonzalez2020bilingual]. While these studies have mostly relied on samples of bilingual children learning two relatively distant languages, as it is the case of English and Spanish, it is unclear whether children learning typologically more similar languages also know less words in each of their languages than monolinguals. What role could linguistic distance play during early vocabulary growth?

For a given set of concepts, bilingual children may be exposed to two distinct sets of word-forms--one in each language. Depending on the linguistic distance between both languages, the two sets of words may overlap in varying degrees. Particularly, when both languages are typologically close, like Spanish and Catalan (both Roman languages), they are more likely to share a large amount of cognates (i.e., form-similar translation equivalents) than two linguistically distant languages, like Spanish and English (one Roman, the other Germanic). For instance, in the presence of a door, a Spanish-Italian (or a Spanish-Catalan) bilingual might hear *puerta* and *porta* (cognates), whereas a Spanish-English bilingual might hear *puerta* and *door* (non-cognates). It could be the case that mapping two phonologically similar labels (cognates like *puerta*-*porta*) onto the same referent is easier than doing the same with two phonologically dissimilar labels (non-cognates, like *puerta* and *door*). If cognates are easier to acquire than non-cognates, bilinguals learning a pair of languages that share a high proportion of cognates should benefit more often from this facilitation effect than those learning a pair of languages with a lower proportion of cognates, and should therefore show larger vocabulary sizes.

@floccia2018introduction provided evidence in line with this claim. The authors collected vocabulary data on word comprehension and production from 372 24-month-old bilingual toddlers living in the United Kingdom who were learning English and an additional language. The additional language was one a pool of 13 typologically diverse languages: Bengali, Cantonese Chinese, Dutch, French, German, Greek, Hindi/Urdu, Italian, Mandarin Chinese, Polish, Portuguese, Spanish and Welsh. The authors calculated the average phonological similarity between the words in each of these additional languages and their translation equivalents in English. Phonological similarity was measured by computing the Levenshtein distance between each cross-language pair of phonological transcriptions. The Levenshtein distance is a metric that computes the edit distance between two strings by counting the smallest number of insertions, deletions and substitutions one of the strings has to go through to become identical to the other [@levenshtein1966binary]. The resulting scores were then divided by the length of the longest string to bound the similarity scores between 0 and 1, and then entered this variable as a predictor as they modelled participants' vocabulary sizes. Among other findings, the authors reported an increase in productive vocabulary size in the additional language associated with an increase in the average phonological similarity between the translation equivalents of each language pair. For example, English-Dutch bilinguals (22.14% phonological similarity), were able to produce more Dutch words than English-Mandarin bilinguals (1.97% phonological similarity) were able to produce in Mandarin.

Floccia et al. pointed to *parallel activation* as the main mechanism underpinning their results. The parallel activation hypothesis suggests that bilinguals activate both languages simultaneously during speech production or comprehension, and that this phenomenon is the result of the activation of lexical representations in both languages, even when only one is in use during production [@costa2000cognate; @hoshino2008cognate] or comprehension [@spivey1999cross; @thierry2007brain]. One of the clearest examples of parallel activation was provided by @costa2000cognate. In this study, Catalan-Spanish monolingual and bilingual adults were asked to name pictures of common objects in Spanish. In half of the trials, the object labels were cognates in Spanish and Catalan (*árbol*-*arbre*, translations of *tree*), whereas in the other half of the trials labels were non-cognates (*mesa*-*taula*, translations of *table*). Bilinguals named cognate pictures faster than non-cognate pictures, even after adjusting for the lexical frequency of the items. Importantly, Spanish monolinguals--unfamiliar with the Catalan translations of the Spanish words they uttered--did not show this effect. These results suggest that bilinguals' Catalan phonology was activated during the production of Spanish words, facilitating the naming of cognate pictures. Several subsequent studies have also provided similar evidence in comprehension in children [e.g., @von2012language; @poulin2013lexical]. Parallel activation is therefore a plausible mechanism to account for Floccia et al.'s results: cognates increase the amount of activation in both languages, facilitating word acquisition, and ultimately leading to children learning language pairs with a larger proportion of cognates are predicted to show larger vocabulary sizes. A missing piece in this account is how increase parallel activation might facilitate the acquisition new words.

In this study, we hypothesise that cognates are acquired earlier in age than non-cognates, which might explain why children learning languages that share many cognates show larger vocabulary sizes. Evidence supporting this claim is scarce. @bosch2014first used vocabulary parental reports (152 lexical items) from 48 Catalan-Spanish bilinguals aged 18 months, and found that cognates represented a larger proportion of participant's vocabulary than non-cognates. @schelletter2002effect reported a longitudinal single case of one English-German bilingual who produced cognates earlier than non-cognates, on average. The low sample size in these two studies makes it challenging to draw strong conclusions about the effect of cognateness on vocabulary growth. On the other hand, Floccia et al.'s estimates are statically more reliable given their (much larger) sample size, but their study was not aimed at testing the effect of cognateness on age of acquisition directly. In their discussion the authors state the following (pp. 70):

> "This  finding  also  provides  support  to  the  proposal  that  the  cognate advantage is due to cognates being acquired before non-cognates in early childhood (Costa et al., 2016), leading to an ease of processing later in life."

We identify two main reasons why an earlier age of acquisition for cognates than for non-cognates is an unwarranted conclusion from Floccia et al.'s results. First, the response variable used was the proportion of words each participant understood and/or produced (i.e., vocabulary size), from the list of lexical items in the vocabulary checklists. By aggregating the responses from all items into a single datum per child, information about the acquisition status of cognates vs. non-cognates was lost. Second, all participants were aged ~24 months, meaning that even if the unaggregated responses to individual items were included as response variable, the possible effect of cognateness could only be interpreted as an increase or decrease in the likelihood of participants at such age to have acquired each item, and not as an increase or decrease in the age of acquisition of such item.

More recently, @mitchell2022cognates addressed this issue overcoming some of these pitfalls. Using a larger, longitudinal sample of 47 16-to-30 month-old French-English bilinguals living in Canada, the authors collected data on expressive vocabulary data in both languages. They created two lists of translation equivalents: one made of 131 cognates, and one made of 406 non-cognates. The proportion of translation equivalents that children were reportedly able to produce was higher in the cognate lists than in the non-cognate list across ages, even when both lists were matched by semantic category (furniture, animals, food were similarity represented in both lists) and age of acquisition norms (an index of word difficulty). These findings shed some light on the ongoing exploration of why (if at all) bilinguals' vocabulary size grows faster when both languages are phonologically more similar: word-forms sharing more phonemes with their translation equivalents (i.e., cognates) seem to be acquired faster.

As @mitchell2022cognates note in their discussion, two competing hypotheses remain untested. The facilitative effect of cognateness can be explained by, at least, two alternative, arguably incompatible, mechanisms. On the one hand, cognateness might operate as a facilitator of the acquisition of both forms of a translation pair, with every exposure to either form activating the other, and therefore strengthening the association between both and their referent. If this is the case, then cognateness should increase the probability of acquisition of the forms in both languages equally. 

Another possibility is that cognateness plays a role in the acquisition of a translation pair only when at least one of the word-forms has been acquired. This account departs from the premise that, if the child is not previously familiar with one of the word forms, the acquisition of its translation in the other language cannot be facilitated by cognateness. This implies that, if cognateness facilitates the acquisition of a word form, it can only do so after the child has acquired one of the word forms of the translation pair. Given that children are more likely to acquire words from languages to which they are exposed more often [@david2008individual; @cattani2014much; @thordardottir2006bilingual], the acquisition of words in the language of lower exposure should, on average, be more susceptible to the effect of cognateness.

In line with this second hypothesis, the vocabulary size associated with linguistic similarity that Floccia et al. reported was larger in the additional language vocabulary than in English vocabulary. Most participants in their sample were English-dominant, meaning that their relative amount of exposure to English was larger than in the additional language. Therefore, participants may have, on average, learnt the English word-form of translation equivalents earlier than the word-form in the additional language.  If this is the case, then the acquisition of English words by English-dominant participants would rarely benefit from their cognate status (the other word-form is not available yet), while the acquisition of words in the additional language would benefit from their phonological similarity with the (available) English form. 

In this study, we investigated the role of cognateness on the acquisition of translation equivalent, and whether such effect is conditional to the amount of time the child is exposed to the corresponding language of each member of the translation pair. Using an online vocabulary checklist--designed specifically for this study--we collected data from a sample of children aged `r min(floor(participants$age))` to `r max(floor(participants$age))` months learning Catalan and/or Spanish, with varying degrees of exposure to each language. We then adopted an Item Response Theory (*IRT*) approach to model the probability of participants being reported by their parents to understand or understand *and* say each word in the checklist, conditional to its cognate status in Catalan and Spanish and participants' degree of exposure to the corresponding language, while adjusting for other indices of word difficulty--lexical frequency and length (phonemes)-- and participant skill--age [see @kachergis2022toward for a similar approach].

# Methods {#methods}

Data and materials are available at OSF [https://osf.io/hy984/](https://osf.io/hy984/), and code is available at GitHub [https://github.com/gongcastro/trajectories](https://github.com/gongcastro/trajectories).

## Participants {#participants}

```{r}
#| label: participants
#| echo: false
#| message: false
#| warning: false
#| include: false
# load packages
n_participants <- length(unique(participants$id))
dates <- as_date(range(participants$time_stamp, na.rm = TRUE))
```

We collected data from `r printnum(n_participants)` children from the Metropolitan Area of Barcelona between `r format(dates[1], "%dth %B, %Y")` and `r format(dates[2], "%dth %B, %Y")`. All families gave informed consent before participating and this study was approved by the Comitè d'Ètica de la Investigació amb Medicaments (CEIm) from Hospital del Mar (Barcelona, Spain), code XXXXXXXXX. Families from the participant database of the Laboratori de Recerca en Infància of the Universitat Pompeu Fabra were contacted by e-mail or phone if their child were aged between `r floor(min(participants$age))` and `r floor(max(participants$age))` months, and had not been reported to be exposed more than 10% of the time to a language other than Spanish or Catalan. Upon consent, families were sent a link to the questionnaire via e-mail, which they filled from a computer, laptop, or mobile device in a browser within the two week following the invitation to participate. @tbl-participants-lp summarises the distribution of participants across ages and degrees of exposure (DoE) to Catalan.

```{r}
#| label: tbl-participants-lp
#| echo: false
#| message: false
#| warning: false
#| tbl-cap: "Participant sample size by age and degree of exposure to Catalan."
#| tbl-subcap: "Information about DoE was provided by families before filling the questionnaire. A 100% indicated that the participant was exclusively exposed to Catalan, and never to Spanish. A 0% indicates that the participant was not exposed to Catalan ever, and rather most of the time to Spanish. A 50% indicates that the participant was exposed to Catalan and Spanish approximately half of the time each. The 100%, 0%, and 50% would be traditionaly classified as Catalan monolingual, Spanish monolingual, and Catalan-Spanish bilingual, respectively. For illustration purposes this table, DoEs were binned into 25%-wide bins, and ages (in months) binned into 4 month-wide bins. Hyphens indicate that no participants from that specific combination of age and DoE filled the questionnaire."
participants %>%
    mutate_at(
        vars(starts_with("doe_")),
        ~floor(.*10)/10
    ) %>%
    mutate(
        age = cut(
            floor(age),
            c(10, 14, 18, 22, 26, 30, 34, 36),
            include.lowest = TRUE
        ),
        doe_catalan = cut(
            doe_catalan,
            c(0, 0.25, 0.5, 0.75, 1),
            labels = c("0-25%", "25-50%", "50-75%", "75-100%"),
            include.lowest = TRUE
        ) %>% 
            as.character()
    ) %>%
    count(age, doe_catalan) %>%
    arrange(desc(doe_catalan)) %>%
    pivot_wider(names_from = age, values_from = n) %>%
    gt() %>%
    summary_rows(
        columns = 2:8,
        fns = list("Total" = ~sum(., na.rm = TRUE)),
        formatter = fmt_integer
    ) %>%
    sub_missing(everything(), everything(), missing_text = "--") %>%
    cols_label(doe_catalan = "DoE Catalan") %>%
    tab_spanner("Age (months)", 2:8) %>%
    tab_footnote(
        "This proportion is complementary to the degree of exposure to Spanish, with the exception of those participants who were also exposed to a third language up to 10% of the time",
        cells_column_labels(columns = doe_catalan)
    ) %>%
    tab_style(
        cell_text(align = "left"),
        list(
            cells_body(doe_catalan),
            cells_column_labels(doe_catalan)
        )
    )
```

We used the highest educational attainment of parents or caretakers as a proxy of participants' socio-economic status (SES), which families self-reported in the questionnaire by filling two items asking for the educational attainment of each parent or caretaker, with the following available options: *No education*, *Primary*, *Secondary*, *Complementary*, *Vocational*, and *University*, in line with the current educational system in Spain. Most families reported university studies (`r table(participants$edu_parent)["University"]`, `r table(participants$edu_parent)["University"]/length(unique(participants$id))`), followed by families were the highest educational attainment were vocational studies (`r table(participants$edu_parent)["Vocational"]`, `r percent(table(participants$edu_parent)["Vocational"]/length(unique(participants$id)))`), complementary studies (`r table(participants$edu_parent)["Complementary"]`,  `r percent(table(participants$edu_parent)["Complementary"]/length(unique(participants$id)))`), secondary education (`r table(participants$edu_parent)["Secondary"]`, `r percent(table(participants$edu_parent)["Secondary"]/length(unique(participants$id)))`, `r percent(table(participants$edu_parent)["Primary"]/length(unique(participants$id)))`), no formal education (`r table(participants$edu_parent)["No education"]`, `r percent(table(participants$edu_parent)["No education"]/length(unique(participants$id)))` and primary education (`r table(participants$edu_parent)["Primary"]`, <1%).

## Questionnaire {#questionnaire}

```{r}
#| label: items
#| echo: false
#| message: false
#| warning: false
#| include: false
n_categories <- nrow(distinct(multilex_data$pool, category))
n_te <- length(unique(multilex_data$pool$te))
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>%
    pull(n) %>% 
    set_names(c("catalan", "spanish"))
n_missing_freq <- multilex::pool %>% 
    filter(
        include,
        class %in% c("Noun", "Verb", "Adjective")
    ) %>% pull(frequency_zipf) %>% 
    is.na() %>%
    table() %>% 
    {.[2] / .[1]}
```

The questionnaire was implemented on-line using the formR platform [@arslan2020formr], and was structured in three blocks: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000infant] and consisted in two lists of words: one in Catalan and one in Spanish. The Catalan inventory contained `r n_item_language["catalan"]` items and the Spanish inventory contained `r n_item_language["spanish"]`. Items in one language were translation equivalents of the items in the other language (e.g., whenever *gos* [dog] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. In case two translation equivalents were possible for a given word, both were included as separate items (e.g., Catalan *acabar* [*to finish*] and Spanish *acabar* and *terminar*), or merged them into a single item (e.g., Spanish *mono* [*monkey*] and Catalan *mono/mico*). We included items from a diverse sample of `r n_categories` semantic/functional categories.

For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand *and* say it, or did not understand or say it (checked out by default). Some families filled a long version of the vocabulary checklists (`r format(n_te, big.mark = ",")` translation equivalents; `r format(n_item_language["catalan"], big.mark = ",")` items in Catalan, `r format(n_item_language["spanish"], big.mark = ",")` items in Spanish), while others filled a shorter version (~400 translation equivalents, ~400 items in Catalan, ~400 items in Spanish). These last families were randomly allocated into one of four different subsets of the complete list of items. These lists were designed so that each contained a representative sub-sample of the items from the complete list. Semantic/functional categories with less than 16 items--thus resulting in less than four items after dividing it in four lists--were not divided in the short version of the questionnaire: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. For the analyses in the present study, we considered responses to words corresponding to nouns, verbs, and adjectives [@fourtassi2020growth]. We excluded multi-word items (e.g., *barrita de cereales* [cereal bar]) and items that included more than one word-form (e.g., *mono / mico*).

We extracted four variables of interest for each word-form: (1) Word lexical frequency ($Frequency$): lexical frequency of the word in its corresponding language, expressed as Zipf scores [@van2014subtlex; @zipf1949human]. This variable ranges from 0 to 7, and follows and approximates a normal distribution, with most values in a corpus ranging from 3 to 5 points. Lexical frequencies were extracted from an adult subtitle-based database: SUBTLEX-CAT [@boada2020subtlex] for Catalan words and SUBTLEX-ESP [@cuetos2012subtlex] for Spanish words. Using child-based estimates of lexical frequency like CHILDES was not possible due to the low number of Catalan participants and tokens in the available corpora. Responses to words with missing lexical frequency score were excluded from analyses (`r percent(n_missing_freq, accuracy = 0.01)` of the total number of items). (2) Word length ($Phonemes$): number of phonemes in the phonological transcription of the word-form in International Phonological association format. (3) Phonological similarity ($Levenshtein$): normalised Levenshtein similarity between the word-form and its translation in the other language [@levenshtein1966binary]. This score is calculated by first calculating the Levenshtein distance between the two transcriptions (number of insertions, deletions or replacements needed for the shortest transcription to become identical to the longer transcription), then dividing the resulting value by the length of the longest transcription, and finally subtracting this value from 1. This results in a proportion that indicates how much the two phonological transcriptions of the translation equivalent are similar to each other, ranging from 0% (no similarity at all) to 100% (both transcriptions are identical) [see @floccia2018introduction; @fourtassi2020growth; @laing2022phonological for similar approaches]. (4) Participant age: number of months elapsed between participants' birth date and questionnaire completion. Finally, (5) participant degree of exposure to the words' language ($DoE$): percentage of exposure to the language the word belonged to. For example, for a participant with 90% exposure to Catalan, and 10% to Spanish, the DoE of the Catalan word *taula* would be 90%, and the DoE for the Spanish word *mesa* would be 10%. @tbl-item-summary shows a summary of the distribution of the word-level predictors across languages in and questionnaire versions.

```{r}
#| label: tbl-item-summary
#| echo: false
#| message: false
#| warning: false
#| tbl-cap: "Lexical properties of the word-forms and translationpairs included in the vocabulary checklist and our analyses. We report the number of items, mean (*M*), standard deviation (*SD*), and range of the lexical frequency (epxressed in Zipf scores), length (number of phonemes) of the word forms, and the phonological similarity (normalised Levenshtein similarity) with their translation equivalent. Statistics are reported separately for Catalan and Spanish, and for the different vocabulary checklists that participants were allocated to (A, B, C, D)."
items <- left_join(items, select(multilex_data$pool, te, item, language, class, category))

items %>%
    unnest(list) %>% 
    group_by(language, list) %>% 
    summarise_at(
        vars(freq, n_phon, lv), 
        lst(n = ~sum(!is.na(.)), mean, sd, min, max)
    ) %>% 
    select(-c(n_phon_n, lv_n)) %>% 
    rename(n = freq_n) %>% 
    gt(groupname_col = "language") %>%
    fmt_number(matches("freq_|n_phon_mean|n_phon_sd")) %>% 
    fmt_percent(matches("lv_")) %>% 
    tab_spanner("Frequency (Zipf)", columns = starts_with("freq_")) %>% 
    tab_spanner("# Phonemes", columns = starts_with("n_phon_")) %>% 
    tab_spanner("Phon. similarity (Levenshtein)", columns = starts_with("lv_")) %>% 
    cols_merge_range(col_begin = "freq_min", col_end = "freq_max") %>% 
    cols_merge_range(col_begin = "n_phon_min", col_end = "n_phon_max") %>% 
    cols_merge_range(col_begin = "lv_min", col_end = "lv_max") %>% 
    cols_label(
        list = "",
        n = md("*N*"),
        freq_mean = md("Mean"),
        freq_sd = md("*SD*"),
        freq_min = md("Range"),
        n_phon_mean = md("Mean"),
        n_phon_sd = md("*SD*"),
        n_phon_min = md("Range"),
        lv_mean = md("Mean"),
        lv_sd = md("*SD*"),
        lv_min = md("Range")
    ) %>% 
    tab_style(
        cell_text(style = "italic"),
        cells_column_labels(everything())
    ) %>% 
    tab_style(
        cell_text(weight = "bold"),
        cells_column_spanners(everything())
    )
```


## Data analysis {#analysis}

```{r}
#| label: sample-sizes
#| echo: false
#| message: false
#| warning: false
#| include: false
n_obs <- nrow(df)
sum_obs <- df %>%
    mutate(te = factor(te)) %>% 
    count(te) %>% 
    summarise(across(n, lst(median, min, max), .names = "{.fn}"))
n_participants <- df %>%
    distinct(id, age) %>% 
    count(id) %>% 
    pull(n) %>% 
    table()

n_items <- ifelse(
    grepl("cat_", distinct(df, item)$item),
    "Catalan",
    "Spanish"
) %>% 
    table()

n_te <- length(unique(df$te))
```


We gathered `r format(n_obs, big.mark = ",")` observations, with each observation corresponding to a single response of one participant to a given item in the questionnaire). These observations correspond to `r sum(n_participants)` distinct participants (of which `r n_participants[1]` participated once, `r n_participants[2]` twice,  `r n_participants[3]` three times, and  `r n_participants[4]` four times), responding to `r format(sum(n_items), big.mark = ",")` distinct items (`r n_items["Catalan"]` in Catalan, `r n_items["Spanish"]` in Spanish, `r n_te` translation equivalents). Translation equivalents (TEs) received a median of `r printnum(sum_obs$median, digits = 0)` responses (*Min* = `r printnum(sum_obs$min, digits = 0)`, *Max* = `r printnum(sum_obs$max, digits = 0)`), both languages summed together.

We modelled the probability of answering each response category (*No* < *Understands* < *Understands and Says*) using a Bayesian, mixed-effects ordinal regression model. This allowed us to simultaneously estimate the impact of item- and participant-level predictors on the probability of word comprehension and production. We included $Age$, $Frequency$, $Phonemes$, $DoE$, and $Levenshtein$ as fixed effects. We also included the $Age \times DoE \times Levenshtein$ three-way interaction, and its corresponding two-way interactions. We added participants and items as crossed random effects including all intercepts and slopes when appropriate [@barr2013random].

This model structure, including word- and participant-level properties to estimate vocabulary acquisition trajectories was discussed by @kachergis2022toward in the context of explanatory item response models. Our model differs from their proposal in that  1) while they modelled global trajectories exclusively, we modelled individual trajectories as well, 2) our outcome variable is ordinal in contrast to the binary outcome used in their study, 3) we propose a Bayesian approach. Our motivation for a Bayesian approach towards statistical inference is that (1) it allows us to incorporate previous domain knowledge to improve estimation accuracy, and (2) to quantify the uncertainty associated with the estimated parameters in our model [@mcelreath2018statistical].

The Bayesian approach implies using Bayes’ rule to assign a probability to possible parameter values (i.e., posterior distribution), based on previous knowledge about such probability distribution (prior distribution) and our data (likelihood). We used Markov chain Monte Carlo (MCMC) to approximate the posterior distribution via sampling. We run 2 sampling chains with 4,000 iterations each, including 2,000 warm-up iterations per chain. All $\hat{R}$ values were smaller than 1.1, indicating that the chains converged successfully in all cases [@gelman1992inference].

We compared a base model–-only including the intercept, $Age$, $Frequency$, $Phonemes$, and $DoE$ as fixed effects, and their corresponding random effects-–to increasingly more complex models, introducing predictors in the following order: $Age \times DoE$, $Levenshtein$, $DoE \times Levenshtein$, and finally $Age \times Levenshtein$ and $Age \times DoE \times Levenshtein$. We compared the predictive performance of the models using Bayesian leave-one-out cross-validation (LOO) [@vehtari2017practical]: we computed the average likelihood of each observation after estimating the model's parameters leaving that same observation out of the data set. Due to computational constraints, we performed LOO based on a random sub-sample of `r dim(model_log_liks$model_fit_1)[1]` samples (out of `r format(dim(model_fit_1$fit)[1], big.mark = ",")`) of the posterior distribution of the fixed effects of the model. and selected the model with the smallest expected log posterior density (ELPD)^[Due to the high computational cost associated with our large dataset, we used a sub-sampling approach for performing Bayesian LOO with `r format(dim(model_log_liks$model_fit_1)[1], big.mark = ",")` posterior samples [@magnusson2019bayesian]].

Finally, we explored the posterior distribution of each parameter in the selected model. Following @kruschke2018bayesian, We specified a region of practical equivalence (*ROPE*) around the values of each regression coefficient that we considered equivalent to zero [@kruschke2018bayesian]. We defined our *ROPE* from -`r round(median(abs(rope_coefs$estimate)), 3)` to +`r round(median(abs(rope_coefs$estimate)), 3)` [see @#appendix-rope for justification of the *ROPE*]. In the results section, we report the mean of each coefficient's marginal posterior distribution along with their 95% highest density intervals (*HDI*). This interval indicates the narrowest range of values that contain 95% of the samples of the posterior distribution, and therefore the true value of the coefficient with 95% confidence, given our data. We also report the proportion of the posterior samples of that coefficient that fell within the *ROPE*. A 90% overlap between the 95% *HDI* of the coefficients' posterior distribution and the *ROPE* indicates that, given the data, there is a 90% probability that the true value of the coefficient falls within the *ROPE*, and is therefore equivalent to zero, that is, negligible.

Data processing and visualisation was done in R [@R-base] using the `tidyverse` family of packages [@R-tidyverse], Bayesian modelling was done using the `brms` [@burkner2017brms; @carpenter2017stan], `loo` [@loo], and `tidybayes` [@tidybayes] R packages.

# Results {#results}

## Model comparison and selection {#comparison}

@tbl-results-loos shows the outputs of the *LOO-CV*. The extended model (`model_fit_1`), which included the three-way interaction between $Age$, $DoE$, and $Levenshtein$ showed the best predictive performance, with a difference in *ELPD* compared to the other models several times larger than the standard error of such difference. This indicates that, given the data, the predictions of the extended model are confidently more accurate than those of the other models.

```{r}
#| label: tbl-results-loos
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| tbl-cap: "Bayesian leave-one-out cross validation (LOO-CV)"
model_loos %>% 
    loo_compare() %>% 
    as.data.frame() %>%   
    rownames_to_column("model") %>% 
    relocate(
        model, 
        matches("elpd_loo"),
        matches("p_loo"), 
        matches("looic"), 
        matches("diff")
    ) %>%
    gt() %>% 
    tab_header(
        title = "",
        subtitle = md("The predictive accuracy of the models was compared using leave-one-out cross-validation. The likelihood of each data point given a model fitted without including that same observation was estimated. The resulting likelihoods of each model were summarised as its expected log-predicted density (*ELPD*), which penalises the complexity of each model. *ELPD* values closer to zero indicate better predictive acuracy. We report the *ELPD*, effective number of parameters (*p*), and information criterion (*IC*) of each model along their associated standard errors (*SE*). The last column indicates the difference in *ELPD* between each model and the model with the best predictive accuracy (`model_fit_1`)")
    ) %>% 
    tab_spanner(md("LOO<sub>ELPD</sub>"), matches("elpd_loo")) %>% 
    tab_spanner(md("LOO<sub>p</sub>"), matches("p_loo")) %>% 
    tab_spanner(md("LOO<sub>IC</sub>"), matches("looic")) %>% 
    tab_spanner(md("LOO<sub>diff</sub>"), matches("diff")) %>% 
    fmt_number(2:9) %>% 
    cols_label(
        model = "Model",
        # elpd
        elpd_loo = md("*ELPD*"),
        se_elpd_loo = md("*SE*"),
        # p
        p_loo = md("*p*"),
        se_p_loo = md("*SE*"),
        # looic
        looic = md("*LOO-IC*"),
        se_looic = md("*SE*"),
        # diff
        elpd_diff = md("*diff*"),
        se_diff = md("*SE*")
    ) %>% 
    tab_source_note(md("Pareto-*k* estimates of all models were acceptable (*k* < 0.5)")) %>% 
    tab_style(
        cell_text(weight = "bold"),
        cells_column_spanners()
    ) %>% 
    tab_style(
        cell_text(align = "left"),
        cells_title(groups = "subtitle")
    )
```

## Regression coefficients {#coefficients}

```{r}
#| label: tbl-results-fixed
#| tbl-cap: "Summary of the estimated posterior distribution of fixed regression coefficients"
#| echo: false
#| message: false
#| warning: false
post_draws <- gather_draws(model_fit_1, `b_.*`, regex = TRUE)

# tidy predictor names
str_repl <- c(
    "b_Intercept[1]" = paste0("Intercept (Comprehension and Production at ",  round(mean(df$age, 2)), " months)"),
    "b_Intercept[2]" = paste0("Intercept (Comprehension at ", round(mean(df$age, 2)), " months)"),
    "b_age_std" = paste0("Age (+1 SD, ",  round(sd(df$age), 2), " months)"),
    "b_freq_std" = paste0("Frequency (+1 SD, ",  round(sd(df$freq), 2), " Zipf)"),
    "b_n_phon_std" = paste0("Phonemes (+1 SD, ",  round(sd(df$n_phon), 2), " phonemes)"),
    "b_doe_std" = paste0("DoE (+1 SD, ",  percent(sd(df$doe)), ")"),
    "b_lv_std" = paste0("Levenshtein (+1 SD, ",  percent(sd(df$lv)), ")"),
    "b_doe_std:lv_std" = "DoE \u00d7 Levenshtein",
    "b_age_std:doe_std" = "Age \u00d7 DoE",
    "b_age_std:lv_std" = "Age \u00d7 Levenshtein",
    "b_age_std:doe_std:lv_std" = "Age \u00d7 DoE \u00d7 Levenshtein"
)

post_draws_list <- split(posterior_description, posterior_description$parameter)

# summarise posterior draws
posterior_description %>% 
    mutate(
        parameter = factor(
            parameter,
            levels = names(str_repl),
            labels = str_repl
        ) %>% 
            as.character()
    ) %>%
    select(parameter, median, ci_high, ci_low, rope_percentage) %>%  
    gt() %>% 
    fmt_number(2:4) %>%
    fmt_percent(5) %>%
    cols_merge(c(ci_low, ci_high), pattern = "[{1}, {2}]") %>%
    cols_label(
        parameter = "Parameter",
        median = "Median",
        ci_low = md("95% *HDI*"),
        rope_percentage = md("*ROPE* prob.")
    ) %>%
    tab_style(
        cell_text(weight = "bold"),
        cells_column_labels(columns = 1:5)
    )
```

@tbl-results-fixed shows the summary of the posterior distribution of the fixed regression coefficients of the model. For interpretability, we supplement the summaries of each posterior regression coefficient with its transformation to the probability scale. The resulting values correspond to the maximum difference in probability of acquisition (*Comprehension* or *Comprehension and Production*) that corresponds to a one standard deviation change in each predictor^[The logit and probability scales related non-linearly. This means that one logit difference is not necessarily translated to a unique value in the probability scale. For example, the probability of acquisition of a given word might increase in 5% when age increases from 22 to 23 months, the probability of acquisition of the same word might only increase in 0.2% when age increases from 34 to 36 months. The linear growth of the probability of acquisition differs along the logistic curve, and therefore deciding the age point at which to report the estimates of the regression coefficients  in the probability scale is not trivial. We followed the suggestion by @gelman2020regression and report the maximum value of such coefficient, which corresponds to the linear growth (i.e. derivative) of the logistic curve at the age at which most participants were acquiring a given word. This value can be approximated by dividing the coefficient in the logit scale by four: $\hat{\beta_j}/4$, where $\hat{\beta_j}$ is the estimated mean of the posterior distribution of coefficient $j$.].

$Age$ was the predictor with the largest effect on the probability of acquisition ($\beta$ = `r printnum(post_draws_list[["b_age_std"]]$median, digits = 2)`, 95% *HDI* = [`r printnum(post_draws_list[["b_age_std"]]$ci_low, digits = 2)`, `r printnum(post_draws_list[["b_age_std"]]$ci_high, digits = 2)`]): at the steepest point of the acquisition trajectory of an average translation equivalent, the probability of acquisition increased `r percent(post_draws_list[["b_age_std"]]$median/(4*sd(df$age)), accuracy = 0.01)` every month. Lexical frequency ($Frequency$) had a small, positive, but inconclusive on the probability of acquisition substantially, ($\beta$ = `r percent(post_draws_list[["b_freq_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_freq_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_freq_std"]]$ci_high, accuracy = 0.01)`]): `r percent(post_draws_list[["b_freq_std"]]$rope_percentage, accuracy = 0.01)` of its posterior samples overlapped with the *ROPE.* The 95% *HDI* of the regression coefficient of the number of phonemes ($Phonemes$) did exclude the *ROPE*, although not by much: `r percent(post_draws_list[["b_n_phon_std"]]$rope_percentage, accuracy = 0.01)` of its posterior samples fell within the *ROPE*. This suggests that the number of phonemes in the word form had a small effect on the probability of acquisition ($\beta$ = `r percent(post_draws_list[["b_n_phon_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_n_phon_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_n_phon_std"]]$ci_high, accuracy = 0.01)`]). For every increase in phoneme length, the probability of acquisition decreased in `r percent(post_draws_list[["b_n_phon_std"]]$median/(4*sd(df$n_phon)), accuracy = 0.01)`. 

```{r}
#| label: fig-results-fixed
#| echo: false
#| message: false
#| warning: false
#| fig-width: 9
#| fig-heigh: 7
#| fig-cap: "Marginal posterior distribution of the regression coefficients of the fixed effects in the extended model. Distributions show the estimated likelihood density of each value in the parameter space (X-axis) of each coefficient (Y-axis). Intervals show the 95% highest density interval (*HDI*) of each distribution. This interval is the narrowest range of values that contains 95% of the distribution, and therefore is 95% likely to contain the true value, given the data. the mean and HDI limits are indicated below each distribution. Coefficients were transformed from the logit scale to the probability scale for interpretability. We used the divide-by-four rule to get the maximum change in probability of correct response associated with a unit increase in this variable, i.e. the derivative of the logistic function in its mid-point."
post_draws %>%
    mutate(
        .variable_name = factor(
            .variable, 
            levels = names(str_repl),
            labels = str_repl,
            ordered = TRUE
        )
    ) %>% 
    filter(!grepl("Intercept|sd", .variable)) %>%
    ggplot(aes(.value, fct_rev(.variable_name))) +
    annotate(
        geom = "rect",
        ymin = -Inf,
        ymax = Inf,
        xmin = rope_interval["lower"],
        xmax = rope_interval["upper"],
        colour = NA,
        alpha = 0.5,
        fill = "grey",
    ) +
    geom_vline(
        xintercept = 0,
        size = 1,
        colour = "grey"
    ) +
    stat_slab(
        aes(
            fill = stat(abs(x) < rope_interval["upper"]),
            colour = stat(abs(x) < rope_interval["upper"]),
        ),
        size = 0.25,
        # fill = pal_d3()(2)[2],
        position = position_nudge(y = 0.15)
    ) +
    geom_errorbar(
        data = post_draws %>% 
            filter(!grepl("Intercept|sd", .variable)) %>%
            median_hdi(
                .exclude = c(
                    ".chain", 
                    ".iteration",
                    ".draw",
                    ".row", 
                    ".variable_name"
                )
            ) %>% 
            mutate(
                .variable_name = factor(
                    .variable, 
                    levels = names(str_repl),
                    labels = str_repl,
                    ordered = TRUE
                )
            ),
        aes(xmin = .lower, xmax = .upper, x = .value),
        width = 0.15
    ) +
    geom_point(
        data = post_draws %>% 
            filter(!grepl("Intercept|sd", .variable)) %>%
            median_hdi(
                .exclude = c(
                    ".chain", 
                    ".iteration",
                    ".draw",
                    ".row", 
                    ".variable_name"
                )
            ) %>% 
            mutate(
                .variable_name = factor(
                    .variable, 
                    levels = names(str_repl),
                    labels = str_repl,
                    ordered = TRUE
                )
            ),
        size = 2
    ) +
    geom_text(
        data = post_draws %>% 
            filter(!grepl("Intercept|sd", .variable)) %>%
            mean_hdi(
                .exclude = c(".chain", ".iteration", ".draw", ".row", ".variable_name")
            ) %>% 
            mutate(
                .variable_name = factor(
                    .variable, 
                    levels = names(str_repl),
                    labels = str_repl,
                    ordered = TRUE
                )
            ),
        aes(
            label = paste0(
                printnum(.value, digits = 2),
                " [", printnum(.lower, digits = 2), ", ",
                printnum(.upper, digits = 2), "]"
            )
        ),
        position = position_nudge(y = -0.25),
        size = 3
    ) +
    
    labs(
        x = "Coefficient estimate (logit scale)",
        y = "Variable", 
        fill = "Overlaps with ROPE",
        colour = "Overlaps with ROPE"
    ) +
    scale_x_continuous(breaks = seq(-0.5, 2, 0.2)) +
    scale_fill_manual(
        values = c("dodgerblue", "#b3d9ff"),
        labels = c("No", "Yes")
    ) +
    scale_colour_manual(
        values = c("dodgerblue", "#b3d9ff"),
        labels = c("No", "Yes")
    ) +
    theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        axis.title.y = element_blank(),
        panel.grid.major.x = element_line(
            colour = "grey85",
            linetype = "dotted"
        ),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank()
    )

# annotate(
#     geom = "text",
#     label = "ROPE",
#     x = 0.3,
#     y = 10,
#     vjust = 1,
#     size = 5,
#     colour = pal_d3()(2)[2]
# ) +
# annotate(
#     geom = "curve",
#     arrow = arrow(length = unit(0.2, "cm")),
#     x = 0.3,
#     y = 9.5,
#     xend = 0.1,
#     yend = 9,
#     size = 1,
#     curvature = -0.25,
#     colour = pal_d3()(2)[2]
# ) +
```

The degree of exposure to the language ($DoE$) had a strong effect on the probability of acquisition ($\beta$ = `r percent(post_draws_list[["b_doe_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_doe_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_doe_std"]]$ci_high, accuracy = 0.01)`]). All of the posterior samples of his regression excluded the *ROPE*. The impact of this predictor on the probability of acquisition was positive: for every 10% increase in exposure to the language the word belongs to, the participant was `r percent(post_draws_list[["b_doe_std"]]$median/(10*sd(df$doe)), accuracy = 0.01)` more likely to acquire it. The effect of phonological similarity by itself (as indicated by the regression coefficient of the main effect of $Levenshtein$) was equivalent to zero ($\beta$ = `r percent(post_draws_list[["b_lv_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_lv_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_lv_std"]]$ci_high, accuracy = 0.01)`]), as `r percent(post_draws_list[["b_lv_std"]]$rope_percentage, accuracy = 0.01)` of the posterior samples of its regression coefficient fell into the *ROPE*. However, the 95% *HDI* of the regression coefficient of the $Doe \times Levenshtein$ interaction excluded the *ROPE* entirely ($\beta$ = `r percent(post_draws_list[["b_doe_std:lv_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_doe_std:lv_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_doe_std:lv_std"]]$ci_high, accuracy = 0.01)`]), suggesting that the effect of phonological similarity on a word's probability of acquisition changed depending on participants' exposure to the language it belonged to. Follow up analyses on this interaction (see @fig-results-marginal) showed that, when exposure to the language was low (e.g., 10%), phonological similarity increased the probability of acquisition substantially. This effect was negligible when exposure to both languages was balanced (e.g. 50-50%). Finally, when exposure to the language was high (e.g., 90%), this effect was very close to zero, although with different direction, with phonological less similar translation equivalents being more likely to be acquired than phonologically more similar ones.

The 95% *HDI* of the regression coefficient of the $Age \times DoE$ interaction did not exclude the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:doe_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:doe_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:doe_std"]]$ci_high, accuracy = 0.01)`]): `r percent(post_draws_list[["b_age_std:doe_std"]]$rope_percentage, accuracy = 0.01)` of its posterior samples fell within the *ROPE*. This shows that the effect of the degree of exposure on the speed at which participants acquired word across ages was inconclusive. Give our data, it is difficult to tell whether this *DoE* increased or decreased the slope of the words' acquisition trajectories. The 95% *HDI* of the regression coefficient of the $Age \times Levenshtein$ interaction overlapped completely with the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:lv_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:lv_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:lv_std"]]$ci_high, accuracy = 0.01)`]), indicating that phonological similarity did not speed-up the acquisition trajectories of the words across ages. Finally, the 95% *HDI* of the regression coefficient of the $Age \times DoE \times Levenshtein$ interaction also overlapped completely with the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:doe_Std:lv_std"]]$median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:doe_std:lv_std"]]$ci_low, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:doe_std:lv_std"]]$ci_high, accuracy = 0.01)`]), suggesting that the impact of the degree of exposure to the language on the effect of phonological similarity did not differ substantially across ages. 

```{r}
#| label: fig-results-marginal
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Expected posterior predictions. Posterior poreditions for the extended model were generated by computing the probability acquisition that resulted from feeding the equation of the regression model with values of the posterior distribution of each coefficient. These values correspond to the 4,000 samples of the posterior distribution that were drawn during the MCMC estimation of the model. Therefore, we generated 4,000 predictions for a series of combination of levels of interest. Each line and interval and in the figure summarises the mean and 95% *HDI* of each combination of levels. The X-axis indicates the age (in months) for which the prediction is generated. The Y-axis indicates the predicted probability of acquisition (*Comprehension* or *Comprehension and Production*). Different colours indicate different levels of phonological similarity (as indicated by the Levenshtein similarity between pairs of translation equivalents). Finally, predictions are presented separately for different degrees of exposure (10%): little exposure to the language (10% DoE, traditionally classified as monolingual), balanced exposure to both languages (50%, traditionally classified as bilingual), and high exposure to the language (90%, traditionally classified as monolingual). Predictions for *Comprehension* are show on top and predictions for *Comprehension and Production* are shown on the bottom."
nd <- expand.grid(
    n_phon_std = 0,
    freq_std = 0,
    age_std = (10:36-mean(df$age))/(sd(df$age)),
    doe_std = (c(0.1, 0.5, 0.9)-mean(df$doe))/(sd(df$doe))
    # lv_std = (c(0, 0.5, 1)-mean(df$lv))/(sd(df$lv))
)

m <- add_epred_draws(nd, model_fit_1, ndraws = NULL, re_formula = NA) %>% 
    mutate(
        freq_std = as.factor(paste0("Frequency = ", freq_std, " SD")),
        doe_std = factor(
            doe_std, 
            levels = unique(nd$doe_std), 
            labels = paste0("DoE: ", c(10, 50, 90), "%")
        )
        # lv_std = factor(
        #     lv_std, 
        #     levels = unique(nd$lv_std),
        #     labels = paste0(c(0, 50, 100), "%")
        # )
    ) %>% 
    filter(.category != "No") %>% 
    pivot_wider(names_from = ".category", values_from = ".epred") %>% 
    mutate(Understands = Understands + `Understands and Says`) %>% 
    pivot_longer(
        c(Understands, `Understands and Says`),
        names_to = ".category",
        values_to = ".epred"
    ) %>% 
    mutate(
        .category = str_replace_all(
            .category,
            c(
                "Understands and Says" = "Production\n(Understands and Says))",
                "Understands" = "Comprehension\n(Understands)"
            )
        )
    )

d <- df %>%
    mutate(
        doe_std = case_when(
            between(doe, 0.00, 0.20) ~ "DoE: 10%",
            between(doe, 0.40, 0.60) ~ "DoE: 50%",
            between(doe, 0.80, 1.00) ~ "DoE: 90%"
        ) %>% 
            factor(., levels = paste0("DoE: ", percent(c(0.1, 0.5, 0.9)))),
        # lv_std = case_when(
        #     between(lv, 0.00, 0.20) ~ "0%",
        #     between(lv, 0.40, 0.60) ~ "50%",
        #     between(lv, 0.80, 1.00) ~ "100%"
        # ) %>% 
        #     factor(., levels = paste0(percent(seq(0, 1, 0.5)))),
        age_std = ((floor(age)-mean(df$age))/(sd(df$age))) %>% 
            cut(
                .,
                breaks = ((seq(10, 38, 2)-mean(df$age))/(sd(df$age))),
                labels = ((seq(10, 36, 2)-mean(df$age))/(sd(df$age))),
                include.lowest = TRUE
            ) %>% 
            as.character() %>% 
            as.numeric(),
        Understands = response %in% c("Understands", "Understands and Says"),
        `Understands and Says` = response %in% "Understands and Says"
    ) %>% 
    drop_na(doe_std) %>% 
    group_by(te, age_std, doe_std) %>% 
    summarise(
        Understands = mean(Understands),
        `Understands and Says` = mean(`Understands and Says`),
        .groups = "drop"
    ) %>% 
    pivot_longer(
        c(Understands, `Understands and Says`),
        names_to = ".category",
        values_to = ".epred"
    ) %>% 
    mutate(
        .category = str_replace_all(
            .category,
            c(
                "Understands and Says" = "Production\n(Understands and Says))",
                "Understands" = "Comprehension\n(Understands)"
            )
        )
    )

m %>% 
    ggplot() +
    aes(
        x = age_std, 
        y = .epred, 
        colour = doe_std,
        fill = doe_std
    ) +
    facet_grid(~.category) +
    stat_lineribbon(
        size = 1,
        alpha = 0.5,
        .width = 0.95, 
        colour = NA,
        point_interval = mean_hdi
    ) +
    stat_summary(
        data = d,
        fun.data = "mean_se",
        geom = "pointrange",
        size = 0.25
    ) +
    # geom_point(
    #     data = d,
    #     position = position_dodge(width = 0.25),
    #     size = 0.5,
    #     alpha = 0.5
    # ) +
    stat_summary(fun = "mean", geom = "line", size = 1) +
    scale_x_continuous(
        breaks = (seq(10, 36, 2)-mean(df$age))/(sd(df$age)),
        labels = seq(10, 36, 2)
    ) +
    scale_color_d3() +
    labs(
        x = "Age (months)", 
        y = "Posterior probability of acquisition\n(Linear prediction)",
        colour = "Degree of exposure",
        fill = "Degree of exposure"
    ) +
    scale_y_continuous(labels = percent, limits = c(0, 1)) +
    theme(
        legend.position = "top",
        axis.ticks.x = element_line(colour = "black"),
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.border = element_rect(fill = NA, colour = "black", size = 0.75),
        strip.background = element_rect(fill = "grey", colour = NA),
        plot.background = element_rect(fill = "white", colour = NA)
    )
```

# Discussion {#discussion}

## Summary of the study

This study explored how word acquisition was affected by cognateness in bilingual toddlers. We collected vocabulary data from children learning Catalan and/or Spanish in differing degrees of exposure to each, and then measured the probability of each word being acquired at different ages as a function of (1) participants' exposure to the language it belongs to, and (2) its phonological overlap with its translation equivalent in the other language. We build a multilevel Bayesian model that estimated the effect of both predictors and their interaction, adjusting for other variables known to be relevant during the acquisition of words: participants' age, lexical frequency, and length in phonemes.

## Summary of the results

## Results in contrast with the literature

## Mechanistic explanations

## Limitations

## Further steps


# References {#references}

::: {#refs}
:::

#  Appendix {#appendix}

## Appendix 1: Words {#appendix-words}

```{r}
#| lab: tbl-appendix-words
#| tbl-cap: "Words included in the analysis"
#| echo: false
#| message: false
#| warning: false
#| eval: false
items %>% 
    left_join(distinct(multilex_data$pool, item, te, label)) %>% 
    mutate(
        language = ifelse(str_detect(item, "cat_"), "Catalan", "Spanish"),
        label = paste0(label, " /", ipa_flat, "/"),
        te = as.integer(te),
        n_phon = as.integer(n_phon)
    ) %>% 
    select(language, te, label, freq, n_phon, lv) %>% 
    pivot_wider(
        id_cols = c(te,lv),
        names_from = language,
        values_from = c(label, freq, n_phon), 
        values_fn = first
    ) %>% 
    clean_names() %>% 
    relocate(te, ends_with("catalan"), ends_with("spanish"), lv) %>% 
    arrange(label_catalan) %>% 
    select(-te) %>% 
    gt() %>% 
    fmt_number(starts_with("freq")) %>% 
    fmt_integer(starts_with("n_phon")) %>% 
    fmt_percent(lv) %>% 
    tab_spanner("Catalan", ends_with("catalan")) %>%
    tab_spanner("Spanish", ends_with("spanish")) %>%
    cols_label(
        label_catalan = "Word-form /IPA/",
        freq_catalan = "Frequency",
        n_phon_catalan = "Phonemes",
        label_spanish = "Word-form /IPA/",
        freq_spanish = "Frequency",
        n_phon_spanish = "Phonemes",
        lv = "Levenshtein"
    ) 
```

## Appendix 2: *ROPE* specification {#appendix-words}

We decided to draw the *ROPE* interval around zero so that it covered values smaller the absolute median of those relevant by similar previous studies. After consulting the regression tables of @mitchell2022cognates, @braginsky2019consistency, and @laing2022phonological, we selected the largest regression coefficient that was interpreted as conclusive evidence of the presence of an effect, as indicated by the authors, and transformed it to the probability scale: `r round(median(abs(rope_coefs$estimate)), 3)`, in the logit scale.

