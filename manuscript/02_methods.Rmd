---
---


# Methods

Data and materials are available at OSF (https://osf.io/hy984/), and code is available at GitHub (https://github.com/gongcastro/trajectories).

## Participants

```{r participants, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
tar_load_globals()
tar_load(participants)
tar_load(items)
tar_load(responses)

n_participants <- length(unique(participants$id))
dates <- as_date(range(participants$time_stamp, na.rm = TRUE))
sex <- participants %>% drop_na(sex) %>% count(sex) %>% pull(n) %>% set_names(c("female", "male"))

```

We collected data from `r printnum(n_participants)` children (`r sex[1]` female) from the Metropolitan Area of Barcelona between `r format(dates[1], "%dth %B, %Y")` and `r format(dates[2], "%dth %B, %Y")`. All families gave informed consent before participating and this study was approved by the Comitè d'Ètica de la Investigació amb Medicaments (CEIm) from Hospital del Mar (Barcelona, Spain), code XXXXXXXXX. Families were contacted by e-mail or phone if their child were aged between 10 and 34 months, and had not previously reported to be exposed more than 10% of the time to a language other than Spanish or Catalan. Upon consent, families were sent a link to the questionnaire via e-mail, which they filled from a computer, laptop, or mobile device in a browser within the two week following the invitation to participate. Table 1 summarises the distribution of participants across ages and degrees of exposure (DoE) to L2.

```{r participants_lp, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Participant sample size by age and degree of exposure to a second language. Information about DoE was provided by families when filling the questionnaire. For illustration purposes this table, DoEs were binned into 10\\% wide bins, and ages (in months) were round to the nearest integer. Hyphens indicate that no participants from that specific combination of age filled the questionnaire."}
labs <- c("0-10%", "10-20%", "20-30%", "30-40%", "40-50%")
participants %>% 
  mutate(
    age = round(age),
    doe_2 = ifelse(dominant_language=="Catalan", doe_spanish, doe_catalan),
    doe_2 = cut(doe_2, breaks = seq(0, 0.5, 0.1), include.lowest = TRUE, labels = labs)
  ) %>% 
  count(age, doe_2) %>% 
  arrange(doe_2) %>% 
  mutate(doe_2 = fct_inorder(doe_2)) %>% 
  pivot_wider(names_from = age, values_from = n, values_fill = NA) %>% 
  gt() %>% 
  tab_spanner(label = "Number of participants by age (months)", columns = 2:17) %>% 
  fmt_missing(everything(), everything(), missing_text = "-") %>% 
  cols_label(
    doe_2 = md("**L2 DoE**")
  ) %>% 
  tab_style(
    cell_text(style = "italic"),
    cells_column_labels(everything())
  ) %>% 
  tab_style(
    cell_text(weight = "bold"),
    cells_column_spanners(everything())
  )

```


We use the highest educational attainment of parents or caretakers as a proxy of participants' socio-economic status (SES), which families self-reported in the questionnaire by filling two items asking for the educational attainment of each parent or caretaker, with the following available options: *No education*, *Primary*, *Secondary*, *Complementary*, *Vocational*, and *University*, in line with the current educational system in Spain. Most families reported university studies (`r table(participants$edu_parent)["University"]`, `r table(participants$edu_parent)["University"]/length(unique(participants$id))`), followed by families were the highest educational attainment were vocational studies (`r table(participants$edu_parent)["Vocational"]`, `r percent(table(participants$edu_parent)["Vocational"]/length(unique(participants$id)))`), complementary studies (`r table(participants$edu_parent)["Complementary"]`,  `r percent(table(participants$edu_parent)["Complementary"]/length(unique(participants$id)))`), secondary education (`r table(participants$edu_parent)["Secondary"]`, `r percent(table(participants$edu_parent)["Secondary"]/length(unique(participants$id)))`, `r `percent(table(participants$edu_parent)["Primary"]/length(unique(participants$id)))`), no formal education (`r table(participants$edu_parent)["No education"]`, and primary education (`r table(participants$edu_parent)["Primary"]`, <1%). Highest educational attainment was similar across participants with different DoE to a second language, and therefore, differences in comprehension or production between participants with different language profiles are unlikely to stem from a difference in SES [@fernald2013ses; see Table 2]. 


```{r participants_edu, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Educational attainment. Proportion of highest parental educational attainment by DoE to the second language. For illustration purposes, DoEs were binned into 10\\% wide bins. The bottom row indicates the mean proportion of participant families for each educational attainment."}
labs <- c("0-10%", "10-20%", "20-30%", "30-40%", "40-50%")

participants %>%
  mutate(
    age = round(age),
    doe_2 = ifelse(dominant_language=="Catalan", doe_spanish, doe_catalan),
    doe_2 = cut(doe_2, breaks = seq(0, 0.5, 0.1), include.lowest = TRUE, labels = labs)
  ) %>% 
  group_by(doe_2) %>%
  summarise(
    n_no_education = length(edu_parent[edu_parent=="No education"])/n(),
    n_primary = length(edu_parent[edu_parent=="Primary"])/n(),
    n_secondary = length(edu_parent[edu_parent=="Secondary"])/n(),
    n_complementary = length(edu_parent[edu_parent=="Complementary"])/n(),
    n_vocational = length(edu_parent[edu_parent=="Vocational"])/n(),
    n_university = length(edu_parent[edu_parent=="University"])/n(),
    .groups = "drop"
  ) %>% 
  gt() %>% 
  tab_spanner("Educational attainment", columns = 2:7) %>% 
  cols_label(
    doe_2 = md("**L2 DoE**"),
    n_no_education = "No education",
    n_primary = "Primary",
    n_secondary = "Secondary",
    n_complementary = "Complementary",
    n_vocational = "Vocational",
    n_university = "University"
  ) %>% 
  fmt_percent(2:7) %>% 
  fmt_missing(everything(), missing_text = "-") %>% 
  summary_rows(
    columns = 2:7, 
    fns = list(Mean = ~mean(.)),
    formatter = fmt_percent,
    decimals = 2
  ) %>%  
  tab_style(
    cell_text(style = "italic"),
    cells_column_labels(everything())
  ) %>% 
  tab_style(
    cell_text(weight = "bold"),
    cells_column_spanners(everything())
  )
```


## Questionnaire

```{r items, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
pool <- multilex::pool %>% 
  drop_na(cognate)
n_categories <- distinct(pool, category) %>% nrow()
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>% pull(n) %>% set_names(c("catalan", "spanish"))
n_item_cognate <- count(pool, language, cognate) %>% 
  pull(n) %>% 
  set_names(c("catalan-cognate", "catalan-noncognate", "spanish-cognate", "spanish-noncognate"))
```


The questionnaire was implemented on-line using `formr` [@arslan2020formr]. This questionnaire was divided in three forms: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000infant] and consisted in two lists of words: one in Catalan and one in Spanish. Items in one language were translation equivalents of the items in the other language (e.g., whenever *gos* [dog] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. When there were two acceptable translation equivalents for a given word, we included both (e.g., Catalan *acabar* [*to finish*] and Spanish *acabar* and *terminar*), or merged them into the same one (e.g., Spanish *mono* [*monkey*] and Catalan *mono/mico*. We included items from a diverse sample of `r n_categories` semantic/functional categories (see Appendix 1). We discarded the following categories: adverbs, auxiliary words, connectives, interjections and games and routines. The Catalan inventory contained `r n_item_language["catalan"]` items (`r n_item_cognate["catalan-cognate"]` cognates, `r n_item_cognate["catalan-noncognate"]` non-cognates) and the Spanish inventory contained `r n_item_language["spanish"]` (`r n_item_cognate["spanish-cognate"]` cognates, `r n_item_cognate["spanish-noncognate"]` non-cognates).


For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand and say it, or did not understand or say it (marked by default). Parents filled a long or a short version of the questionnaire. Those presented with the long version filled a list of 800 translation equivalents (800 items in Catalan, 800 items in Spanish), while participants presented with a short were randomly allocated into one of four list of items. Each list contained a different set of ~400 translation equivalents (~400 items in Catalan, ~400 items in Spanish). Semantic/functional categories with less than 16 items--thus resulting in less than four items after dividing it in four lists--were not divided in the short version of the questionnaire: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. Table 2 in Appendix 1 shows the distribution of items across questionnaire versions. We excluded from the analysis multi-word items (e.g., *barrita de cereales* [cereal bar]) and items that included more than one word-form (e.g., *mono / mico*). Table \@ref(tab:itemsinfo) shows the classification of items in cognates and non-cognates and their lexical frequency scores across the four lists of the inventories.

```{r items_frequency, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Lexical frequencies. Mean, standard error, and 95\\% confidence interval of lexical frequencies of items included in the Catalan and Spanish lists, reported separately for identical cognates, non-identical cognates, and non-cognates. The bottom row indicates the grand mean, mean standard error and mean 95\\% confidence interval for lexical frequencies of identical cognates, non-identical cognates, and non-cognates."}
items %>%
  select(te, language, cognate, frequency) %>% 
  left_join(select(multilex_data$pool, te, language, version)) %>% 
  unnest(version) %>% 
  group_by(language, version, cognate) %>% 
  summarise(
    frequency_mean = mean(frequency, na.rm = TRUE),
    frequency_sd = sd(frequency, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) %>% 
  mutate(
    frequency_se = frequency_sd/sqrt(n),
    frequency_ci_lower = frequency_mean + qnorm(0.025)*frequency_se,
    frequency_ci_upper = frequency_mean + qnorm(0.975)*frequency_se
  ) %>% 
  pivot_wider(names_from = c("cognate"), values_from = c("n", matches("frequency"))) %>% 
  clean_names() %>% 
  relocate(
    language, version,
    n_identical_cognate,
    frequency_mean_identical_cognate,
    frequency_se_identical_cognate,
    frequency_ci_lower_identical_cognate,
    frequency_ci_upper_identical_cognate,
    matches("_non_identical"),
    matches("_non_cognate")
  ) %>% 
  select(-matches("sd")) %>% 
  gt(groupname_col = "language") %>% 
  fmt_number(matches("frequency")) %>% 
  summary_rows(
    columns = matches("frequency"), 
    fns = list(Mean = ~mean(.)),
    formatter = fmt_number,
    decimals = 2
  ) %>%
  cols_merge(
    c("frequency_ci_lower_identical_cognate", "frequency_ci_upper_identical_cognate"), 
    pattern = "[{1}, {2}]") %>% 
  cols_merge(
    c("frequency_ci_lower_non_identical_cognate", "frequency_ci_upper_non_identical_cognate"),
    pattern = "[{1}, {2}]"
  ) %>% 
  cols_merge(
    c("frequency_ci_lower_non_cognate", "frequency_ci_upper_non_cognate"),
    pattern = "[{1}, {2}]"
  ) %>% 
  tab_spanner("Identical cognates", columns = ends_with("_identical_cognate")) %>% 
  tab_spanner("Non-identical cognates", columns = ends_with("_non_identical_cognate")) %>% 
  tab_spanner("Non-cognates", columns = ends_with("_non_cognate")) %>% 
  cols_width(
    starts_with("frequency_ci_lower_") ~ px(100),
    TRUE ~ px(50)
  ) %>% 
  cols_label(
    version = "List",
    n_identical_cognate = "N",
    n_non_identical_cognate = "N",
    n_non_cognate = "N",
    frequency_mean_identical_cognate = md("Mean<sub>freq</sub>"),
    frequency_mean_non_identical_cognate = md("Mean<sub>freq</sub>"),
    frequency_mean_non_cognate = md("Mean<sub>freq</sub>"),
    frequency_se_identical_cognate = md("SD<sub>freq</sub>"),
    frequency_se_non_identical_cognate = md("SD<sub>freq</sub>"),
    frequency_se_non_cognate = md("SD<sub>freq</sub>"),
    frequency_ci_lower_identical_cognate = md("95% CI<sub>freq</sub>"),
    frequency_ci_lower_non_identical_cognate = md("95% CI<sub>freq</sub>"),
    frequency_ci_lower_non_cognate = md("95% CI<sub>freq</sub>")
  ) %>%  
  tab_style(
    cell_text(style = "italic"),
    cells_column_labels(everything())
  ) %>% 
  tab_style(
    cell_text(weight = "bold"),
    cells_column_spanners(everything())
  )


```


## Data analysis

```{r n_responses, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
n_obs <- nrow(responses)
sum_obs <- responses %>%
  group_by(te) %>%
  summarise(n = n(), .groups = "drop") %>%
  summarise(
    mean = mean(n),
    sd = sd(n),
    min = min(n),
    max = max(n)
  )

```


We gathered `r printnum(n_obs, big.mark = ",")` responses. Translation equivalents (TEs) received an average of `r printnum(sum_obs$mean, digits = 2)` responses (*SD* = `r printnum(sum_obs$sd, digits = 2)`, *Min* = `r printnum(sum_obs$min, digits = 2)`, Max = `r printnum(sum_obs$max, digits = 2)`), both languages summed together. To investigate our hypotheses, we modelled the probability of children understanding or producing TEs using a logistic regression model with a Bernoulli distribution and a logit link function [@agresti2003categorical]. We included several predictors of interest as fixed effects to adjust this probability to participants' and items' characteristics, namely:


* *Age* of participant in months (`age`), calculated as the difference in days between participants' birth date and questionnaire completion divided by 30, chunked into bins of two months width, and centred around the mean.
* *Lexical frequency* of item (`frequency_center`), Relative lexical frequencies (frequency per million words, $fpmw$) were extracted from the CHILDES data base, using the `childesr` R package [@braginsky2018childesr], and were transformed to Zipf scores [@van2014subtlex; @zipf1949human] ($log10(fpmw)+3$). Missing frequencies were imputed by multiple imputation using the `mice` R package [van2011mice]. The resulting scores were then centred around the mean.
* *Degree of exposure to L2* of participant (`doe_center`), computed as the percentage of exposure to a second language (Spanish for participants exposed to >50% to Catalan an *vice versa*), chunked into six groups of participants (a proxy of degree of bilingualism), ranging from 0% to 50%, and centred around the mean.
* *Cognateness* of the item, indicating whether the two forms of each TE are identical cognates (IC), non-identical cognates (NIC), or non-cognates (NC), as rated by a trained Spanish-Catalan bilingual linguist. We sum-coded two contrasts [@schad2020capitalize], one comparing IC (coded as +0.5) and NIC with NC (coded as -0.5) (`cognate1`), and the other comparing IC (coded as +0.5) with NIC (coded as -0.5) (`cognate2`).


We first fit a base model that only included the main effects of `age` and `frequency_center`. [see @braginsky2019consistency; @jones2019children; @kachergis2021toward for similar approaches] (Model 1). We then introduced our predictors of interest by adding `doe_center` (Model 2) and then `cognate` and its interaction with `doe` (Model 3). To account for the hierarchical structure of the data--some responses to different TEs corresponded to the same participant, and some responses from different participants corresponded to the same TE--every model included *Participants* (`id`) and *TEs* (`te`) as grouping variables (i.e. random effects), with all possible random intercepts and slopes where appropriate [@barr2013random; see Appendix for more details of the model]. 


We adopted a Bayesian approach toward statistical inference. This approach allows to (1) incorporate previous domain knowledge into the inference process implementing the Bayes theorem, and (2) to quantify the uncertainty associated to the estimated parameters in our model [@mcelreath2018statistical]. 
We fit the models using the R package `brms` [@burkner2017brms], an R interface to the probabilistic language Stan [@carpenter2017stan]. We run four sampling chains with 1,000 iterations each, including 500 warm-up iterations per chain. All R-hat values were smaller than 1.1, indicating that the chains converged successfully in all cases [@gelman1992inference; see Appendix for an extended description of model diagnostics].


We then compared comprehension and production models separately using leave-one-out cross-validation (LOO-CV) [@vehtari2017practical]^[Due to the high computational cost associated with a large dataset, we used a sub-sampling approach for performing Bayesian LOO with 1,000 samples [@magnusson2019bayesian]]. This method computes, for a given model, the sum of the log scores of the posterior predictive distributions that result from removing one data-point at a time, providing an estimate of the model fit. The LOO estimates are adjusted for the number of parameters estimated in the model, therefore accounting for overfitting. We compared the expected log posterior density (ELPD) of each each model to test which one fitted the data the best.


We then explored the posterior distribution of each parameter in the comprehension and production models that fitted the data the best computing the 95% credible intervals and testing whether this interval excluded 0. Credible intervals (CrI) indicate the range of values we are 95% certain contain the true value of the parameter, given our prior and observed data. We performed follow-up tests on interactions whose 95% credible interval excluded 0 by comparing the 95% credible interval of their estimated marginal means using the `emmeans` package [@R-emmeans]. Data processing and visualisation was done in R [@R-base] using the `tidyverse` family of packages [@R-tidyverse], and posterior samples and marginal means were extracted using the `tidybayes` R package [@R-tidybayes].

