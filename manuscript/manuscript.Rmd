---
title             : "The role of cross-linguistic lexical similarity on bilingual word acquisition"
shorttitle        : "Cross-linguistic similarity and  word acquisition"

author: 
  - name          : "Gonzalo Garcia-Castro"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Ramon Trias Fargas, 25-27, 08005 Barcelona, Spain"
    email         : "gonzalo.garciadecastro@upf.edu"
  - name          : "Daniela Avila-Varela"
    affiliation   : "1"
  - name          : "Ignacio Castillejo"
    affiliation   : "2"
  - name          : "Nuria Sebastian-Galles"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Center for Brain and Cognition, Universitat Pompeu Fabra, Barcelona, Spain"
  - id            : "2"
    institution   : "Universidad Autónoma de Madrid"

authornote: |
  Campus de Ciutadella, Universitat Pompeu Fabra, 08005, Barcelona, Spain

abstract: |
  Bilinguals face the challenging task of learning words from languages with overlapping phonologies. Floccia et al. (2018) reported larger vocabulary sizes for 24-month-old bilinguals that were learning languages that shared a greater amount of cognates (e.g., English-Dutch). The mechanisms underlying this effect remain unknown. We explore two compatible scenarios. First, we test whether cognates are learnt earlier than non-cognates. This would account for the difference in vocabulary size associated to the amount of shared cognates across languages. Second, we explore the possibility that the word-forms of one language interact with those form the other language, scaffolding the acquisition of their translation equivalents when their phonologies overlap. This mechanism, in line with the parallel activation account of bilingual speech perception, would provide a plausible explanation to why cognates are acquired ealier by bilinguals. We developed an online tool to collect parental reports of receptive and productive vocabularies from children learning Catalan and/or Spanish, and present data on receptive and productive vocabulary of bilingual toddlers aged 12 to 34 months.


  <!-- https://tinyurl.com/ybremelq -->

keywords          : "lexical acquisition, vocabulary, bilingualism"
wordcount         : "X"

bibliography      : ["references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
keep_text         : false
class             : "man"

documentclass     : "apa6"
classoption       : "man"
output            :
  word_document:
    reference_docx: "manuscript_template.docx"

  

---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
    echo = FALSE,
    fig.align = "center",
    message = FALSE,
    warning = FALSE,
    cache.extra = knitr::rand_seed,
    out.width = "100%",
    dpi = 800,
    results = "asis"
)
```

```{r packages, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

# load packages
library(bayesplot)
library(brms) 
library(conflicted)
library(dplyr) 
library(forcats)
library(ggplot2) 
library(ggsci)
library(gt) 
library(here) 
library(janitor)
library(knitr)
library(lubridate)
library(multilex)
library(patchwork) 
library(papaja) 
library(purrr)
library(quarto)
library(rmarkdown)
library(scales) 
library(stringdist)
library(stringr)
library(tidybayes) 
library(tidyr) 

# load and process objects
tar_load_everything()
participants <- participants %>% 
    left_join(select(multilex_data$logs, id, time, edu_parent))
items <- items %>% 
    left_join(select(pool, item, language, category, class))

# set global options
options(
    knitr.kable.NA = "-",
    knitr.duplicate.label = "allow",
    ggplot2.discrete.fill = ggsci::pal_d3()(4),
    ggplot2.discrete.colour = ggsci::pal_d3()(4),
    ggplot2.continuous.fill = ggplot2::scale_color_gradient,
    ggplot2.continuous.colour = ggplot2::scale_color_gradient
)

# set custom ggplot2 theme
theme_set(theme_custom())

# resolve namespace conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
```

# Introduction

Before the end of their first year of life, infants start directing their gaze to some objects when hearing their labels, according to both experimental data [@jusczyk1995infants; @tincoff1999some; @bergelson2012months; @bergelson2015early] and parental reports [e.g., @fenson2007macarthur]. During the last half of their second year, they acquire new words at an increasingly fast rate [@goldfield1990early; @fenson1994variability; @mayor2011statistical; @bloom2002children; @bergelson2020comprehension]. These early stages of lexical acquisition are characterised by substantial variation between children, reflected, for instance, on the variation on the number of words they know [i.e. vocabulary size; @fenson1994variability; @frank2021variability] or on the proportion of those words that fall into the category of nouns, as opposed to verbs, adjectives, or function words [e.g., @nelson1973structure, bates1994developmental].


Despite this variability, children's trajectories of vocabulary growth seem quite stable across languages. @tardif2008baby collected data about the first ten words acquired by 10 to 16 month-old infants living in the United States, Hong Kong, and Beijing. Since birth, these infants had been learning English, Cantonese and Mandarin, respectively. The authors found a common pattern across the three groups: their first ten words referred to roughly the same concepts, namely relatives/caretakers (*daddy*, *mommy*), social routines (*bye*, *uh-oh*) or animals (*woof-woof*). These results were later extended by @frank2021variability to a wider diversity languages, who also reported that such cross-language commonalities are stronger at earlier stages of lexical acquisition, compared to later stages. Most of the literature on early word acquisition, however, has been conducted on monolingual children, and neglects the problem of how bilinguals--who represent a substantial proportion of the population in most societies--acquire words at early ages.


There is evidence that bilinguals know less words in each of their languages than monolinguals, but also that both groups know a similar amount of words when the two languages are aggregated. For example, @hoff2012dual found that English-Spanish bilingual toddlers in South Florida knew less words in English than monolinguals, who only learnt English. Both groups knew a similar total amount of words when both English and Spanish vocabularies were counted together, pointing to the importance of collecting data on both languages when assessing bilinguals' communicative development. Other studies have provided converging evidence that bilinguals know a similar--or even larger--number of words than monolinguals, only when the languages are aggregated [@oller2002language; @pearson1994patterns; @pearson1993lexical; @patterson2004comparing; @patterson2004bilingual; @smithson2014bilingualism; @petitto2001bilingual; @gonzalez2020bilingual]. While these studies have mostly relied on samples of bilingual children learning two relatively distant languages, as it is the case of English and Spanish, it is unclear whether children learning typologically more similar languages also know less words in each of their languages than monolinguals. What role could linguistic distance play during early vocabulary growth?


For a given set of concepts, bilingual children may be exposed to two distinct sets of word-forms--one in each language. Depending on the linguistic distance between both languages, the two sets of words may overlap in varying degrees. Particularly, when both languages are typologically close, like Spanish and Catalan (both Roman languages), they are more likely to share a large amount of cognates (i.e., form-similar translation equivalents) than two linguistically distant languages, like Spanish and English (one Roman, the other Germanic). For instance, in the presence of a door, a Spanish-Italian (or a Spanish-Catalan) bilingual might hear *puerta* and *porta* (cognates), whereas a Spanish-English bilingual might hear *puerta* and *door* (non-cognates). It could be the case that mapping two phonologically similar labels (cognates like *puerta*-*porta*) onto the same referent is easier than doing the same with two phonologically dissimilar labels (non-cognates, like *puerta* and *door*). If cognates are easier to acquire than non-cognates, bilinguals learning a pair of languages that share a high proportion of cognates should benefit more often from this facilitation effect than those learning a pair of languages with a lower proportion of cognates, and should therefore show larger vocabulary sizes.


@floccia2018introduction provided evidence in line with this claim. The authors collected vocabulary data on word comprehension and production from 372 24-month-old bilingual toddlers living in the United Kingdom who were learning English and an additional language. The additional language was one a pool of 13 typologically diverse languages: Bengali, Cantonese Chinese, Dutch, French, German, Greek, Hindi/Urdu, Italian, Mandarin Chinese, Polish, Portuguese, Spanish and Welsh. The authors calculated the average phonological similarity between the words in each of these additional languages and their translation equivalents in English. Phonological similarity was measured by computing the Levenshtein distance between each cross-language pair of phonological transcriptions. The Levenshtein distance is a metric that computes the edit distance between two strings by counting the smallest number of insertions, deletions and substitutions one of the strings has to go through to become identical to the other [@levenshtein1966binary]. The resulting scores were then divided by the length of the longest string to bound the similarity scores between 0 and 1, and then entered this variable as a predictor as they modelled participants' vocabulary sizes. Among other findings, the authors reported an increase in productive vocabulary size in the additional language associated with an increase in the average phonological similarity between the translation equivalents of each language pair. For example, English-Dutch bilinguals (22.14% phonological similarity), were able to produce more Dutch words than English-Mandarin bilinguals (1.97% phonological similarity) were able to produce in Mandarin.


Floccia et al. pointed to *parallel activation* as the main mechanism underpinning their results. The parallel activation hypothesis suggests that bilinguals activate both languages simultaneously during speech production or comprehension. This phenomenon is the result of the activation of lexical representations in both languages, even when only one is in use during production [@costa2000cognate; @hoshino2008cognate] or comprehension [@thierry2007brain]. One of the clearest examples of parallel activation was provided by @costa2000cognate. In this study, Catalan-Spanish monolingual and bilingual adults were asked to name pictures of common objects in Spanish. In half of the trials, the object labels were cognates in Spanish and Catalan (*árbol*-*arbre*, translations of *tree*), whereas in the other half of the trials labels were non-cognates (*mesa*-*taula*, translations of *table*). Bilinguals named cognate pictures faster than non-cognate pictures, even after adjusting for the lexical frequency of the items. Importantly, Spanish monolinguals did not show this effect. These results suggest that, for the bilinguals, Catalan phonology was activated during the production of Spanish words, facilitating the naming of cognate pictures. Several recent studies have also provided similar evidence in comprehension in children [e.g., @von2012language; @poulin2013lexical]. Parallel activation is therefore a plausible mechanism to account for Floccia et al.'s results: cognates increase the amount of activation in both languages, facilitating word acquisition, and ultimately leading to children learning language pairs with a larger proportion of cognates are predicted to show larger vocabulary sizes. A missing piece in this account is how increase parallel activation might facilitate the acquisition new words.


In this study, we hypothesise that cognates are acquired earlier in age than non-cognates, which might explain why children learning languages that share many cognates show larger vocabulary sizes. Evidence supporting this claim is scarce. To the best of our knowledge, only two studies have provided direct data on this issue. First, @bosch2014first used vocabulary parental reports (152 lexical items) from 48 Catalan-Spanish bilinguals aged 18 months, and found that cognates represented a larger proportion of participant's vocabulary than non-cognates. Second, @schelletter2002effect reported a longitudinal single case of one English-German bilingual who produced cognates earlier than non-cognates, on average. The low sample size in these studies makes it challenging to draw strong conclusions about the effect of cognateness on vocabulary growth. Floccia et al.'s estimates are statically more reliable given their (much larger) sample size, but their study was not aimed at testing the effect of cognateness on age of acquisition directly. In their discussion the authors state the following (pp. 70):


> "This  finding  also  provides  support  to  the  proposal  that  the  cognate advantage is due to cognates being acquired before non-cognates in early childhood (Costa et al., 2016), leading to an ease of processing later in life."


We identify two main reasons why an earlier age of acquisition for cognates than for non-cognates is an unwarranted conclusion from Floccia et al.'s results. First, the response variable used was the proportion of words each participant understood and/or produced (i.e., vocabulary size), from the list of lexical items in the vocabulary checklists. By aggregating the responses from all items into a single datum per child, information about the acquisition status of cognates vs. non-cognates was lost. Second, all participants were aged ~24 months, meaning that even if the unaggregated responses to individual items were included as response variable, the possible effect of cognateness could only be interpreted as an increase or decrease in the likelihood of participants at such age to have acquired each item, and not as an increase or decrease in the age of acquisition of such item. In summary, the current evidence supporting an earlier age of acquisition of cognates vs. non-cognates presents some limitations that prevents drawing sound conclusions about this effect. 


Our second hypothesis detaches from the fact that, for parallel activation to take place, and for cognateness to facilitate the acquisition of a word form in a given language, the child must be familiar with the (phonologically similar) translation of the word, in the other language. If the child is not previously familiar with one of the word forms, the acquisition of its translation in  language cannot be facilitated by cognateness. This implies that, if cognateness facilitates the acquisition of a word form, it can only do so after the child has acquired one of the word forms of the translation pair. Given that children are more likely to acquire words from languages to which they are exposed more often [@david2008individual; @cattani2014much; @thordardottir2006bilingual], the acquisition of words in the language of lower exposure should, on average, be more susceptible to the effect of cognateness. Therefore, we hypothesised that the effect of cognateness for words in the language of lower exposure would be larger than in the language of higher exposure.


In line with this hypothesis, the vocabulary size associated with linguistic similarity that Floccia et al. reported was larger in the additional language vocabulary than in English vocabulary. Most participants in their sample were English-dominant, meaning that their relative amount of exposure to English was larger than in the additional language. Therefore, participants may have, on average, learnt the English word-form of translation equivalents earlier than the word-form in the additional language.  If this is the case, then the acquisition of English words by English-dominant participants would rarely benefit from their cognate status (the other word-form is not available yet), while the acquisition of words in the additional language would benefit from their phonological similarity with the (available) English form. To test this hypothesis, we conditioned the effect of cognateness to the relative degree of exposure to the language.


In summary, we investigated the role of cognateness in bilingual word acquisition (conditional to the degree of relative exposure to the language) as possible mechanism to account for the facilitation  of language similarity on bilingual children's vocabulary size. We hypothesised that cognate words would be acquired earlier than non-cognate words, and that this effect should be larger for words in the language with lower exposure. Using an online vocabulary checklist--carefully designed specifically for this study--we collected data from a sample of children aged `r min(floor(participants$age))` to `r max(floor(participants$age))` months learning Catalan and/or Spanish, with varying degrees of exposure to each language. We then modelled the probability of participants being reported by their parents to understand and/or say each word in the checklist, conditional to its cognate status in Catalan and Spanish and participants' degree of exposure to the corresponding language, while adjusting for participants' age and the item's lexical frequency.


# Methods

Data and materials are available at OSF (https://osf.io/hy984/), and code is available at GitHub (https://github.com/gongcastro/trajectories).

## Participants

```{r participants, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
n_participants <- length(unique(participants$id))
dates <- as_date(range(participants$time_stamp, na.rm = TRUE))
```

We collected data from `r printnum(n_participants)` children from the Metropolitan Area of Barcelona between `r format(dates[1], "%dth %B, %Y")` and `r format(dates[2], "%dth %B, %Y")`. All families gave informed consent before participating and this study was approved by the Comitè d'Ètica de la Investigació amb Medicaments (CEIm) from Hospital del Mar (Barcelona, Spain), code XXXXXXXXX. Families were contacted by e-mail or phone if their child were aged between 10 and 34 months, and had not previously reported to be exposed more than 10% of the time to a language other than Spanish or Catalan. Upon consent, families were sent a link to the questionnaire via e-mail, which they filled from a computer, laptop, or mobile device in a browser within the two week following the invitation to participate. Table 1 summarises the distribution of participants across ages and degrees of exposure (DoE) to the non-dominant language (i.e., their degree of bilingualism).

```{r participants-lp, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=7, fig.cap="Participant sample size by age and degree of exposure to a second language. Information about DoE was provided by families when filling the questionnaire. For illustration purposes this table, DoEs were binned into 10\\% wide bins, and ages (in months) were round to the nearest integer. Hyphens indicate that no participants from that specific combination of age filled the questionnaire."}
participants %>% 
    mutate_at(
        vars(starts_with("doe_")), 
        ~floor(.*10)/10
    ) %>% 
    mutate(age = cut_width(floor(age), 4)) %>% 
    count(age, doe_catalan) %>% 
    arrange(-doe_catalan) %>% 
    pivot_wider(names_from = age, values_from = n) %>% 
    gt() %>% 
    fmt_missing(everything(), everything(), missing_text = "--") %>% 
    cols_label(
        doe_catalan = "DoE Catalan"
    ) %>%
    fmt_percent("doe_catalan", decimals = 0) %>% 
    tab_spanner("Age (months)", 2:8)
```


We use the highest educational attainment of parents or caretakers as a proxy of participants' socio-economic status (SES), which families self-reported in the questionnaire by filling two items asking for the educational attainment of each parent or caretaker, with the following available options: *No education*, *Primary*, *Secondary*, *Complementary*, *Vocational*, and *University*, in line with the current educational system in Spain. Most families reported university studies (`r table(participants$edu_parent)["University"]`, `r table(participants$edu_parent)["University"]/length(unique(participants$id))`), followed by families were the highest educational attainment were vocational studies (`r table(participants$edu_parent)["Vocational"]`, `r percent(table(participants$edu_parent)["Vocational"]/length(unique(participants$id)))`), complementary studies (`r table(participants$edu_parent)["Complementary"]`,  `r percent(table(participants$edu_parent)["Complementary"]/length(unique(participants$id)))`), secondary education (`r table(participants$edu_parent)["Secondary"]`, `r percent(table(participants$edu_parent)["Secondary"]/length(unique(participants$id)))`, `r percent(table(participants$edu_parent)["Primary"]/length(unique(participants$id)))`), no formal education (`r table(participants$edu_parent)["No education"]`, `r percent(table(participants$edu_parent)["No education"]/length(unique(participants$id)))` and primary education (`r table(participants$edu_parent)["Primary"]`, <1%). Highest parental educational attainment was similar across participants with different DoE to a second language (see Appendix).



## Questionnaire

```{r items, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
n_categories <- nrow(distinct(multilex_data$pool, category))
n_te <- length(unique(multilex_data$pool$te))
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>%
    pull(n) %>% 
    set_names(c("catalan", "spanish"))
```


The questionnaire was implemented on-line using the formR platform [@arslan2020formr], and was structured in three blocks: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000infant] and consisted in two lists of words: one in Catalan and one in Spanish. The Catalan inventory contained `r n_item_language["catalan"]` items and the Spanish inventory contained `r n_item_language["spanish"]`. Items in one language were translation equivalents of the items in the other language (e.g., whenever *gos* [dog] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. In case two translation equivalents were possible for a given word, both were inluded as separate items (e.g., Catalan *acabar* [*to finish*] and Spanish *acabar* and *terminar*), or merged them into a single item (e.g., Spanish *mono* [*monkey*] and Catalan *mono/mico*). We included items from a diverse sample of `r n_categories` semantic/functional categories (see Appendix 1). For the analyses included in this study, we excluded items from the adverbs, auxiliary words, connectives, interjections and games and routines categories, so that only data from content words (nouns, adjectives, and verbs) were used.


For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand *and* say it, or did not understand or say it (checked out by default). Some families filled a long version of the vocabulary checklists (`r format(n_te, big.mark = ",")` translation equivalents; `r format(n_item_language["catalan"], big.mark = ",")` items in Catalan, `r format(n_item_language["spanish"], big.mark = ",")` items in Spanish), while others filled a shorter version (~400 translation equivalents, ~400 items in Catalan, ~400 items in Spanish). These last families were randomly allocated into one of four different subsets of the complete list of items. These lists were designed so that each contained a representative sub-sample of the items from the complete list. Semantic/functional categories with less than 16 items--thus resulting in less than four items after dividing it in four lists--were not divided in the short version of the questionnaire: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. Table 2 in Appendix 1 shows the distribution of items across questionnaire versions.


To analyse the data, we considered responses to items corresponding to nouns, verbs, and adjectives [@fourtassi2020]. We excluded multi-word items (e.g., *barrita de cereales* [cereal bar]), items that included more than one word-form (e.g., *mono / mico*), and words with missing lexical frequency scores.

```{r item-summary, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=7, fig.cap="Lexical frequencies. Mean, standard error, and 95\\% confidence interval of lexical frequencies of items included in the Catalan and Spanish lists, reported separately for identical cognates, non-identical cognates, and non-cognates."}
items %>%
    unnest(list) %>% 
    group_by(language, list) %>% 
    summarise_at(
        vars(freq, n_phon, lv), 
        lst(n = ~sum(!is.na(.)), mean, sd, min, max)
    ) %>% 
    select(-c(n_phon_n, lv_n)) %>% 
    rename(n = freq_n) %>% 
    gt(groupname_col = "language") %>% 
    fmt_number(matches("freq_|n_phon_mean|n_phon_sd")) %>% 
    fmt_percent(matches("lv_")) %>% 
    tab_spanner("Frequency (Zipf)", columns = starts_with("freq_")) %>% 
    tab_spanner("# Phonemes", columns = starts_with("n_phon_")) %>% 
    tab_spanner("Levenshtein", columns = starts_with("lv_")) %>% 
    cols_merge_range(col_begin = "freq_min", col_end = "freq_max") %>% 
    cols_merge_range(col_begin = "n_phon_min", col_end = "n_phon_max") %>% 
    cols_merge_range(col_begin = "lv_min", col_end = "lv_max") %>% 
    cols_label(
        list = "",
        n = md("*N*"),
        freq_mean = md("Mean"),
        freq_sd = md("*SD*"),
        freq_min = md("Range"),
        n_phon_mean = md("Mean"),
        n_phon_sd = md("*SD*"),
        n_phon_min = md("Range"),
        lv_mean = md("Mean"),
        lv_sd = md("*SD*"),
        lv_min = md("Range")
    ) %>% 
    tab_style(
        cell_text(style = "italic"),
        cells_column_labels(everything())
    ) %>% 
    tab_style(
        cell_text(weight = "bold"),
        cells_column_spanners(everything())
    )
```


## Data analysis

```{r n_responses, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
n_obs <- nrow(df)
sum_obs <- df %>%
    group_by(te) %>%
    summarise(n = n(), .groups = "drop") %>%
    summarise(
        mean = mean(n),
        median = median(n),
        sd = sd(n),
        min = min(n),
        max = max(n)
    )
```


We gathered `r printnum(n_obs, big.mark = ",")` observations, with each observation corresponding to a single response of one participant to a single item. Translation equivalents (TEs) received a median of `r printnum(sum_obs$median, digits = 2)` responses (*Min* = `r printnum(sum_obs$min, digits = 2)`, *Max* = `r printnum(sum_obs$max, digits = 2)`), both languages summed together.

We modelled the probability of answering each response category (*No* < *Understands* < *Understands and Says*) using a mixed effects model. This allowed us to simultaneously estimate the impact of item- and participant-level predictors on the probability of word comprehension and production. We included the following predictors: age of the participant in months, calculated as the difference in months between participants' birth date and questionnaire completion ($Age$), word lexical frequency, extracted from the CHILDES database using the `childesr` R package [[@braginsky2018childesr]] and expressed in Zipf scores, ($log10(fpmw)+3$) [@van2014subtlex; @zipf1949human] ($Frequency$), number of phonemes included in the IPA phonological transcription of the word-form ($Phonemes$), participant's degree of exposure to the language the item belongs to ($DoE$)^[For instance, for a response to the item `perro` (Spanish), the degree of exposure would correspond to the participant's relative exposure to Spanish (ranging from 0 to 1).], and the Levenshtein distance between the IPA transcriptions of the translation equivalent in Catalan and in Spanish, as a measure of their phonological similarity ($Levenshtein$) [@floccia2018methods].

We included $Age$, $Frequency$, $Phonemes$, $DoE$, and $Levenshtein$ as fixed effects. We also included a three-way interaction between $Age$, $DoE$, and $Levenshtein$ and its corresponding two-way interactions. We added participants and items as crossed random effects including all intercepts and slopes when appropriate [@barr2013maximal]. This model structure, including word- and participant-level properties to estimate vocabulary acquisition trajectories was discussed by @kachergis2021toward in the context of explanatory item response models. Our model differs from their proposal in that  1) while they modelled global trajectories exclusively, we modelled individual trajectories as well, 2) our outcome variable is ordinal in contrast to the binary outcome used in their study, 3) we propose a Bayesian approach. Our motivation for a Bayesian approach towards statistical inference is that (1) it allows us to incorporate previous domain knowledge to improve estimation accuracy, and (2) to quantify the uncertainty associated with the estimated parameters in our model [@mcelreath2018statistical].

The Bayesian approach implies using Bayes’ rule to assign a probability to possible parameter values (i.e., posterior distribution), based on previous knowledge about such probability distribution (prior distribution) and our data (likelihood). We used Markov chain Monte Carlo (MCMC) to approximate the posterior distribution via sampling. We run `r dim(model_fit_7$fit)[2]` sampling chains with `r dim(model_fit_7$fit)[1]` iterations each, including `r dim(model_fit_7$fit)[1]/2` warm-up iterations per chain. All $\hat{R}$ values were smaller than 1.1, indicating that the chains converged successfully in all cases [@gelman1992inference] (see Appendix for an extended description of model structure and diagnostics).

We compared a base model–only including fixed and random intercepts–to increasingly more complex models, introducing predictors in the following order: $Age$, $Frequency$, $Phonemes$, $DoE$, $Levenshtein$, two-, and three-way interactions [see @braginsky2019consistency; @jones2019children; @kachergis2021toward for similar approaches]. We compared the predictive validity of the models using leave-one-out cross-validation (LOO-CV), and selected the model with the smallest expected log posterior density (ELPD) [@vehtari2017practical]^[Due to the high computational cost associated with our large dataset, we used a sub-sampling approach for performing Bayesian LOO with 1,000 samples [@magnusson2019bayesian]]. Finally, we explored the posterior distribution of each parameter in the selected model. We report the mean and 95% credible interval of the posterior distribution of the parameters of interest. We performed follow-up tests on interactions whose 95% credible interval excluded 0 by comparing the 95% CrI of their expected posterior marginal means using the `tidybayes` R package [@R-tidybayes]. Data processing and visualisation was done in R [@R-base] using the `tidyverse` family of packages [@R-tidyverse].

We then explored the posterior distribution of each parameter in the comprehension and production models that fitted the data the best computing the 95% credible intervals and testing whether this interval excluded 0. Credible intervals (CrI) indicate the range of values we are 95% certain contain the true value of the parameter, conditional to the observed data. We performed follow-up tests on interactions whose 95% credible interval excluded 0 by comparing the 95% CrI of their expected posterior marginal means using the `tidybayes` R package [@R-tidybayes]. Data processing and visualisation was done in R [@R-base] using the `tidyverse` family of packages [@R-tidyverse].


# Results

```{r coefs, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
coefs <- as.data.frame(fixef(model_fit_7)) %>% 
    clean_names()

draws_fixed <- gather_draws(model_fit_7, `b_.*`, regex = TRUE)
```


Table 2 shows the summary of the posterior distribution of the fixed coefficients of the model. 

```{r results-fixed, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
str_repl <- c(
    "b_age_std:doe_std:lv_std" = "Age \u00d7 DoE \u00d7 Levenshtein",
    "b_age_std:doe_std" = "Age \u00d7 DoE",
    "b_age_std:lv_std" = "Age \u00d7 Levenshtein",
    "b_doe_std:lv_std" = "DoE \u00d7 Levenshtein",
    "b_lv_std" = "Levenshtein (+1 SD)",
    "b_doe_std" = "DoE (+10%)",
    "b_n_phon_std" = "# Phonemes (+1 SD)",
    "b_freq_std" = "Frequency (+1 SD)",
    "b_age_std" = "Age (+1 month)",
    "b_Intercept[1]" = "Intercept (Production)",
    "b_Intercept[2]" = "Intercept (Comprehension)"
)

draws_fixed %>%
    mutate(
        .value = ifelse(
            grepl("Intercept", .variable),
            inv_logit_scaled(.value), 
            .value/4
        ),
        .variable = factor(.variable, levels = names(str_repl), labels = str_repl)
    ) %>% 
    mean_qi(.width = c(0.95, 0.89)) %>% 
    pivot_wider(names_from = .width, values_from = c(.value, .lower, .upper)) %>% 
    select(-c(.interval, .point, .value_0.89)) %>% 
    arrange(desc(.variable)) %>% 
    gt() %>% 
    fmt_percent(2:6) %>% 
    cols_merge(vars(".lower_0.95", ".upper_0.95"), pattern = "[{1}, {2}]") %>% 
    cols_merge(vars(".lower_0.89", ".upper_0.89"), pattern = "[{1}, {2}]") %>% 
    cols_label(
        .variable = md("Predictor"),
        .value_0.95 = md("Mean"),
        .lower_0.95 = md("95\\% *CrI*"),
        .lower_0.89 = md("89\\% *CrI*")
    ) %>% 
    tab_footnote(
        footnote = "Transformed using the inverse logit to get the average probability of correct response",
        locations = cells_body(
            columns = ".variable", 
            rows = grepl("Intercept", .variable)
        ) 
    ) %>% 
    tab_footnote(
        footnote = "Transformed using the divide-by-four rule to get the maximum change in probability of correct response, associated with a unit increase in this variable.",
        locations = cells_body(
            columns = ".variable",
            rows = !grepl("Intercept", .variable)
        )
    )  %>% 
    tab_style(
        cell_text(weight = "bold"),
        cells_column_labels(columns = everything())
    ) %>% 
    tab_header(title = "Model fixed coefficients", subtitle = "Posterior distribution") %>% 
    tab_style(
        cell_text(align = "left"),
        list(cells_body(), cells_column_labels(columns = everything()))
    )
```

The extended model--which included all main effects and interactions--fitted data the best: it showed the smallest absolute expected log predictive density. This estimate is several times larger than its standard error indicating high predictive accuracy. Table 3 summarises the LOO scores of the fitted models. In the next sections we report the fixed effects of the comprehension and production models separately. We report the mean of each coefficient's posterior distribution along with standard errors and 95% credible intervals (CrI) in Tables 4 and 5. For interpretability, we report the derivative of the logistic function for each coefficient^[The derivative is calculated as $\hat{\beta_j}/4$, where $\hat{\beta_j}$ is the estimated mean of the posterior distribution of coefficient $j$. This value corresponds to the slope of the logistic curve at the midpoint, where it is steepest.] for each coefficient, which indicates the maximum difference in probability corresponding to one unit different in the input variable [@gelman2020regression]. 

```{r loo_prod, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, fig.width=7, fig.cap="Leave-one-out cross-validation. The expected log predictive density (*ELPD*) indicates the sum of the likelihood of each observation, given the model when fitted without such obervation. Values close to 0 indicate that the model fits data better. Standard errors (*SE*) indicate the uncertainty around the computed ELPD in each model. A small *SE* (in realtion to the magnitde of the *ELPD* indicates less uncertainty around the ELPD estimate.", eval=FALSE}
l_comp <- loo_comp %>% 
    as_tibble() %>% 
    select(-matches("p_loo|looic")) %>% 
    mutate_all(as.numeric) %>% 
    mutate(
        type = "Comprehension",
        model = paste0("Model ", 2:0)
    ) %>% 
    relocate(model, type, matches("elpd_loo"), matches("diff")) 


l_prod <- loo_prod %>% 
    as_tibble() %>% 
    select(-matches("p_loo|looic")) %>% 
    mutate_all(as.numeric) %>% 
    mutate(
        type = "Production",
        model = paste0("Model ", 2:0)
    ) %>% 
    relocate(model, type, matches("elpd_loo"), matches("diff")) 


l <- bind_rows(l_comp, l_prod) %>% 
    mutate_all(function(x) ifelse(x==0, NA, x))

t <- gt(l, groupname_col = "type") %>% 
    tab_spanner(md("**ELPD**"), matches("elpd_loo")) %>% 
    tab_spanner(md("**Diff.**"), matches("diff")) %>%
    fmt_number(2:7) %>% 
    fmt_missing(columns = everything(), missing_text = "-") %>% 
    cols_label(
        model = "Model",
        # elpd
        elpd_loo = md("*ELPD*"),
        se_elpd_loo = md("*SE*"),
        subsampling_se_elpd_loo = md("*SE* (sub)"),
        # diff
        elpd_diff = md("*diff*"),
        se_diff = md("*SE*"),
        subsampling_se_diff = md("*SE* (sub)"),
    )
```


## Comprehension

The average probability of participants understanding a TE was `r printnum(inv_logit_scaled(coef_comp["Intercept", "Estimate"])*100)`% (intercept) when all predictors were equal to 0: mean participant age (`r printnum(mean(responses$age))` months), mean item lexical frequency (`r printnum(mean(responses$frequency))`, Zipf score), mean participant DoE (`r printnum(mean(responses$doe)*10)`%), and regardless of its cognate status (average across the three levels). An increase in one month of age was associated with a `r printnum(coef_comp["age", "Estimate"]*100/4)`% increment in comprehension probability. A one standard deviation increase in lexical frequency (1 *SD* = `r printnum(sd(responses$frequency))` Zipf scores) was associated with a `r printnum(coef_comp["frequency", "Estimate"]*100/4)`% increment in comprehension probability. A 10% increase in relative language exposure made TEs `r printnum(abs(coef_comp["doe_center", "Estimate"]*100/4))`% less likely to be understood. Cognates (identical and non-identical) were `r printnum(coef_comp["cognate1", "Estimate"]*100/4)`% more like to be understood than non-cognates. The 95% credible interval of the `doe_center:cognate1` interaction excluded 0 and covered negative values, indicating that for every 10% increment in DoE, the difference in comprehension probability between cognates and non-cognates decreased in `r printnum(abs(coef_comp["doe_center:cognate1", "Estimate"]*100/4))`%. Identical cognates were `r printnum(abs(coef_comp["cognate2", "Estimate"]*100/4))`% less like to be understood than non-identical cognates. The 95% credible interval of the `doe_center:cognate2` interaction excluded 0 (although its lower bound was near zero), and covered only negative values, indicating that for every 10% increase in DoE, the difference in comprehension probability between identical cognates and non-identical cognates decreased in `r printnum(abs(coef_comp["doe_center:cognate2", "Estimate"]*100/4))`%. Figure 1 summarises the posterior distribution of the fixed effects of the model.


```{r results-fixed, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Point estimate (mean) and credible interval (95\\%) of the posterior distribution of the coefficients of the fixed effects of the best fitting model for comprehension and production. Points and error bars in indicate the posterior means, and 50% and 95% CrI. The intercept has been transformed using the inverse logit to get the average probability of correct response. The rest of the coefficients has been transformed using the divide-by-four- rule to get the maximum change in probability of correct response, associated with a unit increase in this variable."}
c_comp <- fixef(fits_comp$fit_2) %>% 
    as.data.frame() %>%
    rownames_to_column("term") %>% 
    clean_names() %>% 
    mutate(
        estimate = ifelse(term=="Intercept", inv_logit_scaled(estimate), estimate/4),
        q2_5 = ifelse(term=="Intercept", inv_logit_scaled(q2_5), q2_5/4),
        q97_5 = ifelse(term=="Intercept", inv_logit_scaled(q97_5), q97_5/4),
        est_error = ifelse(term=="Intercept", inv_logit_scaled(est_error), est_error/4)
    ) %>% 
    rename_at(vars(-matches("term")), ~paste0("comp_", .)) %>% 
    select(-any_of(c("rhat", "bulk_ess", "tail_ess")))

c_prod <- fixef(fits_prod$fit_2) %>% 
    as.data.frame() %>%
    rownames_to_column("term") %>% 
    clean_names() %>% 
    mutate(
        estimate = ifelse(term=="Intercept", inv_logit_scaled(estimate), estimate/4),
        q2_5 = ifelse(term=="Intercept", inv_logit_scaled(q2_5), q2_5/4),
        q97_5 = ifelse(term=="Intercept", inv_logit_scaled(q97_5), q97_5/4),
        est_error = ifelse(term=="Intercept", inv_logit_scaled(est_error), est_error/4)
    ) %>% 
    rename_at(vars(-matches("term")), ~paste0("prod_", .)) %>% 
    select(-term, -one_of(c("term", "rhat", "bulk_ess", "tail_ess")))

c <- bind_cols(c_comp, c_prod) 

t <- gt(c) %>% 
    fmt_percent(matches("estimate|error")) %>% 
    fmt_percent(matches("_q")) %>% 
    tab_spanner("Comprehension", matches("comp_")) %>% 
    tab_spanner("Production", matches("prod_")) %>% 
    cols_merge(vars("comp_q2_5", "comp_q97_5"), pattern = "[{1}, {2}]") %>% 
    cols_merge(vars("prod_q2_5", "prod_q97_5"), pattern = "[{1}, {2}]") %>%
    cols_label(
        term = md("**Predictor**"),
        comp_estimate = md("**Mean**"),
        comp_est_error = md("**SE**"),
        comp_q2_5 = md("**95\\% CrI**"),
        comp_q2_5 = md("**95\\% CrI**"),
        prod_q2_5 = md("**95\\% CrI**"),
        prod_estimate = md("**Mean**"),
        prod_est_error = md("**SE**"),
        prod_q2_5 = md("**95\\% CrI**")
    ) %>% 
    tab_footnote(
        footnote = "Transformed using the inverse logit to get the average probability of correct response",
        locations = cells_body(columns = "term", rows = term=="Intercept")
    ) %>% 
    tab_footnote(
        footnote = "Transformed using the divide-by-four- rule to get the maximum change in probability of correct response, associated with a unit increase in this variable.",
        locations = cells_body(columns = "term", rows = term %in% c("age_center", "frequency_center", "doe_center", "cognate1", "cognate2", "doe_center:cognate1"))
    ) %>% 
    cols_align(
        align = c("left"),
        columns = 2:4
    )
gtsave(t, here("Figures/fix_effects.png"))
```



## Production

The average probability of participants understanding a TE was `r printnum(inv_logit_scaled(coef_prod["Intercept", "Estimate"])*100)`% (intercept) when all predictors were equal to 0. An increase in one month of age was associated with a `r printnum(coef_prod["age_center", "Estimate"]*100/4)`% increment in production probability. A one standard deviation increase in lexical frequency (1 *SD* = `r printnum(sd(responses$frequency))` Zipf scores) was associated with a `r printnum(coef_prod["frequency", "Estimate"]*100/4)`% increment in production probability. A 10% increase in relative language degree of exposure  made TEs `r printnum(coef_prod["doe_center", "Estimate"]*100/4)`% less likely to be produced. Cognates (identical and non-identical) were `r printnum(coef_prod["cognate1", "Estimate"]*100/4)`% more like to be produced than non-cognates. The `doe_center:cognate1` interaction (whose posterior 95% CrI did not exclude 0) indicated that the size of this effect decreased in `r printnum(abs(coef_comp["cognate1", "Estimate"]*100/4))`% for every 10% increment in language degree of exposure. Identical cognates were `r printnum(abs(coef_prod["cognate2", "Estimate"]*100/4))`% less likely to be produced than non-identical cognates. The `doe_center:cognate1` interaction (whose posterior 95% CrI did not excdude 0 either) indicated that the size of this effect decreased in `r printnum(abs(coef_comp["doe_center:cognate2", "Estimate"]*100/4))`% for every 10% increment in language degree of exposure.


```{r emmeans, message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=6, fig.width=8, fig.cap="Expected marginal mean and 95% credible interval of the posterior probability of comprehension and production for identical cognates, non-identical cognates, and non cognates, plotted separately for three levels of degree of exposue to the language: 0% (no exposure, monolingual), 50% (exposed half of the time, balanced bilingual), and 100% (exposed all of the time, monolingual). Dots represent the mean, and error bars represent the range of values within the true values is contained with 50% (thick line) and 95% (thin line) cprobability, given the data."}
nd <- expand.grid(
    age_center = floor(seq(min(responses$age_center), max(responses$age_center), 0.5)),
    doe_center = c(min(responses$doe_center), mean(responses$doe_center), max(responses$doe_center)),
    cognate = unique(items$cognate),
    frequency_center = 0
)

# comprehension
m_comp <- epred_draws(fits_comp$fit_2, newdata = nd, ndraws = 50, re_formula = NA) %>% 
    mutate(
        frequency_center = as.factor(paste0("Frequency = ", frequency_center, " SD")),
        doe_center = factor(doe_center, levels = unique(nd$doe_center), labels = c("DoE: 0%", "Doe: 50%", "DoE: 100%")),
        cognate = factor(cognate, levels = c("Identical cognate", "Non-identical cognate", "Non-cognate"))
    )
m_comp_ci <- mean_qi(m_comp)

# production
m_prod <- epred_draws(fits_prod$fit_2, newdata = nd, ndraws = 50, re_formula = NA) %>% 
    mutate(
        frequency_center = as.factor(paste0("Frequency = ", frequency_center, " SD")),
        doe_center = factor(doe_center, levels = unique(nd$doe_center), labels = c("DoE: 0%", "Doe: 50%", "DoE: 100%")),
        cognate = factor(cognate, levels = c("Identical cognate", "Non-identical cognate", "Non-cognate"))
    )
m_prod_ci <- mean_qi(m_prod)

# join datasets
m <- bind_rows(m_comp, m_prod, .id = "type") %>% 
    mutate(
        type = ifelse(type==1, "Comprehension", "Production"),
        age_center = age_center+mean(responses$age)
    )

m_ci <- bind_rows(m_comp_ci, m_prod_ci, .id = "type") %>% 
    mutate(
        type = ifelse(type==1, "Comprehension", "Production"),
        age_center = age_center+mean(responses$age)
    )



ggplot(m, aes(age_center, .epred, colour = cognate, fill = cognate, shape = cognate)) +
    facet_grid(type~doe_center) +
    # geom_line(aes(group = interaction(.draw, cognate), colour = cognate), alpha = 0.25, size = 0.2,
    #           show.legend = FALSE) +
    # stat_lineribbon(size = 0, alpha = 0.5, .width = 0.95) +
    geom_hline(yintercept = 0.5, colour = "grey") +
    geom_vline(xintercept = mean(responses$age), colour = "grey") +
    
    geom_errorbar(data = m_ci, aes(ymin = .lower, ymax = .upper), width = 0.5, size = 0.25) +
    stat_summary(fun = "mean", geom = "line", size = 0.75) +
    # stat_pointinterval(.width = 0.95, position = position_dodge(width = 0.5), size = 0.75, point_size = 2) +
    scale_y_continuous(labels = scales::percent, breaks = seq(0, 1, 0.25)) +
    scale_x_continuous(labels = floor, breaks = floor(seq(min(responses$age), max(responses$age), by = 2))) +
    labs(
        x = "Age (months)", y = "Posterior probability",
        colour = "Cognateness", fill = "Cognateness", shape = "DoE"
    ) +
    theme(
        legend.position = "top",
        axis.text.x = element_text(size = 8),
        panel.grid.major.y = element_line(colour = "grey", linetype = "dotted"),
        legend.title = element_blank(),
    )




```




# Discussion

# References


\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>

\endgroup


```{r create_r-references, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

r_refs(file = "manuscript.bib")

```

