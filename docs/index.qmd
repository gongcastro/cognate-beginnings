---
title: "Cognate beginnings to bilingual lexical acquisition"
subtitle: "Lab notes"
short-title: "Cognate beginnings"
author:
  - name: Gonzalo Garcia-Castro
    corresponding: true
    orcid: 0000-0002-8553-4209
    email: gonzalo.garciadecastro@upf.edu
    affiliations:
      - id: cbc
        name: Universitat Pompeu Fabra
        department: Center for Brain and Cognition
        address: Ramon Trias Fargas 25-27
        city: Barcelona
        region: Spain
        postal-code: "08005"
  - name: Daniela S. Avila-Varela
    orcid: 0000-0002-3518-8117
    affiliations: 
      - ref: cbc
      - id: ul
        name: Universidade de Lisboa
        department: Facultade de Letras
        address: Alameda da Universidade
        city: Lisboa
        region: Portugal
        postal-code: "1600-214"
  - name: Ignacio Castillejo
    orcid: 0000-0001-7445-0416
    affiliations: 
      - id: uam 
        name: Universidad Autónoma de Madrid
        department: Departamento de Psicología
        address: Iván Pavlov, 6
        city: Madrid
        region: Spain
        postal-code: "28049"
  - name: Núria Sebastian-Galles
    orcid: 0000-0001-6938-2498
    affiliations: 
      - ref: cbc
date: "May 10th, 2023"
code-repo: "Access the code, data, and analysis at <https://github.com/gongcastro/trajectories>"
keywords:
  - lexical acquisition
  - vocabulary
  - bilingualism
  - item response theory
  - bayesian
csl: "../assets/apa7.csl"
bibliography: "../assets/references.bib"
link-citations: true
editor: source

code-fold: true
warning: false

format:
  html: default

abstract: |
    Language non-selectivity is prominent feature of bilingual lexical processing. An instance of such non-selectivity is embodied by cognateness, which recent studies have suggested to facilitate vocabulary acquisition in bilingual toddlers, who show larger vocabulary sizes when their languages share many cognates, and to be acquired at earlier ages than non-cognates. The specific mechanisms behind such facilitation are unclear. We present an account of early bilingual vocabulary growth in which cognateness interacts with lexical frequency and language exposure to facilitate the word acquisition. We evaluated this model against vocabulary data from 436 Catalan-Spanish bilinguals toddlers. We used Bayesian Explanatory Item Response Models to estimate participants’ probability of acquisition of 604 words, conditional to the cognate status and lexical frequency of the word-form, and the age and degree of exposure to each language of the toddler. We found cognateness facilitation effect only in low-frequency words. Overall, our findings support an interactive account of bilingual vocabulary acquisition in which the lexical representations in one language interact with the acquisition of words in the other language.

fig-dpi: 1000

---

```{r setup}
#| label: setup
#| message: false
#| warning: false
# load objects -----------------------------------------------------------------

library(patchwork)
library(gt)
library(ggplot2)

targets::tar_config_set(store = here::here("_targets"),
                        script = here::here("_targets.R"))

targets::tar_load_globals()

targets::tar_load(c(bvq_data, childes, items, 
                    participants, responses))

targets::tar_load(c(model_fit, model_summary, model_epreds,
                    model_convergence, model_fit_prior, 
                    model_ppcs, posterior_doe_summary,
                    model_draws, model_summary,
                    posterior_doe_draws))

targets::tar_load(c(syllables_data, model_fit_syllables, post_syllables))

# process objects
items <- bvq_data$pool  |>  
    mutate(item = str_remove(item, "cat_|spa_")) |> 
    select(item, language, semantic_category, class) |> 
    right_join(items, by = c("item", "language"))

rope_interval <- c(lower = -0.1, upper = 0.1)

# set ggplot theme and colour palette ------------------------------------------

my_theme <- theme_minimal() +
    theme(panel.grid = element_line(colour = "grey",
                                    linetype = "dotted"),
          axis.line = element_line(colour = "black"),
          text = element_text(size = 12, colour = "black"),
          axis.text = element_text(colour = "black"))

theme_set(my_theme)

bayesplot::bayesplot_theme_set(my_theme + theme(panel.grid = element_blank()))

clrs <- c("#003f5c", "#58508d", "#bc5090", "#ff6361", "#ffa600")

set.seed(888)

options(ggplot2.ordinal.fill = clrs,
        ggplot2.ordinal.colour = clrs,
        ggplot2.discrete.fill = clrs,
        ggplot2.discrete.colour = clrs,
        ggplot2.continuous.fill = scale_color_gradient,
        ggplot2.continuous.colour = scale_color_gradient,
        knitr.graphics.error = FALSE) 
```


# Methods

::: {.callout-tip}
Data and materials are available at [OSF](https://osf.io/hy984/), and code is available at [GitHub](https://github.com/gongcastro/trajectories).
:::

## Questionnaires

```{r}
#| label: questionnaire
#| message: false
#| warning: false
data("pool", package = "bvq")
n_categories <- distinct(pool, semantic_category) %>% nrow()
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>% 
    pull(n) %>%
    set_names(c("catalan", "spanish"))
```

The questionnaire was implemented on-line using the formR platform [@arslan2020formr], and was structured in three blocks: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000infant] and consisted of two lists of words: one in Catalan and one in Spanish. The Catalan inventory contained `r n_item_language["catalan"]` items and the Spanish inventory contained `r n_item_language["spanish"]` items. Items in one language were translation equivalents of the items in the other language (e.g., whenever *gos* \[dog\] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. When there were two acceptable translation equivalents for a given word, we included both in separate items (e.g., Catalan *acabar* \[*to finish*\] and Spanish *acabar* and *terminar*), or merged them into a single items (e.g., Spanish *mono* \[*monkey*\] and Catalan *mono/mico*. We included items from a diverse sample of `r n_categories` semantic/functional categories (see Appendix 1). For the analyses included in this study, we excluded items from the adverbs, auxiliary words, connectives, interjections and games and routines categories, so that only data from content words (nouns, adjectives, and verbs) were used.

For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand *and* say it, or did not understand or say it (checked out by default). Some families filled a long version of the vocabulary checklists (800 translation equivalents; 800 items in Catalan, 800 items in Spanish), while others filled a shorter version (\~400 translation equivalents, \~400 items in Catalan, \~400 items in Spanish). These last families were randomly assigned to one of four different subsets of the complete list of items. These lists were designed so that each contained a representative subsample of the items from the complete list. Semantic/functional categories with less than 16 items were not divided in the short version of the questionnaire to preserve a minimum of four items per list for each category: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. Table 2 in Appendix 1 shows the distribution of items across questionnaire versions. We excluded from the analysis multi-word items (e.g., *barrita de cereales* \[cereal bar\]) and items that included more than one word-form (e.g., *mono / mico*). Table 3 shows the classification of items in cognates and non-cognates and their lexical frequency scores across the four lists of the inventories.

## Participants

```{r}
#| label: fig-participants-time
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 10 
#| fig-cap: "Date at which responses were collected"
participants %>% 
    group_by(time_stamp) %>% 
    summarise(n = n(), .groups = "drop") %>% 
    mutate(n = cumsum(n)) %>% 
    ggplot(aes(time_stamp, n)) +
    geom_vline(xintercept = ymd("2020-03-15"), size = 0.5) +
    annotate(geom = "text", y = 350, x = ymd("2020-03-15"), label = "COVID-19 lockdown in Spain",
             angle = 90, vjust = 1.5, hjust = 1) +
    geom_line(size = 1, colour = clrs[1]) +
    labs(x = "Date", y = "Number of responses", colour = "Dominant language") +
    scale_y_continuous(breaks = seq(0, 500, 100), limits = c(0, 500)) +
    theme(legend.position = "top",
          legend.title = element_blank(),
          panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 20, hjust = 1),
          axis.title.x = element_blank()) +
    
    participants %>% 
    mutate(age = cut(floor(age), breaks = seq(7, 35, 5))) %>% 
    group_by(time_stamp, age) %>% 
    summarise(n = n(), .groups = "drop") %>% 
    group_by(age) %>% 
    mutate(n = cumsum(n)) %>% 
    ggplot(aes(time_stamp, n, colour = age)) +
    geom_vline(xintercept = ymd("2020-03-15"), size = 0.5) +
    geom_line(size = 1) +
    labs(x = "Date", y = "Number of responses", colour = "Age (months(") +
    scale_y_continuous(breaks = seq(0, 500, 50)) +
    scale_colour_manual(values = clrs) +
    
    plot_layout(ncol = 1) &
    
    scale_x_date(date_breaks = "3 month", date_labels = "%B %Y") &
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 20, hjust = 1),
        axis.title.x = element_blank(),
    )
```

### Age

Number of months elapsed between participants' birth date and questionnaire completion.

```{r}
#| label: fig-participants-age
#| fig-width: 7
#| fig-height: 3
#| fig-cap: "Distribution of participants' ages"
participants %>% 
    mutate(age = floor(age)) %>% 
    count(age) %>% 
    ggplot() +
    aes(x = age, y = n) +
    geom_col(fill = "grey60") +
    geom_text(aes(label = n), size = 3.5, vjust = -1) +
    labs(x = "Age (months)",
         y = "# participants") +
    scale_x_continuous(breaks = seq(0, 40, 2)) +
    scale_y_continuous(limits = c(0, 55),
                       breaks = seq(0, 55, 10)) +
    theme(
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()
    )
```

### Language exposure (Degree of Exposure)

Participant degree of exposure to the words' language ($DoE$): percentage of exposure to the language the word belonged to. For example, for a participant with 90% exposure to Catalan, and 10% to Spanish, the DoE of the Catalan word *taula* would be 90%, and the DoE for the Spanish word *mesa* would be 10%.

```{r fig-participants}
#| label: tab-participants
#| message: false
#| warning: false
#| tbl-cap: "Participant sample size by age and degree of exposure to Catalan. Information about language degree of exposure (DoE) was provided by families before filling the questionnaire. In this table, a 100\\% indicates that the participant was exclusively exposed to Catalan, and never to Spanish. A 0\\% indicates that the participant was not exposed to Catalan ever, and most of the time to Spanish. A 50\\% indicates that the participant was exposed to Catalan and Spanish approximately half of the time each. The 100\\%, 0\\%, and 50\\% would be traditionaly classified as Catalan monolingual, Spanish monolingual, and Catalan-Spanish bilingual, respectively. For illustration purposes this table, DoEs were binned into 25\\%-wide bins, and ages (in months) binned into 4 month-wide bins. Hyphens indicate that no participants from that specific combination of age and DoE filled the questionnaire."
participants |>
    mutate_at(vars(starts_with("doe_")), 
              (\(x) floor(x * 10) / 10)) |> 
    mutate(
        age = cut(floor(age),
                  c(10, 14, 18, 22, 26, 30, 34, 36),
                  include.lowest = TRUE),
        doe_catalan = cut(
            doe_catalan,
            c(0, 0.25, 0.5, 0.75, 1),
            labels = c("0-25%",
                       "25-50%", 
                       "50-75%",
                       "75-100%"),
            include.lowest = TRUE
        ) |>
            as.character()
    ) |>
    count(age, doe_catalan) |>
    arrange(desc(doe_catalan)) |>
    pivot_wider(names_from = age, values_from = n) |>
    gt() |>
    sub_missing(everything(), everything(), missing_text = "--") |>
    cols_label(doe_catalan = "Catalan exposure") |>
    tab_spanner("Age (months)", 2:7) |>
    tab_style(cell_text(align = "left"),
              list(cells_body(doe_catalan),
                   cells_column_labels(doe_catalan)))
```

### SES/parental education

```{r}
#| label: tbl-participants-edu
#| tbl-cap: "Participant exposure to the language (DoE) and socio-economic status (SES)."
participants %>%
    mutate(id = as.character(id)) |> 
    left_join(bvq_data$logs,
              by = join_by(id, time, age, lp, doe_catalan, doe_spanish, edu_parent)) %>%
    mutate(
        edu_parent = edu_parent |> 
            as.factor() |> 
            fct_na_value_to_level(),
        doe_catalan = cut(doe_catalan,
                          breaks = seq(0, 1, 0.2),
                          include.lowest = TRUE)
    ) %>%
    count(doe_catalan, edu_parent) %>%
    right_join(
        expand_grid(
            doe_catalan = levels(.$doe_catalan),
            edu_parent = unique(bvq_data$logs$edu_parent)
        ),
        by = join_by(doe_catalan, edu_parent)
    ) %>%
    rename(total = n) %>%
    pivot_wider(names_from = edu_parent,
                values_from = total,
                values_fill = 0) %>%
    mutate(total = rowSums(cbind(.[,3:8]), na.rm = TRUE)) %>%
    rename(Total = total) %>%
    select(-"NA") %>%
    gt() |> 
    cols_label(doe_catalan = "DoE Catalan") %>%
    sub_missing(columns = everything(),
                missing_text = "--") %>%
    tab_spanner("Educational attainment", 
                Secondary:Primary) %>%
    tab_style(
        style = list(cell_borders(weight = px(2),
                                  sides = "left", 
                                  color = "grey50")),
        locations = cells_body(columns = 8,
                               rows = 1:5)
    ) %>%
    tab_style(
        cell_text(style = "italic"),
        cells_column_labels(columns = 2:7)
    ) %>%
    tab_style(
        cell_text(weight = "bold"),
        cells_column_labels(columns = c(1, 8))
    ) %>%
    tab_style(
        cell_text(weight = "bold"),
        cells_column_spanners(spanners = "Educational attainment")
    )
```

## Items


```{r}
#| label: tbl-items-summary
#| tbl-cap: "Lexical frequencies. Mean, standard error, and 95% confidence interval of lexical frequencies of items included in the Catalan and Spanish lists, reported separately for identical cognates, non-identical cognates, and non-cognates."
items <- left_join(items, select(bvq_data$pool, te, item, language, class, semantic_category))

items %>%
    unnest(list) %>%
    summarise(n = n(),
              across(c(freq, n_phon, lv),
                     lst(mean, sd, min, max)),
              .by = c(language, list)) |> 
    gt(groupname_col = "language", 
       rowname_col = "list") %>%
    fmt_number(-c(list, n),
               decimals = 1) %>%
    tab_spanner("Frequency (Zipf)",
                columns = starts_with("freq_")) %>%
    tab_spanner("Length (Phonemes)",
                columns = starts_with("n_phon_")) %>%
    tab_spanner("Levenshtein (cognateness)", 
                columns = starts_with("lv_")) %>%
    cols_merge_uncert(col_val = freq_mean,
                      col_uncert = freq_sd) %>%
    cols_merge_uncert(col_val = n_phon_mean,
                      col_uncert = n_phon_sd) %>%
    cols_merge_uncert(col_val = lv_mean, 
                      col_uncert = lv_sd) %>%
    cols_merge_range(col_begin = freq_min, 
                     col_end = freq_max) %>%
    cols_merge_range(col_begin = n_phon_min, 
                     col_end = n_phon_max) %>%
    cols_merge_range(col_begin = lv_min,
                     col_end = lv_max) %>%
    cols_label(list = "",
               n = md("*N*"),
               freq_mean = md("Mean ± SD"),
               freq_min = md("Range"),
               n_phon_mean = md("Mean ± SD"),
               n_phon_min = md("Range"),
               lv_mean = md("Mean ± SD"),
               lv_min = md("Range")) %>%
    tab_style(cell_text(style = "italic"),
              cells_column_labels(everything())) %>%
    tab_style(cell_text(weight = "bold"),
              cells_column_spanners(everything()))
```

### Lexical frequency

Word lexical frequency ($Frequency$): lexical frequency of the word in its corresponding language, expressed as Zipf scores [@van2014subtlex; @zipf1949human]. This variable ranges from 0 to 7, and follows and approximates a normal distribution, with most values in a corpus ranging from 3 to 5 points. Lexical frequencies were extracted from the English corpora of the [CHILDES](https://childes.talkbank.org/) database using the [{childesr}](https://langcog.github.io/childes-db-website/) R package. Available words in the corpora were then mapped to their Catalan and Spanish translations. Therefore, the Catalan and Spanish word-forms of the same translation equivalent had the same value for lexical frequency. Responses to words with missing lexical frequencies were excluded from analyses of the total number of items). 


```{r}
#| label: fig-items-freq
#| message: false
#| warning: false
#| fig-width: 6
#| fig-height: 3
#| fig-cap: "Distribution of lexical frequency across items. Lexical frequencies were extracted from the English CHILDES corpora, and mapped to their Catalan and Spanish translations. Therefore Catalan and Spanish word-forms that belong to the same translation equivalent had the same lexical frequency. The black dot and interval indicate the mean and standard deviation."
mean_sd <- function(x, ...) {
    m <- mean(x, ...)
    s <- sd(x, ...)
    data.frame(mean = m, ymin = m-s, ymax = m+s)
}

items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    ggplot(aes(x = freq)) +
    geom_histogram(fill = "grey60",
                   colour = "white",
                   bins = 30)  +
    labs(x = "Lexical frequency (Zipf score)", y = "Number of words") +
    theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        legend.title = element_blank()
    )
```

### Word length

Word length ($Length$), computed as the number of phonemes in the phonological transcription of the word-form in [SAMPA](https://en.wikipedia.org/wiki/SAMPA) format.


```{r}
#| label: fig-items-nphon
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Distribution of number of phonemes across items"
items %>%
    count(language, n_phon) %>%
    ggplot(aes(x = n_phon, y = n)) +
    facet_wrap(~language, ncol = 1) +
    geom_col(fill = "grey60", colour = "white") +
    geom_text(aes(label = n),
              position = position_nudge(y = 5),
              colour = "black") +
    labs(x = "Phonemes",
         y = "Number of words",
         fill = "Language",
         shape = "Language",
         colour = "Language") +
    scale_x_continuous(breaks = 1:15) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    theme(legend.position = "none",
          panel.grid.major.x = element_blank(),
          panel.grid.minor = element_blank(),
          axis.ticks.x = element_line(),
          legend.title = element_blank())
```

### Levenshtein (cognateness)

Phonological similarity between translation equivalents was computed as the normalised Levenshtein similarity between the word-form and its translation in the other language [@levenshtein1966binary]. This score is calculated by first calculating the Levenshtein distance between the two transcriptions (number of insertions, deletions or replacements needed for the shortest transcription to become identical to the longer transcription), then dividing the resulting value by the length of the longest transcription, and finally subtracting this value from 1. This results in a proportion that indicates how much the two phonological transcriptions of the translation equivalent are similar to each other, ranging from 0% (no similarity at all) to 100% (both transcriptions are identical) [see @floccia2018vocabulary; @fourtassi2020growth; @laing2022phonological for similar approaches]. 

```{r}
#| label: fig-items-lv
#| message: false
#| warning: false
#| fig-width: 9
#| fig-cap: "Distribution of Levenshtein similarities across items"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    mutate(lv = cut(lv, breaks = seq(0, 1, 0.1), include.lowest = TRUE)) %>% 
    count(lv) %>% 
    mutate(prop = n/sum(n),
           labels = paste0(
               n, " (",
               scales::percent(prop, accuracy = 0.1), 
               ")")) %>% 
    ggplot(aes(x = lv, n)) +
    geom_col(fill = "grey60", colour = "white") +
    geom_text(aes(label = labels),
              position = position_nudge(y = 3), 
              size = 3.5) +
    labs(x = "Levenshtein distance", y = "Number of words") +
    theme(
        panel.grid.major.x = element_blank(),
        legend.position = "top"
    )
```

### Frequency by word length

```{r}
#| label: fig-items-frequency-phonemes
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 4
#| fig-cap: "Association betwen number of lexical frequency and number of phonemes"
items %>% 
    drop_na(freq) %>% 
    distinct(te, .keep_all = TRUE) %>% 
    count(n_phon, freq) %>% 
    ggplot(aes(n_phon, freq)) +
    geom_point(size = 2,
               alpha = 0.5,
               colour = "grey60", 
               shape = 1, 
               stroke = 1,
               position = position_jitter(width = 0.1)) +
    geom_smooth(method = "lm",
                formula = "y ~ x" ,
                colour = "black") +
    labs(
        x = "# Phonemes", 
        y = "Lexical frequency (Zipf score)", 
        colour = "Language", 
        fill = "Language"
    ) +
    scale_x_continuous(breaks = seq(0, 16, 1)) +
    theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()
    ) 
```

### Frequency by Levenshtein

```{r}
#| label: fig-items-frequency-lv
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Association betwen lexical frequency and phonological similarity"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    drop_na(freq) %>% 
    count(freq, lv) %>% 
    ggplot(aes(freq, lv)) +
    geom_point(size = 2,
               shape = 1, 
               colour = "grey60",
               stroke = 1) +
    geom_smooth(method = "lm", 
                formula = "y ~ x", 
                colour ="black") +
    labs(y = "Levenshtein similarity", 
         x = "Lexical frequency (Zipf score)", 
         colour = "Language", 
         fill = "Language") +
    scale_y_continuous(labels = scales::percent) +
    theme(
        legend.position = "none",
        panel.grid.major.y = element_blank()
    )
```

### Word length by Levenshtein

```{r}
#| label: fig-items-nphon-lv
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Association between number of phonemes and phonological similarity"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    drop_na(freq) %>% 
    count(n_phon, lv) %>% 
    ggplot(aes(n_phon, lv, size = n)) +
    geom_point(shape = 1,
               stroke = 1,
               colour = "grey60") +
    geom_smooth(method = "lm",
                formula = "y ~ x",
                size = 1,
                colour = "black") +
    labs(x = "# Phonemes", 
         y = "Levenshtein similarity", 
         colour = "Language", 
         fill = "Language") +
    scale_y_continuous(labels = scales::percent) +
    scale_x_continuous(breaks = seq(0, 16, 1)) +
    theme(legend.position = "none",
          panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank()) 
```


### Word exposure index by lexical frequency

We created a predictor ($Exposure$) to account for the exposure rate of each child to each of the words their parents responded to, weighted by the child's exposure to the language the word belongs to. the exposure of the $i$-th child to the $j$-th word measure is the product of the lexical frequency of the word (Zipf score) and the child’s degree of exposure to the corresponding language (a proportion) (see @eq-exposure).

$$
\textbf{Exposure}_{ij} = \textbf{Frequency}_i \times \textbf{DoE}_{j}
$$ {#eq-exposure}

For instance, for a child who is reportedly exposure to Catalan 80% of the time, and to Spanish 20% of the time, the expected exposure to the word *cavall* (horse, in Catalan, with a lexical frequency of `r round(items$freq[items$item=="cat_cavall"], 2)`) would be `r round(items$freq[items$item=="cat_cavall"]*0.80, 2)`, while that of its translation to Spanish *caballo* would be `r round(items$freq[items$item=="cat_cavall"]*0.20, 2)` (see @eq-exposure-example):

$$
\begin{aligned}
\textbf{Exposure}_{\textbf{cavall, Catalan}} &= \textbf{Frequency}_{cavall} \times \textbf{DoE}_{Catalan} = 6.14 \times 0.8 = 4.91 \\
\textbf{Exposure}_{\textbf{caballo, Spanish}} &= \textbf{Frequency}_{caballo} \times \textbf{DoE}_{Spanish} = 6.14 \times 0.2 = 1.23
\end{aligned}
$$ {#eq-exposure-example}

```{r}
#| label: fig-exposure-distribution
#| fig-cap: "Relationship between lexical frequency and language exposure-weighted lexical frequency"
#| warnings: false
#| fig-height: 7
#| fig-width: 13
responses %>%
    mutate(
        exposure = cut(exposure,
                       breaks = seq(0, 9, 1),
                       include.lowest = TRUE)) %>%
    count(exposure, language) %>%
    ggplot(aes(exposure, n)) +
    facet_wrap( ~ language) +
    geom_col(colour = "white",
             fill = "grey60") +
    labs(x = "Exposure-weighted frequency\n(Frequency \u00d7 DoE)",
         y = "Number of observations",
         fill = "Language") +
    
    responses %>%
    mutate(exposure = cut(exposure,
                          breaks = seq(0, 9, 1),
                          include.lowest = TRUE),
           freq = cut(freq, 
                      breaks = seq(0, 9, 0.25), 
                      include.lowest = TRUE)) %>%
    count(exposure, freq, language) %>%
    ggplot(aes(x = freq,
               y = exposure,
               size = n)) +
    facet_wrap( ~ language) +
    geom_point(colour = "grey60",
               alpha = 1/2) +
    labs(x = "Frequency (Zipf score)",
         y = "Exposure-weighted frequency\\
         (Frequency \u00d7 DoE)",
         colour = "Language",
         fill = "Language",
         size = "Number of observations") +
    theme(panel.grid = element_blank()) +
    plot_layout(ncol = 1) &
    scale_colour_manual(values = clrs[c(1, 4)]) &
    scale_fill_manual(values = clrs[c(1, 4)]) &
    guides(fill = "none", colour = "none") &
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.y = element_blank(),
          legend.position = "none")
```


## Data analysis

We used multilevel ordinal regression to model the cumulative probability of a *No* response, a *Understands* response, or a *Understands and Says* response [@burkner2019ordinal] using the *logit* link function. The likelihood of the cumulative probability distribution of the responses is defined by @eq-likelihood (see @fig-likelihood for a graphical representation). 


$$
\begin{aligned}
\textbf{Likelihood:} \\
y_{ij} &\sim \text{Cumulative}(p_{k})
\end{aligned}
$$ {#eq-likelihood}


where:

- $y$ is an observed response ($y \in \{\text{No, Understands, Understands and Says}\}$)
- $i$ is the participant index
- $j$ is the translation equivalent (TE) index
- $p_{k}$ is a probability ($p \in (0, 1)$) that indicates the threshold $k$ ($k \in (1, 2)$)) between two response categories in the latent distribution
$p_{k}$ is then estimated using a logit regression model as indicated in @eq-linear.


```{r}
#| label: fig-likelihood
#| fig-cap: "Graphical representation of the assumed latent distribution that generates observed responses in the questionnaire. Cumulative ordinal regression assumes that observed categorical responses (*No*, *Understands* and *Understands and Says* are generated from a common latent (i.e., unobserved) distribution. For threotical reasons, we refer to the dimension captured by such distribution as *Familiarity*. *Familiarity* describes a given participant's familiarity with a given word. When familiarity is low (below some threshold 1), the reulting response is *No*. When familiarity is higher than such threshold 1, but lower than some threshold 2, the resulting result is *Understands* (i.e., comprehension). When familiarity exceeds threshold 2, the resulting response is *Understands and Says* (i.e., comprehension and production). These thresholds are estimated in the cumulative regression model as intercepts 1, and 2. The rest of the coefficients in the regression model shift the response thresholds, making comprehension or production more likely or less likely. See @burkner2019ordinal for a detailed description of cumulative ordinal regression and its implementation."
#| fig-width: 7
#| fig-height: 3.5
dist_df <- tribble(~mean, ~sd, 0,   1)

thresholds <- data.frame(
    ymin = c(-Inf, -1.5, 1.5),
    ymax = c(-1.5, 1.5, Inf),
    xmin = -Inf,
    xmax = Inf,
    .category = str_wrap(c(
        "No", 
        "Understands",
        "Understands and Says"
    ),
    width = 12)
)

thresholds %>%
    ggplot(aes(ymin = ymin, ymax = ymax,
               xmin = xmin, xmax = xmax,
               fill = .category)) +
    geom_rect(alpha = 0.5) +
    stat_dist_slab(
        data = dist_df, 
        aes(dist = "norm", arg1 = mean, arg2 = sd),
        position = "dodge", inherit.aes = FALSE,
        fill = NA, colour = "black"
    ) +
    geom_hline(yintercept = c(-1.5, 1.5), 
               linetype = "dotted",
               linewidth = 1) +
    geom_text(aes(label = .category, y = c(-3, 0, 3), x = 1),
              vjust = 1, hjust = 0.5) +
    annotate(
        geom = "text",
        label = c("Threshold~1~(p[1])", "Threshold~2~(p[2])"),
        y = c(-1.5, 2), parse = TRUE,
        x = 0.5, angle = 90, vjust = -0.5
    ) +
    labs(y = "Hypothetical response-generating latent distribution",
         x = "Response probability",
         fill = "Response type",
         colour = "Response type") +
    coord_flip() +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_x_continuous(labels = scales::percent) +
    scale_y_continuous(limits = c(-4, 4)) +
    theme(panel.grid = element_blank(),
          legend.position = "none")
```


To test our hypotheses, we included several predictors in the regression model as fixed effects: the main effects of participant age ($Age$), number of phonemes ($Phonemes$), word exposure index ($Exposure$), and of phonological similarity ($Levenshtein$), the two-way interactions $Age \times Exposure$, $Age \times Levenshtein$, and $Exposure \times Leveshtein$, and the three-way interaction $Age \times Exposure \times Leveshtein$. We also included crossed random effects for participants and translation equivalents to account for the repeated measures in our dataset--each participant provided responses to multiple translation equivalents, and each translation equivalent was responded to by multiple participants [@gelman2020regression]. For both grouping variables, we included random intercepts, random slopes, and correlation parameters for all predictors were repeated measures were observed in our dataset [@barr2013random, see @eq-linear]. 

$$
\begin{aligned}
\textbf{Linear model:} \\
logit(p_{k}) = \text{ln} \frac{p_{k}}{1-p_{k}} &= (\beta_{0_{k}} + u_{0_{i_{k}}} + w_{0_{j_{k}}}) + \\
& (\beta_{1} + u_{1_{i}} + w_{1_{j}}) · \text{Age}_{i} + & \\
& (\beta_{2} + u_{2_{i}} + w_{2_{j}}) · \text{Phonemes}_{ij} + & \\
& (\beta_{3} + u_{3_{i}} + w_{3_{j}}) · \text{Exposure}_{ij} + & \\
& (\beta_{4} + u_{4_{i}}) · \text{Levenshtein}_{ij} + & \\
& (\beta_{5} + u_{5_{i}} + w_{3_{j}}) · (\text{Age}_{i} \times \text{Exposure}_{ij}) + & \\
& (\beta_{6} + u_{6_{i}}) · (\text{Age}_{i} \times \text{Levenshtein}_{ij}) + & \\
& (\beta_{7} + u_{7_{i}}) · (\text{Exposure}_{ij} \times \text{Levenshtein}_{ij}) & \\
& (\beta_{8} + u_{8_{i}}) · (\text{Age}_{i} \times \text{Exposure}_{ij} \times \text{Levenshtein}_{ij}) & \\
\end{aligned}
$$ {#eq-linear}

where:

- $i$ and $j$ index the participant and translation equivalent (TE)
- $\beta_{0_k}$ is the fixed coefficient of the regression model for the intercept of threshold $k$
- $u_{0_{i}}$ and $w_{0_{j}}$ are the by-participant and by-TE adjustments for $\beta_{0_{k}}$ (i.e., random intercepts), respectively
- $\beta_{1-8}$ are the fixed coefficients of the regression model for the predictors of interest
- $u_{1-8_{i}}$ and $w_{1-3_{j}}$ are the by-participant and by-TE adjustments for$\beta_{1-8}$ (i.e., random slopes), respectively

We used the Bayesian framework to estimate the parameters in our model. This involves using the Bayes theorem to compute a distribution (*posterior distribution*) that describes what values of each parameter in the model are more likely given the data (*likelihood*, see @eq-likelihood), and previous knowledge about such distribution (*prior distribution*, see @eq-prior) [@mcelreath2020statistical]. This posterior distribution not only informs about the most likely values of our regression coefficients of interest, but also about the uncertainty around such estimations. We used a weakly informative prior for our parameters, with the exception of the main effect of $Age$, for which we specified a strongly informative prior based on previous literature about how age affects the acquisition of words [see @eq-prior].

$$
\begin{aligned}
\\
\textbf{Prior:} \\
\beta_{0_{k}} &\sim \mathcal{N}(-0.25, 0.1) & [\mbox{Intercept/response category threshold}] \\
\beta_{1} &\sim \mathcal{N}(1, 0.1) & [\mbox{Age population-level coefficient}]\\
\beta_{2-8} &\sim \mathcal{N}(0, 1) & [\mbox{Rest of population-level coefficients}] \\
u_{0-8_{i}} &\sim \mathcal{N}(0, \sigma_{u_{0-8_{i}}}) & [\mbox{Participant-level coefficient variability}] \\
w_{0-3_{j}} &\sim \mathcal{N}(0, \sigma_{w_{0-3_{j}}}) & [\mbox{TE-level coefficient variability}] \\\\
&&\mbox{[Participant-level coefficient variability]} \\ \\
\Bigg(\begin{smallmatrix}
u_{k_{0}} \\ 
u_{1_{i}} \\ 
\vdots \\ 
u_{8_{i}} 
\end{smallmatrix}\Bigg) &\sim \mathcal{N} 
\Bigg(\Bigg(\begin{smallmatrix}0 \\
0 \\ 
\vdots \\
0\end{smallmatrix}\Bigg), \Sigma_{u}\Bigg) \\
\Sigma_{u} &= \Bigg(\begin{smallmatrix} \\
\rho_{u_{0}} & \rho_{u_{0}} \sigma_{u_{0_{k}}} \sigma_{u_{1}} & \dots & \rho_{u_{0}} \sigma_{u_{0}} \sigma_{w_{8}}\\ 
\rho_{u_{1}} \sigma_{u_{1}} \sigma_{u_{0}} & \rho_{u_{1}} & \dots & \rho_{u_{1}} \sigma_{u_{1}} \sigma_{u_{8}}\\ 
\vdots & \vdots & \vdots & \vdots \\
\rho_{8} \sigma_{u_{8}} \sigma_{u_{0_{k}}} & \dots & \dots & \rho_{u_{8}} \end{smallmatrix}\Bigg) \\
\sigma_{u_{0-8}} &\sim \mathcal{N_{+}}(1, 0.1) \\
\rho_{u} &\sim LKJcorr(2) \\
\\
&&\mbox{[TE-level coefficient variability]} \\ \\
\Bigg(\begin{smallmatrix}
w_{k_{0}}\\ 
w_{1_{j}} \\ 
\vdots \\ 
w_{3_{j}} 
\end{smallmatrix}\Bigg) &\sim \mathcal{N} \Bigg(\Bigg(\begin{smallmatrix}
0\\ 
0 \\ 
\vdots \\
0 
\end{smallmatrix}\Bigg), \Sigma_{w}\Bigg) \\
\Sigma_{w} &= \Bigg(\begin{smallmatrix} \\
\rho_{w_{0}} & \rho_{w_{0}} \sigma_{w_{0_{k}}} \sigma_{w_{1}} & \dots & \rho_{w_{0}} \sigma_{w_{0}} \sigma_{w_{3}}\\ 
\rho_{w_{1}} \sigma_{w_{1}} \sigma_{w_{0}} & \rho_{w_{1}} & \dots & \rho_{w_{1}} \sigma_{w_{1}} \sigma_{w_{3}}\\ 
\vdots & \vdots & \vdots & \vdots \\
\rho_{3} \sigma_{w_{3}} \sigma_{w_{0_{k}}} & \dots & \dots & \rho_{w_{3}} \end{smallmatrix}\Bigg) \\
\sigma_{w_{0-3}} &\sim \mathcal{N_{+}}(1, 0.1) \\
\rho_{w_{0-3}} &\sim LKJcorr(2)
\end{aligned}
$$ {#eq-prior}

where:

- $\rho_{u_{0-8}}$ and $\rho_{w_{0-3}}$ indicate the correlation parameters between the by-participant and by-TE adjustments, respectively
- $\sigma_{u_{0-8}}^2$ and $\sigma_{w_{0-3}}^2$ indicate the variance of the by-participant and by-TE variance of the adjustments, respectively
- $\mathcal{N}$ indicates a normal distribution, $\mathcal{N}_{+}$ indicates a truncated normal distribution with only positive values, and $LKJcorr$ indicates a [LKJ correlation distribution](https://mc-stan.org/docs/2_22/functions-reference/lkj-correlation.html) [@lewandowski2009generating].


::: {.panel-tabset}

#### Prior-predicted mean

```{r fig_prior-mean}
#| label: fig-prior-mean
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 3
#| out-width: 90%
#| fig-cap: "Expected prior-predicted mean."
nd <- expand.grid(n_phon_std = 0,
                  age_std = (10:36-mean(responses$age))/(sd(responses$age)),
                  exposure_std = 0,
                  lv_std = 0)

prior_epreds <- add_epred_draws(nd, 
                                model_fit_prior,
                                ndraws = 50, 
                                re_formula = NA) |> 
    filter(.category != "No") |> 
    pivot_wider(names_from = ".category", values_from = ".epred") |> 
    mutate(Understands = Understands + `Understands and Says`) |> 
    pivot_longer(c(Understands, `Understands and Says`),
                 names_to = ".category",
                 values_to = ".epred") |> 
    mutate(.category = factor(.category,
                              levels = c("Understands",
                                         "Understands and Says"),
                              labels = c("Comprehension\n(Understands)",
                                         "Production\n(Understands and Says)")))

prior_epreds |> 
    ggplot(aes(x = age_std, y = .epred)) +
    facet_wrap(~ .category) +
    geom_line(linewidth = 3/4,
              alpha = 1/2,
              aes(group = .draw),
              colour = "grey50") + 
    labs(x = "Age (months)", 
         y = "Probability of acquisition",
         colour = "Credible interval", 
         fill = "Credible interval") +
    scale_x_continuous(breaks = scale(seq(10, 36, 4), 
                                      mean(responses$age), 
                                      sd(responses$age))[, 1],
                       labels = seq(10, 36, 4)) +
    theme(legend.position = "top",
          axis.ticks.x = element_line(colour = "black"),
          panel.grid = element_blank())
```


#### Prior-predictions

```{r}
#| label: fig-prior-predictions
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Expected prior predictions"
nd <- expand.grid(
    n_phon_std = 0,
    age_std = (10:36-mean(responses$age))/(sd(responses$age)),
    exposure_std = 0,
    lv_std = 0
)

m <- add_predicted_draws(nd, model_fit_prior, ndraws = NULL, re_formula = NA)

m %>% 
    count(age_std, .prediction) %>% 
    pivot_wider(names_from = .prediction, values_from = n) %>% 
    mutate(Understands = Understands + `Understands and Says`) %>% 
    pivot_longer(c(No, Understands, `Understands and Says`),
                 names_to = ".prediction", 
                 values_to = "n") %>%
    ggplot(aes(x = age_std, y = n, fill = .prediction)) +
    geom_col(position = position_fill()) +
    labs(
        x = "Age (months)", 
        y = "Probability of acquisition",
        colour = "Category", 
        fill = "Category"
    ) +
    scale_x_continuous(
        breaks = (seq(10, 36, 4)-mean(responses$age))/(sd(responses$age)),
        labels = seq(10, 36, 4)
    ) +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = scales::percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        axis.ticks.x = element_line(colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA, colour = "black", size = 0.75),
        strip.background = element_rect(fill = "grey", colour = NA),
        plot.background = element_rect(fill = "white", colour = NA)
    )
```

:::



### Model settings

-   OS: `r sessionInfo()$running`, `r sessionInfo()$platform`
-   R version: `r sessionInfo()$R.version$version.string`
-   Algorithm: Hamiltonian Monte Carlo (No U-turn Sampler)
-   Engine: Stan (`brms` interface, `r sessionInfo()$otherPkgs$brms$Version`)
-   `brms` backend: CmdStanR (`cmdstanr` `r sessionInfo()$loadedOnly$cmdstanr$Version`)
-   Chains: `r dim(model_fit$fit)[2]`
-   Cores: `r dim(model_fit$fit)[2]`
-   Iterations: `r format(dim(model_fit$fit)[1], big.mark = ",")` (`r format(dim(model_fit$fit)[1]/2, big.mark = ",")`)

More details in Appendix: Session Info.

### R code (`brms`)


```{r}
print(model_fit$formula)
```
:::

# Results

## Descriptive statistics

::: panel-tabset

### By number of phonemes

```{r}
#| lab: fig-responses-age-phonemes
#| fig-cap: "Proportion of responses to each category by age and number of phonemes"
responses %>% 
    mutate(
        age = floor(age),
        n_phon = cut_interval(n_phon, n = 4)
    ) %>%
    count(age, n_phon, response) %>% 
    ggplot(aes(age, n, fill = response)) +
    facet_wrap(~n_phon) +
    geom_col(position = position_fill()) +
    labs(x = "Age (months)", y = "Proportion of responses", fill = "Response") +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = scales::percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```

### By exposure

```{r}
#| lab: fig-responses-age-exposure
#| fig-cap: "Proportion of responses to each category by age and exposure."
responses %>% 
    mutate(
        age = floor(age),
        exposure = cut_interval(exposure, n = 4)
    ) %>%
    count(age, exposure, response) %>% 
    ggplot(aes(age, n, fill = response)) +
    facet_wrap(~exposure) +
    geom_col(position = position_fill()) +
    labs(x = "Age (months)", y = "Proportion of responses", fill = "Response") +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = scales::percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```

### By Levenshtein

```{r}
#| lab: fig-responses-age-lv
#| fig-cap: "Proportion of responses to each category by age and Levenhstein similarity"
responses %>%
    mutate(
        age = floor(age),
        exposure = cut_interval(exposure, n = 4, labels = paste0("Q", 1:4)),
        lv = cut_interval(lv, n = 4)
    ) %>%
    group_by(te, lv, exposure, response) %>%
    count(lv, exposure, response) %>%
    pivot_wider(names_from = response,
                values_from = n,
                values_fill = 0) %>%
    mutate(
        `Understands` = `Understands` + `Understands and Says`,
        n_total = sum(No, `Understands`, `Understands and Says`)
    ) %>%
    pivot_longer(
        c(`No`, `Understands`, `Understands and Says`),
        names_to = "response",
        values_to = "n"
    ) %>%
    filter(response != "No") %>%
    mutate(prop = n / n_total) %>%
    # group_by(age, lv, exposure, response) %>%
    # summarise(prop_mean = mean(prop), .groups = "drop") %>%
    ggplot(aes(exposure, prop, colour = lv, fill = lv)) +
    facet_wrap(~ response, ncol = 1) +
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    stat_dots(aes(group = lv),
              position = position_dodge(width = 1),
              layout = "swarm",
              side = "both",
              colour = "grey80",
              fill = "grey80"
    ) +
    stat_summary(geom = "errorbar",
                 fun.data = "mean_se",
                 position = position_dodge(width = 1),
                 width = 0.25) +
    stat_summary(geom = "point",
                 fun = "mean",
                 position = position_dodge(width = 1),
                 size = 2) +
    labs(y = "Proportion of responses", 
         x = "Exposure",
         fill = "Levenshtein", 
         colour = "Levenshtein") +
    scale_colour_manual(values = clrs[c(1, 4, 3, 5)]) +
    scale_fill_manual(values = clrs[c(1, 4, 3, 5)]) +
    
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```
:::


## Fixed effects

```{r tbl-coefs}
#| label: tbl-coefs
#| tbl-cap: "Posterior distribution of regression coefficients."
#| tbl-note: "Median: median of the posterior distribution in the probability scale. 95\\% HDI: 95\\% highest density interval of the distribution; narrowest range of values that contains 95\\% of the distribution, and therefore is 95\\% likely to contain the true value, given the data. On top of each distribution, we indicate the proportion of posterior samples in the 95\\% HDI that fall into the region of practical equivalence (ROPE). This proportion indicates the probability of the true value of the coefficient being equivalent to zero. Lower values indicate that the true value is unlikely to be zero of equivalent to zero."
#| message: false
#| warning: false
#| out-width: 80%
# summarise posterior draws
intercept_label <- "Intercepts (at 22 months)"

model_summary |>
    select(.variable_name, .median, .lower, .upper, .rope_overlap, .type) |>
    mutate(across(.median:.upper,
                  \(x) ifelse(.type==intercept_label, plogis(x), x/4))) |> 
    gt(groupname_col = ".type", 
       rowname_col = ".variable_name") |>
    fmt_percent(.rope_overlap, decimals = 3) |> 
    fmt_number(c(.median:.upper), decimals = 3) |>
    cols_merge(c(.lower, .upper),
               pattern = "[{1}, {2}]") |>
    cols_label(
        .variable_name = "Parameter",
        .median = "Median",
        .lower = md("95% HDI"),
        .rope_overlap = md("*p*(H0)")
    ) |>
    tab_style(cell_text(weight = "bold"),
              cells_column_labels(columns = 1:5)) |>
    tab_style(cell_text(align = "left"),
              cells_title(groups = "subtitle")) |> 
    tab_style(cell_text(size = "small"), 
              list(cells_body(),
                   cells_row_groups(),
                   cells_stub())) |> 
    tab_style(cell_text(style = "italic"),
              cells_row_groups())
```



```{r}
#| label: fig-results-fixed
#| fig-width: 9
#| fig-heigh: 7
#| fig-cap: "Marginal posterior distribution of the regression coefficients of the fixed effects in the extended model. Distributions show the estimated likelihood density of each value in the parameter space (X-axis) of each coefficient (Y-axis). Intervals show the 95% highest density interval (*HDI*) of each distribution. This interval is the narrowest range of values that contains 95% of the distribution, and therefore is 95% likely to contain the true value, given the data. the mean and HDI limits are indicated below each distribution. Coefficients were transformed from the logit scale to the probability scale for interpretability. We used the divide-by-four rule to get the maximum change in probability of correct response associated with a unit increase in this variable, i.e. the derivative of the logistic function in its mid-point."

model_draws %>%
    ggplot(aes(.value, .variable_name)) +
    annotate(geom = "rect", ymin = -Inf, ymax = Inf,
             xmin = rope_interval["lower"],
             xmax = rope_interval["upper"],
             colour = NA, alpha = 0.2, fill = clrs[5],) +
    geom_vline(xintercept = 0, size = 1, colour = clrs[5]) +
    stat_slab(
        aes(fill = stat(abs(x) < rope_interval["upper"]),
            colour = stat(abs(x) < rope_interval["upper"]),),
        size = 1, 
        position = position_nudge(y = 0.15)
    ) +
    geom_errorbar(
        data = model_summary,
        aes(xmin = .lower, 
            xmax = .upper, 
            x = .median),
        width = 0.15
    ) +
    geom_point(data = model_summary, 
               aes(x = .median),
               size = 1.5) +
    geom_text(
        data = model_summary,
        aes(x = .median, 
            y = .variable_name,
            label = glue::glue(
                "{round(.median, 1)}",
                "[{round(.lower, 1)}, {round(.upper, 1)}]",
                .sep = " ")),
        colour = "black",
        position = position_nudge(y = -0.3), size = 3
    ) +
    labs(
        x = "Logistic regression coefficient estimate (Logit scale)",
        y = "Variable", 
        fill = "Overlaps with ROPE",
        colour = "Overlaps with ROPE"
    ) +
    scale_x_continuous(breaks = seq(-3, 3, 0.2)) +
    scale_fill_manual(
        values = clrs[c(1, 4)],
        labels = c("No", "Yes")
    ) +
    scale_colour_manual(
        values = clrs[c(1, 4)],
        labels = c("No", "Yes")
    ) +
    theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        axis.title.y = element_blank(),
        panel.grid.major.x = element_line(
            colour = "grey85",
            linetype = "dotted"
        ),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank()
    )
```


## Marginal effects

```{r fig-marginal}
#| label: fig-marginal
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 4.5
#| out-width: 100%
#| eval: true
#| fig-cap: "Posterior marginal effects. Thin lines correspond to 50 mean predictions. Thicker lines indicate the median of those predictions. Different colours indicate different levels of cognateness (phonological similarity). Predictions are presented separately for different degrees of word exposure index: little exposure to the word, mean exposure, and high exposure. Predictions for Comprehension are show on top and predictions for Comprehension and Production are shown on the bottom. In-sample predictions lie inside the grey rectangles."
clrs_reorder <- c("#58508d", "#003f5c", "#122A36", "#ffa600", "#ff6361", "#bc5090")

model_epreds |> 
    mutate(age = (age_std * sd(responses$age)) + mean(responses$age),
           exposure = factor(exposure_std,
                             levels = unique(exposure_std),
                             labels = c("Low exposure (-1 SD)",
                                        "Mean exposure",
                                        "High exposure (+1 SD)"),
                             ordered = TRUE),
           lv = factor(lv_std,
                       levels = unique(lv_std),
                       labels = paste0(c(0, 50, 100), "%"),
                       ordered = TRUE),
           .category = ifelse(.category=="Understands",
                              "Comprehension",
                              "Production")) |> 
    ggplot(aes(age, .value, colour = lv, fill = lv)) +
    facet_grid(.category~exposure) +
    annotate(geom = "rect",
             xmin = min(responses$age),
             xmax = max(responses$age),
             ymin = -Inf,
             ymax = Inf,
             fill = "grey95",
             colour = NA) +
    annotate(geom = "text",
             x = mean(responses$age),
             y = 0,
             hjust = -0.1,
             vjust = 0,
             label = "Observed age range",
             size = 2) +
    geom_vline(xintercept = mean(responses$age), 
               linetype = "dotted") +
    geom_hline(yintercept = 0.5,
               linetype = "dotted") +
    geom_line(aes(group = interaction(lv, .draw)),
              linewidth = 0.5,
              alpha = 1/10) +
    stat_summary(fun = median, geom = "line", linewidth = 0.75) +
    labs(x = "Age (months)",
         y = "Probability of acquisition",
         linetype = "Cognateness (phonological similarity)",
         colour = "Cognateness (phonological similarity)",
         fill = "Cognateness (phonological similarity)") +
    guides(colour = guide_legend(override.aes = list(linewidth = 2))) +
    scale_colour_manual(values = clrs_reorder[c(4, 5, 1)]) +
    scale_fill_manual(values = clrs_reorder[c(4, 5, 1)]) +
    scale_y_continuous(breaks = seq(0, 1, 0.25),
                       limits = c(0, 1)) +
    scale_x_continuous(breaks = seq(0, 50, 5)) +
    theme(legend.position = "top",
          legend.key.size = unit(1, "cm"),
          legend.key.height = unit(1, "cm"),
          axis.text.x = element_text(size = 9),
          panel.grid = element_blank(),
          panel.border = element_rect(fill = NA, 
                                      colour = "black", 
                                      linewidth = 0.75))
```

## Marginal effects

In order to examine the impact of the word exposure index on the effect of phonological similarity we used the [`marginaleffects`](https://vincentarelbundock.github.io/marginaleffects/index.html) R package to compute the average marginal effect of the Levenshtein distance on the probability of acquisition (comprehension or production) for the range of observed values of the word exposure index in our dataset.


```{r}
#| label: fig-marginal-effect
#| fig-cap: "Average marginal effect of phonological similarity (Levenshtein distance) on the probability of comprehension and production across the range of values of exposure. The observed range of values of the word exposure index is indicated in the X-axis, and the estimated average marginal effect of phonological similarity (Levenshtein distance) is indicated in the Y-axis. This quantity is generated by averaging the derivative of the regression coefficient of the predictor Levenshtein across the range of values of all predictors but Exposure. We represent the uncertainty associated with the resulting estimate by generating multiple values of this marginal effect by drawing multiple samples from the posterior distribution of the model coefficients, calculating the average marginal effect for each posterior draw, and plotting the result as a thin grey line. Closer lines indicate lower uncertainty over the true value of the average marginal effect of Levenshein, while more distant lines indicate higher uncertainty."
nd <- marginaleffects::datagrid(
    model = model_fit,
    n_phon_std = 0,
    lv_std = 0,
    exposure_std = seq(-1.5, 1.5, length.out = 100),
    age_std = 0,
    id = NA,
    te = NA
)

marg_effects <- marginaleffects::marginaleffects(
    model_fit,
    newdata = nd, 
    re_formula = NA,
    ndraws = 50,
    vcov = FALSE,
    type = "link"
)

marg_effects %>% 
    marginaleffects::posteriordraws() %>%
    as_tibble() %>% 
    filter(term=="lv_std") %>% 
    mutate(draw = draw/4) %>% 
    ggplot(aes(exposure_std, draw)) +
    geom_hline(yintercept = 0, size = 1, colour = "grey") +
    geom_line(aes(group = drawid), 
              alpha = 1, 
              size = 0.75,
              colour = "grey") +
    # stat_summary(fun.data = median_hdi, geom = "ribbon",
    #              colour = NA, alpha = 0.5, fill = clrs[1]) +
    stat_summary(fun = mean, 
                 geom = "line", 
                 size = 1, 
                 color = clrs[1]) +
    labs(
        x = "Word exposure index",
        y = "Marginal effect of phonological similarity\n(Levenshtein distance)"
    ) +
    scale_x_continuous(
        labels = scales::label_number(style_positive = "plus", suffix = " SD"),
        breaks = seq(-2, 2, 0.5)
    ) +
    scale_y_continuous(
        labels = scales::label_percent(style_positive = "plus", ),
        breaks = seq(-1, 1, 0.05)
    ) +
    theme(
        legend.position = "top",
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA, colour = "black", size = 0.75)
    )

```


## Random effects

### Participant-level effects

::: panel-tabset

#### Intercept

```{r}
#| label: fig-results-random-id-intercept
#| fig-width: 7
#| fig-cap: "Posterior probability of acquisition by participant"
re_id <- ranef(model_fit)$id[,,1] %>% 
    as_tibble() %>% 
    rownames_to_column("id") %>%
    left_join(distinct(model_fit$data, id),
              by = join_by(id)) %>% 
    janitor::clean_names() %>% 
    mutate(
        across(
            .cols = estimate:q97_5,
            .fns = list(
                Comprehension = ~plogis(. + fixef(model_fit)[1]),
                Production = ~plogis(. + fixef(model_fit)[2])
            ), 
            .names = "{.col}__{.fn}"
        )
    ) %>% 
    select(id, ends_with("Comprehension"), ends_with("Production")) %>% 
    pivot_longer(
        -id, 
        names_to = c(".value", "type"),
        names_sep = "__"
    ) 

re_id %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate), 
        xmin = q2_5, xmax = q97_5,
        fill = type, colour = type) +
    facet_wrap(~type) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA) +
    geom_line(aes(group = 1), size = 1) +
    geom_vline(xintercept = 0.5, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior probability of acquisition",
        y = "Participant", 
        colour = "Type"
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    scale_x_continuous(limits = c(0, 1), labels = scales::percent) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age slope

```{r}
#| label: fig-results-random-id-age
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_age <- ranef(model_fit)$id[,,"age_std"] 

re_age %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(id = unique(model_fit$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### # Phonemes slope

```{r}
#| label: fig-results-random-id-nphon
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the number of phonemes by participant"
re_n_phon <- ranef(model_fit)$id[,,"n_phon_std"] 

re_n_phon %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(id = unique(model_fit$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(
        x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5
    ) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Exposure slope

```{r}
#| label: fig-results-random-id-exposure
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of lexical frequency by participant"
re_freq <- ranef(model_fit)$id[,,"exposure_std"] 

re_freq %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(id = unique(model_fit$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```


#### Levenshtein slope

```{r}
#| label: fig-results-random-id-lv
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of phonological similarity by participant"
re_lv <- ranef(model_fit)$id[,,"lv_std"]

re_lv %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(id = unique(model_fit$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Doe-by-Levenshtein slope

```{r}
# | label: fig-results-random-id-exposure-lv
# | message: false
# | warning: false
# | fig-width: 7
# | fig-cap: "Posterior random slope of age by participant"
re_exposure_lv <- ranef(model_fit)$id[,,"exposure_std:lv_std"]

re_lv %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(id = unique(model_fit$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-DoE slope

```{r}
#| label: fig-results-random-id-age-doe
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-language degree of exposure interaction by participant"
re_age_exposure <- ranef(model_fit)$id[,,"age_std:exposure_std"]

re_age_exposure %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(id = unique(model_fit$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-Levenshtein slope

```{r}
#| label: fig-results-random-id-age-lv
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-phonological similarity interaction by participant"
re_age_lv <- ranef(model_fit)$id[,,"age_std:lv_std"]

re_age_lv %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(id = unique(model_fit$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-DoE-by-Levenshtein slope

```{r}
#| label: fig-results-random-id-age-exposure-lv
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-exposure-by-phonological similarity interaction by participant"
re_age_exposure_lv <- ranef(model_fit)$id[,,"age_std:exposure_std:lv_std"]

re_age_exposure_lv %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(id = unique(model_fit$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```


:::



### Item-level effects

::: panel-tabset

#### Intercept

```{r}
#| label: fig-results-random-te
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior probability of acquisition by translation equivalent"
re_te <- ranef(model_fit)$te[,,"Intercept"] %>% 
    as_tibble() %>% 
    rownames_to_column("te") %>% 
    janitor::clean_names() %>% 
    mutate(
        across(
            .cols = where(is.numeric),
            .fns = list(
                Comprehension = ~plogis(. + fixef(model_fit)[1]),
                Production = ~plogis(. + fixef(model_fit)[2])
            ), .names = "{.col}__{.fn}"
        )
    ) %>% 
    select(-c(estimate:q97_5)) %>% 
    pivot_longer(
        where(is.numeric), 
        names_to = c(".value", "type"),
        names_sep = "__"
    ) %>% 
    mutate(te = as.numeric(te)) 

re_te %>% 
    ggplot() +
    aes(x = estimate,
        y = reorder(te, estimate), 
        xmin = q2_5,
        xmax = q97_5,
        colour = type, 
        fill = type) +
    facet_wrap(~type) +
    geom_ribbon(aes(group = 1), 
                alpha = 0.5, 
                colour = NA) +
    geom_line(aes(group = 1), size = 1) +
    geom_vline(xintercept = 0.5, 
               colour = "black", 
               linetype = "dotted") +
    labs(x = "Posterior probability of acquisition",
         y = "TE", 
         colour = "Type") +
    scale_x_continuous(limits = c(0, 1),
                       labels = scales::percent) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age slope

```{r}
#| label: fig-results-random-te-age
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by translation equivalent"
re_age <- ranef(model_fit)$te[,,"age_std"]

re_age %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(te = unique(model_fit$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### # Phonemes slope

```{r}
#| label: fig-results-random-te-nphon
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the number of phonemes by translation equivalent"
re_n_phon <- ranef(model_fit)$te[,,"n_phon_std"]

re_n_phon %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(te = unique(model_fit$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Exosure slope

```{r}
#| label: fig-results-random-te-exposure
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_doe <- ranef(model_fit)$te[,,"exposure_std"]

re_doe %>%
    as_tibble() %>%
    janitor::clean_names() %>%
    mutate(te = unique(model_fit$data$te)) %>%
    relocate(te) %>%
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-exposure slope

```{r}
#| label: fig-results-random-te-age-exposure
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_age_doe <- ranef(model_fit)$te[,,"age_std:exposure_std"]

re_age_doe %>% 
    as_tibble() %>% 
    janitor::clean_names() %>% 
    mutate(te = unique(model_fit$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

:::


## Model diagnostics

### Traceplots

```{r}
#| label: fig-diagnostics-traceplots
#| message: false
#| warning: false
#| fig-width: 12
gather_draws(model_fit, `b_.*`, `sd_te__.*`, regex = TRUE) %>%
    mutate(.chain = paste("Chain ", .chain)) %>%
    ggplot(aes(.iteration, .value, colour = .chain)) +
    facet_wrap(~.variable, scales = "free_y") +
    annotate(geom = "rect", colour = NA,
             xmin = 0, xmax = dim(model_fit$fit)[1]/2,
             ymin = -Inf, ymax = Inf,
             alpha = 0.25) +
    geom_line() +
    labs(
        x = "Iteration",
        y = "Sample value",
        colour = "Chain"
    ) +
    scale_colour_manual(values = clrs[c(1, 3, 4, 5)]) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank(),
        axis.text.x = element_text(size = 7)
    )
```



### Model convergence

```{r fig-rhats-neffs}
#| label: fig-rhats-neffs
#| fig-cap: "MCMC convergence diagnostic of all parameters in the model. A: distribution of the Gelman-Rubin (R-hat) scores. B: distribution of the ratio of effective sa"
#| message: false
#| warning: false
#| fig-height: 4
#| fig-width: 7
#| out-width: 100%
model_convergence |> 
    ggplot(aes(.rhat)) +
    geom_histogram(binwidth = 0.001, colour = "white", fill = "grey60") +
    geom_vline(xintercept = 1.01, linetype = "dashed") +
    labs(x = "R-hat",
         y = "MCMC samples") +
    
    model_convergence |> 
    ggplot(aes(.neff)) +
    geom_histogram(binwidth = 0.1, colour = "white", fill = "grey60") +
    geom_vline(xintercept = 1.01, linetype = "dashed") +
    labs(x = "Effective sample size ratio",
         y = "MCMC samples") +
    
    plot_layout(ncol = 1) &
    plot_annotation(tag_levels = "A") &
    theme(legend.position = "none",
          panel.grid = element_blank())
```

# Appendix

## Session info

```{r}
sessionInfo()
```
