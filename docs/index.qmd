---
title: "Trajectories"
subtitle: "Lab notes"
date: "Updated: `r format(Sys.Date(), '%Y/%m/%d')`"
authors:
  - name: Gonzalo Garcia-Castro
    orcid: 0000-0002-8553-4209
    email: gonzalo.garciadecastro@upf.edu
    corresponding: true
    affiliations:
      - name: Universitat Pompeu Fabra
        department: Center for Brain and Cognition
        address: Ramon Trias fargas 25-27
        city: Barcelona
        state: Spain
        postal-code: 08005
  - name: Daniela S. Ávila-Varela
    orcid: 0000-0002-3518-8117
    affiliations:
      - name: Universitat Pompeu Fabra
        department: Center for Brain and Cognition
  - name: Ignacio Castillejo
    orcid: 0000-0001-7445-0416
    affiliations:
      - name: Universidad Autónoma de Madrid
        department: Departamento de Psicología
  - name: Nuria Sebastian-Galles
    orcid: 0000-0001-6938-2498
    affiliations:
      - name: Universitat Pompeu Fabra
        department: Center for Brain and Cognition
abstract: "Bilinguals face the challenging task of learning words from languages with overlapping phonologies. Floccia et al. (2018) reported larger vocabulary sizes for 24-month-old bilinguals that were learning languages that shared a greater amount of cognates (e.g., English-Dutch). The mechanisms underlying this effect remain unknown. We explore two compatible scenarios. First, we test whether cognates are learnt earlier than non-cognates. This would account for the difference in vocabulary size associated to the amount of shared cognates across languages. Second, we explore the possibility that the word-forms of one language interact with those in the other language, scaffolding the acquisition of their translation equivalents when their phonologies overlap. This mechanism, in line with the parallel activation account of bilingual speech perception, would provide a plausible explanation to why cognates are acquired ealier by bilinguals. We developed an online tool to collect parental reports of receptive and productive vocabularies from children learning Catalan and/or Spanish, and present data on receptive and productive vocabulary of bilingual toddlers aged 12 to 34 months."
format:
    html:
        code-copy: hover
        reference-location: margin
        code-overflow: scroll
link-external-newwindow: true
code-fold: true
code-line-numbers: true
fig-dpi: 1000
page-layout: full
warning: false
echo: false
toc: true
colorlinks: true
number-sections: true
csl: "../assets/apa7.csl"
bibliography: "../assets/references.bib"
---

```{r}
#| label: setup
#| include: false

# import packages
library(conflicted)
library(ggplot2)
library(patchwork)
library(dplyr)
library(tidyr)
library(purrr)
library(gt)
library(forcats)
library(stringr)
library(tibble)
library(tidybayes)
library(janitor)
library(glue)
library(brms)
library(scales)
library(marginaleffects)
library(lubridate)
library(bvqdev)

# load targets as R objects
tar_load(participants)
tar_load(responses)
tar_load(items)
tar_load(bvq_data)
tar_load(model_fit_0)
tar_load(model_fit_1)
tar_load(model_fit_2)
tar_load(model_fit_3)
tar_load(model_fit_4)
tar_load(model_fit_4_prior)
tar_load(model_fit_prior)
tar_load(model_loos)
tar_load(posterior_draws)
tar_load(posterior_draws_re)
tar_load(marginal_effects_epreds)

# resolve namespace conflicts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")

# set ggplot theme and colour palette
theme_set(theme_custom()) # set custom ggplot theme
clrs <- c("#003f5c", "#58508d", "#bc5090", "#ff6361", "#ffa600")

options(ggplot2.ordinal.fill = clrs,
        ggplot2.ordinal.colour = clrs,
        ggplot2.discrete.fill = clrs,
        ggplot2.discrete.colour = clrs,
        ggplot2.continuous.fill = ggplot2::scale_color_gradient,
        ggplot2.continuous.colour = ggplot2::scale_color_gradient)

rope_interval <- c(lower = -0.1, upper = +0.1)
```

# Methods

::: {.callout-tip}
Data and materials are available at [OSF](https://osf.io/hy984/), and code is available at [GitHub](https://github.com/gongcastro/trajectories).
:::

## Questionnaires

```{r}
#| label: questionnaire
#| echo: false
#| message: false
#| warning: false
data("pool", package = "bvqdev")
n_categories <- distinct(pool, semantic_category) %>% nrow()
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>% 
    pull(n) %>%
    set_names(c("catalan", "spanish"))
```

The questionnaire was implemented on-line using the formR platform [@arslan2020formr], and was structured in three blocks: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000infant] and consisted of two lists of words: one in Catalan and one in Spanish. The Catalan inventory contained `r n_item_language["catalan"]` items and the Spanish inventory contained `r n_item_language["spanish"]` items. Items in one language were translation equivalents of the items in the other language (e.g., whenever *gos* \[dog\] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. When there were two acceptable translation equivalents for a given word, we included both in separate items (e.g., Catalan *acabar* \[*to finish*\] and Spanish *acabar* and *terminar*), or merged them into a single items (e.g., Spanish *mono* \[*monkey*\] and Catalan *mono/mico*. We included items from a diverse sample of `r n_categories` semantic/functional categories (see Appendix 1). For the analyses included in this study, we excluded items from the adverbs, auxiliary words, connectives, interjections and games and routines categories, so that only data from content words (nouns, adjectives, and verbs) were used.

For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand *and* say it, or did not understand or say it (checked out by default). Some families filled a long version of the vocabulary checklists (800 translation equivalents; 800 items in Catalan, 800 items in Spanish), while others filled a shorter version (\~400 translation equivalents, \~400 items in Catalan, \~400 items in Spanish). These last families were randomly assigned to one of four different subsets of the complete list of items. These lists were designed so that each contained a representative subsample of the items from the complete list. Semantic/functional categories with less than 16 items were not divided in the short version of the questionnaire to preserve a minimum of four items per list for each category: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. Table 2 in Appendix 1 shows the distribution of items across questionnaire versions. We excluded from the analysis multi-word items (e.g., *barrita de cereales* \[cereal bar\]) and items that included more than one word-form (e.g., *mono / mico*). Table 3 shows the classification of items in cognates and non-cognates and their lexical frequency scores across the four lists of the inventories.

## Participants

```{r}
#| label: fig-participants-time
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 10 
#| fig-cap: "Date at which responses were collected"
participants %>% 
    group_by(time_stamp) %>% 
    summarise(n = n(), .groups = "drop") %>% 
    mutate(n = cumsum(n)) %>% 
    ggplot(aes(time_stamp, n)) +
    geom_vline(xintercept = ymd("2020-03-15"), size = 0.5) +
    annotate(geom = "text", y = 350, x = ymd("2020-03-15"), label = "COVID-19 lockdown in Spain",
             angle = 90, vjust = 1.5, hjust = 1) +
    geom_line(size = 1, colour = clrs[1]) +
    labs(x = "Date", y = "Number of responses", colour = "Dominant language") +
    scale_y_continuous(breaks = seq(0, 500, 100), limits = c(0, 500)) +
    theme(legend.position = "top",
          legend.title = element_blank(),
          panel.grid.minor = element_blank(),
          axis.text.x = element_text(angle = 20, hjust = 1),
          axis.title.x = element_blank()) +
    
    participants %>% 
    mutate(age = cut(floor(age), breaks = seq(7, 35, 5))) %>% 
    group_by(time_stamp, age) %>% 
    summarise(n = n(), .groups = "drop") %>% 
    group_by(age) %>% 
    mutate(n = cumsum(n)) %>% 
    ggplot(aes(time_stamp, n, colour = age)) +
    geom_vline(xintercept = ymd("2020-03-15"), size = 0.5) +
    geom_line(size = 1) +
    labs(x = "Date", y = "Number of responses", colour = "Age (months(") +
    scale_y_continuous(breaks = seq(0, 500, 50)) +
    scale_colour_manual(values = clrs) +
    
    plot_layout(ncol = 1) &
    
    scale_x_date(date_breaks = "3 month", date_labels = "%B %Y") &
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 20, hjust = 1),
        axis.title.x = element_blank(),
    )
```

### Age

Number of months elapsed between participants' birth date and questionnaire completion.

```{r}
#| label: fig-participants-age
#| fig-width: 7
#| fig-cap: "Distribution of participants' ages"
participants %>% 
    mutate(age = floor(age)) %>% 
    count(age) %>% 
    ggplot() +
    aes(x = age, y = n) +
    geom_col(fill = clrs[1]) +
    geom_text(aes(label = n), size = 3.5, vjust = -1) +
    labs(
        x = "Age (months)",
        y = "# participants"
    ) +
    scale_x_continuous(breaks = seq(0, 40, 2)) +
    scale_y_continuous(limits = c(0, 55), breaks = seq(0, 55, 10)) +
    theme(
        panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()
    )
```

### Language exposure (Degree of Exposure)

Participant degree of exposure to the words' language ($DoE$): percentage of exposure to the language the word belonged to. For example, for a participant with 90% exposure to Catalan, and 10% to Spanish, the DoE of the Catalan word *taula* would be 90%, and the DoE for the Spanish word *mesa* would be 10%.

```{r}
#| label: fig-participants-lp
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Participant degree of exposure (DoE) to Catalan and Spanish"
participants %>% 
    pivot_longer(
        c(doe_catalan, doe_spanish),
        names_to = "language", values_to = "doe", 
        names_transform = ~str_to_sentence(str_remove(., "doe_"))
    ) %>% 
    mutate(
        doe = cut(doe, breaks = seq(0, 1, 0.1), include.lowest = TRUE),
        id = paste0(id, " (", time, ")")
    ) %>% 
    count(language, doe) %>% 
    ggplot(aes(doe, y = n, label = n, fill = language)) +
    geom_col(colour = "white", size = 1) +
    geom_text(position = position_nudge(y = 5)) +
    facet_wrap(~language, ncol = 1) + 
    labs(
        x = "Degree of exposure to Catalan",
        y = "Number of participants",
        colour = "Language",
        fill = "Language"
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "top",
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank()
    )
```

### SES/parental education

<!-- # ```{r} -->
<!-- #| label: tbl-participants-edu -->
<!-- #|  tbl-cap: "Participant exposure to the language (DoE) and socio-economic status (SES)." -->
<!-- # participants %>% -->
<!-- #     left_join(bvq_data$logs) %>% -->
<!-- #     mutate( -->
<!-- #         edu_parent = fct_explicit_na(as.factor(edu_parent)), -->
<!-- #         doe_catalan = cut(doe_catalan, breaks = seq(0, 1, 0.2), include.lowest = TRUE) -->
<!-- #     ) %>% -->
<!-- #     count(doe_catalan, edu_parent) %>% -->
<!-- #     right_join( -->
<!-- #         expand_grid( -->
<!-- #             doe_catalan = levels(.$doe_catalan), -->
<!-- #             edu_parent = unique(bvq_data$logs$edu_parent) -->
<!-- #         ) -->
<!-- #     ) %>% -->
<!-- #     rename(total = n) %>% -->
<!-- #     pivot_wider(names_from = edu_parent, -->
<!-- #                 values_from = total,  -->
<!-- #                 values_fill = 0) %>% -->
<!-- #     mutate(total = rowSums(cbind(.[,3:8]), na.rm = TRUE)) %>% -->
<!-- #     rename(Total = total) %>% -->
<!-- #     select(-"NA") %>%  -->
<!-- #     gt()  -->
<!-- # summary_rows( -->
<!-- #     columns = Complementary:Primary, -->
<!-- #     fns = list(Total = ~sum(., na.rm = TRUE)), -->
<!-- #     formatter = fmt_integer -->
<!-- # ) %>% -->
<!-- # cols_label(doe_catalan = "DoE Catalan") %>% -->
<!-- # sub_missing(columns = 2:8, missing_text = "--") %>% -->
<!-- # tab_spanner("Educational attainment", Secondary:Primary) %>% -->
<!-- # tab_style( -->
<!-- #     style = list(cell_borders(weight = px(2), sides = "left", color = "grey50")), -->
<!-- #     locations = cells_body(columns = 9, rows = 1:5) -->
<!-- # ) %>% -->
<!-- # tab_style( -->
<!-- #     cell_text(style = "italic"), -->
<!-- #     cells_column_labels(columns = 2:7) -->
<!-- # ) %>% -->
<!-- # tab_style( -->
<!-- #     cell_text(weight = "bold"), -->
<!-- #     cells_column_labels(columns = c(1, 8)) -->
<!-- # ) %>% -->
<!-- # tab_style( -->
<!-- #     cell_text(weight = "bold"), -->
<!-- #     cells_column_spanners(spanners = "Educational attainment") -->
<!-- # ) -->
<!-- ``` -->

## Items


```{r}
#| label: tbl-items-summary
#| tbl-cap: "Lexical frequencies. Mean, standard error, and 95% confidence interval of lexical frequencies of items included in the Catalan and Spanish lists, reported separately for identical cognates, non-identical cognates, and non-cognates."
# items <- left_join(items, select(bvq_data$pool, te, item, language, class, semantic_category))
# 
# items %>%
#     unnest(list) %>%
#     group_by(language, list) %>%
#     summarise_at(
#         vars(freq, n_phon, lv),
#         list(
#             n = ~sum(!is.na(.)),
#             mean = ~mean(., na.rm = TRUE),
#             sd = ~sd(., na.rm = TRUE),
#             min = ~min(., na.rm = TRUE),
#             max = ~max(., na.rm = TRUE)
#         )
#     ) %>%
#     select(-c(n_phon_n, lv_n)) %>%
#     rename(n = freq_n) %>%
#     gt(groupname_col = "language", rowname_col = "list") %>%
#     fmt_number(matches("freq_|n_phon_mean|n_phon_sd"), decimals = 1) %>%
#     fmt_percent(matches("lv_"), decimals = 1) %>%
#     tab_spanner("Frequency (Zipf)", columns = starts_with("freq_")) %>%
#     tab_spanner("Length (Phonemes)", columns = starts_with("n_phon_")) %>%
#     tab_spanner("Phon. similarity (Levenshtein)", columns = starts_with("lv_")) %>%
#     cols_merge_uncert(col_val = freq_mean, col_uncert = freq_sd) %>%
#     cols_merge_uncert(col_val = n_phon_mean, col_uncert = n_phon_sd) %>%
#     cols_merge_uncert(col_val = lv_mean, col_uncert = lv_sd) %>%
#     cols_merge_range(col_begin = freq_min, col_end = freq_max) %>%
#     cols_merge_range(col_begin = n_phon_min, col_end = n_phon_max) %>%
#     cols_merge_range(col_begin = lv_min, col_end = lv_max) %>%
#     cols_label(
#         list = "",
#         n = md("*N*"),
#         freq_mean = md("Mean ± SD"),
#         freq_min = md("Range"),
#         n_phon_mean = md("Mean ± SD"),
#         n_phon_min = md("Range"),
#         lv_mean = md("Mean ± SD"),
#         lv_min = md("Range")
#     ) %>%
#     tab_style(
#         cell_text(style = "italic"),
#         cells_column_labels(everything())
#     ) %>%
#     tab_style(
#         cell_text(weight = "bold"),
#         cells_column_spanners(everything())
#     ) %>%
#     summary_rows(
#         fns = list("Grand mean" = ~mean(.)),
#         columns = ends_with("_mean")
#     ) %>%
#     summary_rows(
#         fns = list("N" = ~sum(.)),
#         columns = n,
#         formatter = fmt_integer
#     )
```

### Lexical frequency

Word lexical frequency ($Frequency$): lexical frequency of the word in its corresponding language, expressed as Zipf scores [@van2014subtlex; @zipf1949human]. This variable ranges from 0 to 7, and follows and approximates a normal distribution, with most values in a corpus ranging from 3 to 5 points. Lexical frequencies were extracted from the English corpora of the [CHILDES](https://childes.talkbank.org/) database using the [{childesr}](https://langcog.github.io/childes-db-website/) R package. Available words in the corpora were then mapped to their Catalan and Spanish translations. Therefore, the Catalan and Spanish word-forms of the same translation equivalent had the same value for lexical frequency. Responses to words with missing lexical frequencies were excluded from analyses of the total number of items). 


```{r}
#| label: fig-items-freq
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-height: 4
#| fig-cap: "Distribution of lexical frequency across items. Lexical frequencies were extracted from the English CHILDES corpora, and mapped to their Catalan and Spanish translations. Therefore Catalan and Spanish word-forms that belong to the same translation equivalent had the same lexical frequency. The black dot and interval indicate the mean and standard deviation."
mean_sd <- function(x, ...) {
    m <- mean(x, ...)
    s <- sd(x, ...)
    data.frame(mean = m, ymin = m-s, ymax = m+s)
}

items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    ggplot(aes(x = freq)) +
    geom_histogram(fill = clrs[4], colour = "white", bins = 30)  +
    labs(x = "Lexical frequency (Zipf score)", y = "Number of words") +
    theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        legend.title = element_blank()
    )
```

### \# Phonemes

Word length ($Phonemes$), computed as the number of phonemes in the phonological transcription of the word-form in [SAMPA](https://en.wikipedia.org/wiki/SAMPA) format.


```{r}
#| label: fig-items-nphon
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Distribution of number of phonemes across items"
items %>%
    mutate(language = ifelse(str_detect(item, "cat_"), "Catalan", "Spanish")) %>%
    count(language, n_phon) %>%
    ggplot() +
    aes(
        x = n_phon,
        y = n,
        fill = language,
        colour = language,
        shape = language
    ) +
    facet_wrap(~language, ncol = 1) +
    geom_col(colour = "white") +
    geom_text(aes(label = n), position = position_nudge(y = 5), colour = "black") +
    labs(
        x = "# Phonemes",
        y = "Number of words",
        fill = "Language",
        shape = "Language",
        colour = "Language"
    ) +
    scale_x_continuous(breaks = 1:15) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        axis.ticks.x = element_line(),
        legend.title = element_blank()
    )
```

### Phonological similarity (Levenshtein)

Phonological similarity between translation equivalents was computed as the normalised Levenshtein similarity between the word-form and its translation in the other language [@levenshtein1966binary]. This score is calculated by first calculating the Levenshtein distance between the two transcriptions (number of insertions, deletions or replacements needed for the shortest transcription to become identical to the longer transcription), then dividing the resulting value by the length of the longest transcription, and finally subtracting this value from 1. This results in a proportion that indicates how much the two phonological transcriptions of the translation equivalent are similar to each other, ranging from 0% (no similarity at all) to 100% (both transcriptions are identical) [see @floccia2018vocabulary; @fourtassi2020growth; @laing2022phonological for similar approaches]. 

```{r}
#| label: fig-items-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 9
#| fig-cap: "Distribution of Levenshtein similarities across items"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    mutate(lv = cut(lv, breaks = seq(0, 1, 0.1), include.lowest = TRUE)) %>% 
    count(lv) %>% 
    mutate(prop = n/sum(n)) %>% 
    ggplot(aes(x = lv, n)) +
    geom_col(fill = clrs[4], colour = "white") +
    geom_text(aes(label = paste0(n, " (", percent(prop, accuracy = 0.1), ")")),
              position = position_nudge(y = 3), size = 3.5) +
    labs(x = "Levenshtein distance", y = "Number of words") +
    theme(
        panel.grid.major.x = element_blank(),
        legend.position = "top"
    )
```

### Frequency by \# Phonemes

```{r}
#| label: fig-items-frequency-phonemes
#| echo: false
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 4
#| fig-cap: "Association betwen number of lexical frequency and number of phonemes"
items %>% 
    drop_na(freq) %>% 
    distinct(te, .keep_all = TRUE) %>% 
    count(n_phon, freq) %>% 
    ggplot(aes(n_phon, freq)) +
    geom_point(size = 2, alpha = 0.5, colour = clrs[4], shape = 1, stroke = 1,
               position = position_jitter(width = 0.1), seed = 888) +
    geom_smooth(method = "lm", formula = "y ~ x" ,
                colour = clrs[1], fill = clrs[1]) +
    labs(
        x = "# Phonemes", 
        y = "Lexical frequency (Zipf score)", 
        colour = "Language", 
        fill = "Language"
    ) +
    scale_x_continuous(breaks = seq(0, 16, 1)) +
    theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()
    ) 
```

### Frequency by Levenshtein

```{r}
#| label: fig-items-frequency-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Association betwen lexical frequency and phonological similarity"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    drop_na(freq) %>% 
    count(freq, lv) %>% 
    ggplot(aes(freq, lv, size = n)) +
    geom_point(size = 2, shape = 1, stroke = 1, colour = clrs[4]) +
    geom_smooth(method = "lm", formula = "y ~ x", colour = clrs[1], fill = clrs[1]) +
    labs(
        y = "Levenshtein similarity", 
        x = "Lexical frequency (Zipf score)", 
        colour = "Language", 
        fill = "Language"
    ) +
    scale_y_continuous(labels = percent) +
    theme(
        legend.position = "none",
        panel.grid.major.y = element_blank()
    )
```

### \# Phonemes by Levenshtein

```{r}
#| label: fig-items-nphon-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Association between number of phonemes and phonological similarity"
items %>% 
    distinct(te, .keep_all = TRUE) %>% 
    drop_na(freq) %>% 
    count(n_phon, lv) %>% 
    ggplot(aes(n_phon, lv, size = n)) +
    geom_point(shape = 1, stroke = 1, colour = clrs[4]) +
    geom_smooth(method = "lm", formula = "y ~ x", size = 1,
                colour = clrs[1], fill = clrs[1]) +
    labs(
        x = "# Phonemes", 
        y = "Levenshtein similarity", 
        colour = "Language", 
        fill = "Language"
    ) +
    scale_y_continuous(labels = percent) +
    scale_x_continuous(breaks = seq(0, 16, 1)) +
    theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        panel.grid.major.x = element_blank()
    ) 
```


### Word exposure index by lexical frequency

We created a predictor ($Exposure$) to account for the exposure rate of each child to each of the words their parents responded to, weighted by the child's exposure to the language the word belongs to. the exposure of the $i$-th child to the $j$-th word measure is the product of the lexical frequency of the word (Zipf score) and the child’s degree of exposure to the corresponding language (a proportion) (see @eq-exposure).

$$
\textbf{Exposure}_{ij} = \textbf{Frequency}_i \times \textbf{DoE}_{j}
$$ {#eq-exposure}

For instance, for a child who is reportedly exposure to Catalan 80% of the time, and to Spanish 20% of the time, the expected exposure to the word *cavall* (horse, in Catalan, with a lexical frequency of `r round(items$freq[items$item=="cat_cavall"], 2)`) would be `r round(items$freq[items$item=="cat_cavall"]*0.80, 2)`, while that of its translation to Spanish *caballo* would be `r round(items$freq[items$item=="cat_cavall"]*0.20, 2)` (see @eq-exposure-example):

$$
\begin{aligned}
\textbf{Exposure}_{\textbf{cavall, Catalan}} &= \textbf{Frequency}_{cavall} \times \textbf{DoE}_{Catalan} = 6.14 \times 0.8 = 4.91 \\
\textbf{Exposure}_{\textbf{caballo, Spanish}} &= \textbf{Frequency}_{caballo} \times \textbf{DoE}_{Spanish} = 6.14 \times 0.2 = 1.23
\end{aligned}
$$ {#eq-exposure-example}

```{r}
#| label: fig-exposure-distribution
#| fig-cap: "Relationship between lexical frequency and language exposure-weighted lexical frequency"
#| warnings: false
#| fig-height: 7
#| fig-width: 13
responses %>%
    mutate(
        language = ifelse(grepl("cat_", item), "Catalan", "Spanish"),
        exposure = cut(
            exposure,
            breaks = seq(0, 9, 1),
            include.lowest = TRUE
        )
    ) %>%
    count(exposure, language) %>%
    ggplot(aes(exposure, n, fill = language)) +
    facet_wrap( ~ language) +
    geom_col(colour = "white") +
    labs(x = "Exposure-weighted frequency\n(Frequency \u00d7 DoE)",
         y = "Number of observations",
         fill = "Language") +
    
    responses %>%
    mutate(
        language = ifelse(grepl("cat_", item), "Catalan", "Spanish"),
        exposure = cut(
            exposure,
            breaks = seq(0, 9, 1),
            include.lowest = TRUE
        ),
        freq = cut(freq, breaks = seq(0, 9, 0.25), include.lowest = TRUE)
    ) %>%
    count(exposure, freq, language) %>%
    ggplot(aes(
        x = freq,
        y = exposure,
        colour = language,
        size = n
    )) +
    facet_wrap( ~ language) +
    geom_point() +
    labs(
        x = "Frequency (Zipf score)",
        y = "Exposure-weighted frequency\n(Frequency \u00d7 DoE)",
        colour = "Language",
        fill = "Language",
        size = "Number of observations"
    ) +
    theme(panel.grid = element_blank()) +
    plot_layout(ncol = 1) &
    scale_colour_manual(values = clrs[c(1, 4)]) &
    scale_fill_manual(values = clrs[c(1, 4)]) &
    guides(fill = "none", colour = "none") &
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.y = element_blank())
```


## Data analysis

We used multilevel ordinal regression to model the cumulative probability of a *No* response, a *Understands* response, or a *Understands and Says* response [@burkner2019ordinal] using the *logit* link function. The likelihood of the cumulative probability distribution of the responses is defined by @eq-likelihood (see @fig-likelihood for a graphical representation). 


$$
\begin{aligned}
\textbf{Likelihood:} \\
y_{ij} &\sim \text{Cumulative}(p_{k})
\end{aligned}
$$ {#eq-likelihood}


where:

- $y$ is an observed response ($y \in \{\text{No, Understands, Understands and Says}\}$)
- $i$ is the participant index
- $j$ is the translation equivalent (TE) index
- $p_{k}$ is a probability ($p \in (0, 1)$) that indicates the threshold $k$ ($k \in (1, 2)$)) between two response categories in the latent distribution
$p_{k}$ is then estimated using a logit regression model as indicated in @eq-linear.


```{r}
#| label: fig-likelihood
#| fig-cap: "Graphical representation of the assumed latent distribution that generates observed responses in the questionnaire. Cumulative ordinal regression assumes that observed categorical responses (*No*, *Understands* and *Understands and Says* are generated from a common latent (i.e., unobserved) distribution. For threotical reasons, we refer to the dimension captured by such distribution as *Familiarity*. *Familiarity* describes a given participant's familiarity with a given word. When familiarity is low (below some threshold 1), the reulting response is *No*. When familiarity is higher than such threshold 1, but lower than some threshold 2, the resulting result is *Understands* (i.e., comprehension). When familiarity exceeds threshold 2, the resulting response is *Understands and Says* (i.e., comprehension and production). These thresholds are estimated in the cumulative regression model as intercepts 1, and 2. The rest of the coefficients in the regression model shift the response thresholds, making comprehension or production more likely or less likely. See @burkner2019ordinal for a detailed description of cumulative ordinal regression and its implementation."
#| fig-width: 7
#| fig-height: 3.5
dist_df <- tribble(~mean, ~sd, 0,   1)

thresholds <- data.frame(
    ymin = c(-Inf, -1.5, 1.5),
    ymax = c(-1.5, 1.5, Inf),
    xmin = -Inf,
    xmax = Inf,
    .category = str_wrap(c(
        "No", 
        "Understands",
        "Understands and Says"
    ),
    width = 12)
)

thresholds %>%
    ggplot(aes(ymin = ymin, ymax = ymax,
               xmin = xmin, xmax = xmax,
               fill = .category)) +
    geom_rect(alpha = 0.5) +
    stat_dist_slab(
        data = dist_df, 
        aes(dist = "norm", arg1 = mean, arg2 = sd),
        position = "dodge", inherit.aes = FALSE,
        fill = NA, colour = "black"
    ) +
    geom_hline(yintercept = c(-1.5, 1.5), 
               linetype = "dotted",
               linewidth = 1) +
    geom_text(aes(label = .category, y = c(-3, 0, 3), x = 1),
              vjust = 1, hjust = 0.5) +
    annotate(
        geom = "text",
        label = c("Threshold~1~(p[1])", "Threshold~2~(p[2])"),
        y = c(-1.5, 2), parse = TRUE,
        x = 0.5, angle = 90, vjust = -0.5
    ) +
    labs(y = "Hypothetical response-generating latent distribution",
         x = "Response probability",
         fill = "Response type",
         colour = "Response type") +
    coord_flip() +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_x_continuous(labels = percent) +
    scale_y_continuous(limits = c(-4, 4)) +
    theme(panel.grid = element_blank(),
          legend.position = "none")
```


To test our hypotheses, we included several predictors in the regression model as fixed effects: the main effects of participant age ($Age$), number of phonemes ($Phonemes$), word exposure index ($Exposure$), and of phonological similarity ($Levenshtein$), the two-way interactions $Age \times Exposure$, $Age \times Levenshtein$, and $Exposure \times Leveshtein$, and the three-way interaction $Age \times Exposure \times Leveshtein$. We also included crossed random effects for participants and translation equivalents to account for the repeated measures in our dataset--each participant provided responses to multiple translation equivalents, and each translation equivalent was responded to by multiple participants [@gelman2020regression]. For both grouping variables, we included random intercepts, random slopes, and correlation parameters for all predictors were repeated measures were observed in our dataset [@barr2013random, see @eq-linear]. 

$$
\begin{aligned}
\textbf{Linear model:} \\
logit(p_{k}) = \text{ln} \frac{p_{k}}{1-p_{k}} &= (\beta_{0_{k}} + u_{0_{i_{k}}} + w_{0_{j_{k}}}) + \\
& (\beta_{1} + u_{1_{i}} + w_{1_{j}}) · \text{Age}_{i} + & \\
& (\beta_{2} + u_{2_{i}} + w_{2_{j}}) · \text{Phonemes}_{ij} + & \\
& (\beta_{3} + u_{3_{i}} + w_{3_{j}}) · \text{Exposure}_{ij} + & \\
& (\beta_{4} + u_{4_{i}}) · \text{Levenshtein}_{ij} + & \\
& (\beta_{5} + u_{5_{i}} + w_{3_{j}}) · (\text{Age}_{i} \times \text{Exposure}_{ij}) + & \\
& (\beta_{6} + u_{6_{i}}) · (\text{Age}_{i} \times \text{Levenshtein}_{ij}) + & \\
& (\beta_{7} + u_{7_{i}}) · (\text{Exposure}_{ij} \times \text{Levenshtein}_{ij}) & \\
& (\beta_{8} + u_{8_{i}}) · (\text{Age}_{i} \times \text{Exposure}_{ij} \times \text{Levenshtein}_{ij}) & \\
\end{aligned}
$$ {#eq-linear}

where:

- $i$ and $j$ index the participant and translation equivalent (TE)
- $\beta_{0_k}$ is the fixed coefficient of the regression model for the intercept of threshold $k$
- $u_{0_{i}}$ and $w_{0_{j}}$ are the by-participant and by-TE adjustments for $\beta_{0_{k}}$ (i.e., random intercepts), respectively
- $\beta_{1-8}$ are the fixed coefficients of the regression model for the predictors of interest
- $u_{1-8_{i}}$ and $w_{1-3_{j}}$ are the by-participant and by-TE adjustments for$\beta_{1-8}$ (i.e., random slopes), respectively

We used the Bayesian framework to estimate the parameters in our model. This involves using the Bayes theorem to compute a distribution (*posterior distribution*) that describes what values of each parameter in the model are more likely given the data (*likelihood*, see @eq-likelihood), and previous knowledge about such distribution (*prior distribution*, see @eq-prior) [@mcelreath2020statistical]. This posterior distribution not only informs about the most likely values of our regression coefficients of interest, but also about the uncertainty around such estimations. We used a weakly informative prior for our parameters, with the exception of the main effect of $Age$, for which we specified a strongly informative prior based on previous literature about how age affects the acquisition of words [see @eq-prior].

$$
\begin{aligned}
\\
\textbf{Prior:} \\
\beta_{0_{k}} &\sim \mathcal{N}(-0.25, 0.1) & [\mbox{Intercept/response category threshold}] \\
\beta_{1} &\sim \mathcal{N}(1, 0.1) & [\mbox{Age population-level coefficient}]\\
\beta_{2-8} &\sim \mathcal{N}(0, 1) & [\mbox{Rest of population-level coefficients}] \\
u_{0-8_{i}} &\sim \mathcal{N}(0, \sigma_{u_{0-8_{i}}}) & [\mbox{Participant-level coefficient variability}] \\
w_{0-3_{j}} &\sim \mathcal{N}(0, \sigma_{w_{0-3_{j}}}) & [\mbox{TE-level coefficient variability}] \\\\
&&\mbox{[Participant-level coefficient variability]} \\ \\
\Bigg(\begin{smallmatrix}
u_{k_{0}} \\ 
u_{1_{i}} \\ 
\vdots \\ 
u_{8_{i}} 
\end{smallmatrix}\Bigg) &\sim \mathcal{N} 
\Bigg(\Bigg(\begin{smallmatrix}0 \\
0 \\ 
\vdots \\
0\end{smallmatrix}\Bigg), \Sigma_{u}\Bigg) \\
\Sigma_{u} &= \Bigg(\begin{smallmatrix} \\
\rho_{u_{0}} & \rho_{u_{0}} \sigma_{u_{0_{k}}} \sigma_{u_{1}} & \dots & \rho_{u_{0}} \sigma_{u_{0}} \sigma_{w_{8}}\\ 
\rho_{u_{1}} \sigma_{u_{1}} \sigma_{u_{0}} & \rho_{u_{1}} & \dots & \rho_{u_{1}} \sigma_{u_{1}} \sigma_{u_{8}}\\ 
\vdots & \vdots & \vdots & \vdots \\
\rho_{8} \sigma_{u_{8}} \sigma_{u_{0_{k}}} & \dots & \dots & \rho_{u_{8}} \end{smallmatrix}\Bigg) \\
\sigma_{u_{0-8}} &\sim \mathcal{N_{+}}(1, 0.1) \\
\rho_{u} &\sim LKJcorr(2) \\
\\
&&\mbox{[TE-level coefficient variability]} \\ \\
\Bigg(\begin{smallmatrix}
w_{k_{0}}\\ 
w_{1_{j}} \\ 
\vdots \\ 
w_{3_{j}} 
\end{smallmatrix}\Bigg) &\sim \mathcal{N} \Bigg(\Bigg(\begin{smallmatrix}
0\\ 
0 \\ 
\vdots \\
0 
\end{smallmatrix}\Bigg), \Sigma_{w}\Bigg) \\
\Sigma_{w} &= \Bigg(\begin{smallmatrix} \\
\rho_{w_{0}} & \rho_{w_{0}} \sigma_{w_{0_{k}}} \sigma_{w_{1}} & \dots & \rho_{w_{0}} \sigma_{w_{0}} \sigma_{w_{3}}\\ 
\rho_{w_{1}} \sigma_{w_{1}} \sigma_{w_{0}} & \rho_{w_{1}} & \dots & \rho_{w_{1}} \sigma_{w_{1}} \sigma_{w_{3}}\\ 
\vdots & \vdots & \vdots & \vdots \\
\rho_{3} \sigma_{w_{3}} \sigma_{w_{0_{k}}} & \dots & \dots & \rho_{w_{3}} \end{smallmatrix}\Bigg) \\
\sigma_{w_{0-3}} &\sim \mathcal{N_{+}}(1, 0.1) \\
\rho_{w_{0-3}} &\sim LKJcorr(2)
\end{aligned}
$$ {#eq-prior}

where:

- $\rho_{u_{0-8}}$ and $\rho_{w_{0-3}}$ indicate the correlation parameters between the by-participant and by-TE adjustments, respectively
- $\sigma_{u_{0-8}}^2$ and $\sigma_{w_{0-3}}^2$ indicate the variance of the by-participant and by-TE variance of the adjustments, respectively
- $\mathcal{N}$ indicates a normal distribution, $\mathcal{N}_{+}$ indicates a truncated normal distribution with only positive values, and $LKJcorr$ indicates a [LKJ correlation distribution](https://mc-stan.org/docs/2_22/functions-reference/lkj-correlation.html) [@lewandowski2009generating].


::: {.panel-tabset}

#### Prior-predicted mean

```{r}
#| label: fig-prior-mean
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Expected prior predictions"
nd <- expand.grid(
    n_phon_std = 0,
    age_std = (10:36-mean(responses$age))/(sd(responses$age)),
    exposure_std = 0,
    lv_std = 0
)

m <- add_epred_draws(nd, 
                     model_fit_4_prior, 
                     ndraws = NULL,
                     re_formula = NA) %>% 
    filter(.category != "No") %>% 
    pivot_wider(names_from = ".category", values_from = ".epred") %>% 
    mutate(Understands = Understands + `Understands and Says`) %>% 
    pivot_longer(
        c(Understands, `Understands and Says`),
        names_to = ".category",
        values_to = ".epred"
    ) %>% 
    mutate(
        .category = factor(
            .category,
            levels = c("Understands and Says", "Understands"),
            labels = c("Production\n(Understands and Says))", "Comprehension\n(Understands)")
        )
    )

m %>% 
    ggplot(aes(x = age_std, y = .epred)) +
    facet_wrap(~.category) +
    stat_lineribbon(size = 1, colour = NA, .width = c(0.95, 0.89, 0.67, 0.5)) +
    stat_summary(fun = "mean", geom = "line", size = 0.75) +
    scale_x_continuous(
        breaks = (seq(10, 36, 4)-mean(responses$age))/(sd(responses$age)),
        labels = seq(10, 36, 4)
    ) +
    scale_fill_manual(
        values = rev(clrs), 
        labels = c("95%", "89%", "67%", "50%")
    ) +
    labs(
        x = "Age (months)", 
        y = "Probability of acquisition",
        colour = "Credible interval", 
        fill = "Credible interval"
    ) +
    scale_y_continuous(labels = percent, limits = c(0, 1)) +
    theme(
        legend.position = "top",
        axis.ticks.x = element_line(colour = "black"),
        panel.grid = element_blank()
    )
```

#### Prior-predictions

```{r}
#| label: fig-prior-predictions
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Expected prior predictions"
nd <- expand.grid(
    n_phon_std = 0,
    age_std = (10:36-mean(responses$age))/(sd(responses$age)),
    exposure_std = 0,
    lv_std = 0
)

m <- add_predicted_draws(nd, model_fit_4_prior, ndraws = NULL, re_formula = NA)

m %>% 
    count(age_std, .prediction) %>% 
    pivot_wider(names_from = .prediction, values_from = n) %>% 
    mutate(Understands = Understands + `Understands and Says`) %>% 
    pivot_longer(c(No, Understands, `Understands and Says`), names_to = ".prediction", values_to = "n") %>%
    ggplot(aes(x = age_std, y = n, fill = .prediction)) +
    geom_col(position = position_fill()) +
    labs(
        x = "Age (months)", 
        y = "Probability of acquisition",
        colour = "Category", 
        fill = "Category"
    ) +
    scale_x_continuous(
        breaks = (seq(10, 36, 4)-mean(responses$age))/(sd(responses$age)),
        labels = seq(10, 36, 4)
    ) +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        axis.ticks.x = element_line(colour = "black"),
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA, colour = "black", size = 0.75),
        strip.background = element_rect(fill = "grey", colour = NA),
        plot.background = element_rect(fill = "white", colour = NA)
    )
```

:::

### Model comparison

To test of goodness of fit of our model, we compared its predictive accuracy of this extended model--which included all predictors of interest--to four simpler models that included a subset of our predictors of interest: a base model that only included the main effects of $Age$, $Phonemes$, and $Exposure$ ($\mathcal{M}_{0}$), a model that also included the $Age \times Exposure$ interaction ($\mathcal{M}_{1}$), a model that also included the main effect of $Levenshtein$ ($\mathcal{M}_{2}$), a model that also included the $Age \times Levenshtein$ interaction ($\mathcal{M}_{3}$). Only the extended model included the $Age \times Exposure \times Levenshtein$ interaction. We compared the predictive performance of the models using Bayesian leave-one-out cross-validation (*LOO*), a relative fit index, via the `loo` R package. LOO consists in computing the average likelihood of each observation after estimating the model's parameters leaving that same observation out of the data set. Due to computational constraints, we performed LOO based on a random subsample of 750 samples (out of `r format(dim(model_fit_4$fit)[1], big.mark = ",")`) of the posterior distribution of the fixed effects of the model.

### Model settings

-   OS: `r sessionInfo()$running`, `r sessionInfo()$platform`
-   R version: `r sessionInfo()$R.version$version.string`
-   Algorithm: Hamiltonian Monte Carlo (No U-turn Sampler)
-   Engine: Stan (`brms` interface, `r sessionInfo()$otherPkgs$brms$Version`)
-   `brms` backend: CmdStanR (`cmdstanr` `r sessionInfo()$loadedOnly$cmdstanr$Version`)
-   Chains: `r dim(model_fit_4$fit)[2]`
-   Cores: `r dim(model_fit_4$fit)[2]`
-   Iterations: `r format(dim(model_fit_4$fit)[1], big.mark = ",")` (`r format(dim(model_fit_4$fit)[1]/2, big.mark = ",")`)

More details in Appendix: Session Info.

### R code (`brms`)

::: panel-tabset

#### Model 0

```{r}
print(model_fit_0$formula)
```

#### Model 1

```{r}
print(model_fit_1$formula)
```

#### Model 2

```{r}
print(model_fit_2$formula)
```

#### Model 3

```{r}
print(model_fit_3$formula)
```

#### Model 4

```{r}
print(model_fit_4$formula)
```
:::

# Results

## Descriptive statistics

::: panel-tabset

### By number of phonemes

```{r}
#| lab: fig-responses-age-phonemes
#| fig-cap: "Proportion of responses to each category by age and number of phonemes"
responses %>% 
    mutate(
        age = floor(age),
        n_phon = cut_interval(n_phon, n = 4)
    ) %>%
    count(age, n_phon, response) %>% 
    ggplot(aes(age, n, fill = response)) +
    facet_wrap(~n_phon) +
    geom_col(position = position_fill()) +
    labs(x = "Age (months)", y = "Proportion of responses", fill = "Response") +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```

### By exposure

```{r}
#| lab: fig-responses-age-exposure
#| fig-cap: "Proportion of responses to each category by age and exposure."
responses %>% 
    mutate(
        age = floor(age),
        exposure = cut_interval(exposure, n = 4)
    ) %>%
    count(age, exposure, response) %>% 
    ggplot(aes(age, n, fill = response)) +
    facet_wrap(~exposure) +
    geom_col(position = position_fill()) +
    labs(x = "Age (months)", y = "Proportion of responses", fill = "Response") +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(labels = percent) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```

### By Levenshtein

```{r}
#| lab: fig-responses-age-lv
#| fig-cap: "Proportion of responses to each category by age and Levenhstein similarity"
responses %>%
    mutate(
        age = floor(age),
        exposure = cut_interval(exposure, n = 4, labels = paste0("Q", 1:4)),
        lv = cut_interval(lv, n = 4)
    ) %>%
    group_by(te, lv, exposure, response) %>%
    count(lv, exposure, response) %>%
    pivot_wider(names_from = response,
                values_from = n,
                values_fill = 0) %>%
    mutate(
        `Understands` = `Understands` + `Understands and Says`,
        n_total = sum(No, `Understands`, `Understands and Says`)
    ) %>%
    pivot_longer(
        c(`No`, `Understands`, `Understands and Says`),
        names_to = "response",
        values_to = "n"
    ) %>%
    filter(response != "No") %>%
    mutate(prop = n / n_total) %>%
    # group_by(age, lv, exposure, response) %>%
    # summarise(prop_mean = mean(prop), .groups = "drop") %>%
    ggplot(aes(prop, exposure, colour = lv, fill = lv)) +
    facet_grid(~ response) +
    stat_slab(alpha = 0.5, size = 0.2, trim = FALSE) +
    geom_point(size = 1, alpha = 0.5, position = position_nudge(y = -0.1)) +
    labs(x = "Proportion of responses", 
         y = "Exposure",
         fill = "Levenshtein", 
         colour = "Levenshtein") +
    scale_x_continuous(labels = percent) +
    scale_colour_manual(values = clrs[c(1, 4, 3, 5)]) +
    scale_fill_manual(values = clrs[c(1, 4, 3, 5)]) +
    
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank()
    )
```
:::


## Model selection

@tbl-results-loos shows the outputs of the *LOO-CV*. The extended model (`model_fit_3`), which included the three-way interaction between $Age$, $DoE$, and $Levenshtein$ showed the best predictive performance, with a difference in *ELPD* compared to the other models several times larger than the standard error of such difference. This indicates that, given the data, the predictions of the extended model are confidently more accurate than those of the other models.

```{r}
#| label: tbl-results-loos
#| tbl-cap: "Bayesian leave-one-out cross validation (LOO-CV). This procedure involves estimating the likelihood of each observation given a model fitted without such observation. The resulting likelihoods of each model were summed to compute the expected log-predicted density (ELPD) of the model, and correcting it for the number of parameters in the model to penalised for its the complexity. ELPD values closer to zero indicate better predictive acuracy. We report the ELPD, effective number of parameters (p), and information criterion (LOO-IC) of each model along their associated standard errors in paratheses. The first column indicates the difference in ELPD between each model and the model with the best predictive accuracy (model 4)."
model_loos %>% 
    loo_compare() %>% 
    as.data.frame() %>%   
    rownames_to_column("model") %>% 
    relocate(
        model, 
        matches("diff"),
        matches("elpd_loo"),
        matches("p_loo"), 
        matches("looic")
    ) %>%
    mutate(model = str_extract_all(model, "\\d")) %>% 
    gt() %>% 
    fmt_number(2:9, decimals = 1) %>%
    cols_merge_uncert(col_val = elpd_diff, col_uncert = se_diff) %>%
    cols_merge_uncert(col_val = elpd_loo, col_uncert = se_elpd_loo) %>%
    cols_merge_uncert(col_val = p_loo, col_uncert = se_p_loo) %>%
    cols_merge_uncert(col_val = looic, col_uncert = se_looic) %>%
    cols_label(
        model = "Model",
        elpd_loo = md("*ELPD*"),
        p_loo = md("*p*"),
        looic = md("*LOO-IC*"),
        elpd_diff = md("Difference")
    ) %>%
    tab_source_note(md("Pareto-*k* estimates of all models were acceptable (*k* < 0.5)")) %>%
    tab_style(
        cell_text(weight = "bold"),
        cells_column_labels()
    ) %>%
    tab_style(
        cell_fill(color = "grey", alpha = 0.5),
        cells_body(matches("diff"))
    ) %>%
    tab_style(
        cell_fill(color = clrs[4], alpha = 0.5),
        cells_body(rows = 1)
    )
```



## Fixed effects

```{r}
#| label: tbl-results-fixed
#| tbl-cap: "Summary of the estimated posterior distribution of fixed regression coefficients"
#| fig-width: 7
intercept_footnote <- glue("Probability of comprehension or production at the grand age of the sample ({round(mean(responses$age), 2)} months")

# summarise posterior draws
posterior_draws$summary %>%
    gt(rowname_col = ".variable_name", 
       groupname_col = ".type") %>%
    cols_hide(".variable") %>% 
    fmt_number(.median:.lower, decimals = 2) %>%
    fmt_percent(.rope_overlap, decimals = 2) %>%
    cols_merge(c(.lower, .upper), pattern = "[{1}, {2}]") %>%
    cols_label(.median = "Median",
               .lower = "95% HDI",
               .rope_overlap = "ROPE prob.") %>%
    tab_style(cell_text(weight = "bold"),
              cells_column_labels()) %>%
    tab_style(cell_text(align = "left"),
              cells_stub())

post_draws_list <- split(posterior_draws$summary, 
                         posterior_draws$summary$.variable)
```

We specified a region of practical equivalence (*ROPE*) around the values of each regression coefficient that we considered equivalent to zero [@kruschke2018bayesian]. We decided to draw this interval around zero so that it covered values smaller than those considered as negligible by similar previous studies: after consulting the regression tables of [ADD STUDIES], we selected the largest regression coefficient that was interpreted as conclusive evidence of the presence of an effect, as indicated by the authors, and transformed it to the probability scale: 3%. consequently, we defined our *ROPE* from -0.1% to +0.1%. We report the mean of each coefficient's marginal posterior distribution along with their 95% highest density intervals (*HDI*). This interval indicates the narrowest range of values that contain 95% of the samples of the posterior distribution, and therefore the true value of the coefficient with 95% confidence, given our data. Following [@kruschke2018bayesian], we considered as relevant those regression coefficients whose 95% *HDI* did not overlap with the *ROPE* interval we previously defined. For those coefficients that did not exclude completely the *ROPE* we also report a Bayes Factor indicating how many times is such coefficient more likely to be bigger than the upper limit of the *ROPE*, or smaller than the lower limit of the *ROPE*, given our data. 

For interpretability, we report the estimated regression coefficients transformed from the probability scale. The resulting values correspond to the maximum difference in probability of acquisition (*Comprehension* or *Comprehension and Production*) that corresponds to a one standard deviation change in each predictor^[The logit and probability scales related non-linearly. This means that one logit difference is not necessarily translated to a unique value in the probability scale. For example, the probability of acquisition of a given word might increase in 5% when age increases from 22 to 23 months, the probability of acquisition of the same word might only increase in 0.2% when age increases from 34 to 36 months. The linear growth of the probability of acquisition differs along the logistic curve, and therefore deciding the age point at which to report the estimates of the regression coefficients  in the probability scale is not trivial. We followed the suggestion by @gelman2020regression and report the maximum value of such coefficient, which corresponds to the linear growth (i.e. derivative) of the logistic curve at the age at which most participants were acquiring a given word. This value can be approximated by dividing the coefficient in the logit scale by four: $\hat{\beta_j}/4$, where $\hat{\beta_j}$ is the estimated mean of the posterior distribution of coefficient $j$.].

@fig-results-fixed shows the outputs of the model. **Age** was the predictor with the largest effect on the probability of acquisition ($\beta$ = `r round(post_draws_list[["b_age_std"]]$.median, 2)`, 95% *HDI* = [`r round(post_draws_list[["b_age_std"]]$.lower, 2)`, `r round(post_draws_list[["b_age_std"]]$.upper, 2)`]): at the steepest point of the acquisition trajectory of an average translation equivalent, the probability of acquisition increased `r percent(post_draws_list[["b_age_std"]]$.median/(4*sd(responses$age)), accuracy = 0.01)` every month.

The 95% *HDI* of the regression coefficient of the **number of phonemes** did exclude the *ROPE*, although not by much: `r percent(post_draws_list[["b_n_phon_std"]]$.rope_overlap, accuracy = 0.01)` of its posterior samples fell within the *ROPE*. This suggests that the number of phonemes in the word form had a small effect on the probability of acquisition ($\beta$ = `r percent(post_draws_list[["b_n_phon_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_n_phon_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_n_phon_std"]]$.upper, accuracy = 0.01)`]). For every increase in phoneme length, the probability of acquisition decreased in `r percent(post_draws_list[["b_n_phon_std"]]$.median/(4*sd(responses$n_phon)), accuracy = 0.01)`.

**Exposure** ($Exposure$) had a strong effect on the probability of acquisition ($\beta$ = `r percent(post_draws_list[["b_exposure_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_exposure_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_exposure_std"]]$.upper, accuracy = 0.01)`]). All of the posterior samples of his regression excluded the *ROPE*. The impact of this predictor on the probability of acquisition was positive: for every SD increase in exposure rate, the participant was `r percent(post_draws_list[["b_exposure_std"]]$.median/(4*sd(responses$exposure)), accuracy = 0.01)` more likely to acquire it.

The effect of **phonological similarity** by itself (as indicated by the regression coefficient of the main effect of $Levenshtein$) was equivalent to zero ($\beta$ = `r percent(post_draws_list[["b_lv_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_lv_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_lv_std"]]$.upper, accuracy = 0.01)`]), as `r percent(post_draws_list[["b_lv_std"]]$.rope_overlap, accuracy = 0.01)` of the posterior samples of its regression coefficient fell into the *ROPE*.

However, the 95% *HDI* of the regression coefficient of the $Exposure \times Levenshtein$ interaction excluded the *ROPE* entirely ($\beta$ = `r percent(post_draws_list[["b_exposure_std:lv_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_exposure_std:lv_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_exposure_std:lv_std"]]$.upper, accuracy = 0.01)`]), suggesting that the effect of phonological similarity on a word's probability of acquisition changed depending on participants' exposure to the word. Follow up analyses on this interaction (see @fig-results-marginal) showed that, when exposure to the language was low (e.g., 10%), phonological similarity increased the probability of acquisition substantially. This effect was negligible when exposure to both languages was balanced (e.g. 50-50%). Finally, when exposure to the language was high (e.g., 90%), this effect was very close to zero, although with different direction, with phonological less similar translation equivalents being more likely to be acquired than phonologically more similar ones.

The 95% *HDI* of the regression coefficient of the $Age \times Exposure$ interaction did not exclude the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:exposure_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:exposure_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:exposure_std"]]$.upper, accuracy = 0.01)`]): `r percent(post_draws_list[["b_age_std:exposure_std"]]$.rope_overlap, accuracy = 0.01)` of its posterior samples fell within the *ROPE*. This shows that the effect of exposure on the speed at which participants acquired words across ages was inconclusive. Given our data, it is difficult to tell whether this *Exposure* increased or decreased the slope of the words' acquisition trajectories.

The 95% *HDI* of the regression coefficient of the $Age \times Levenshtein$ interaction overlapped completely with the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:lv_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:lv_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:lv_std"]]$.upper, accuracy = 0.01)`]), indicating that phonological similarity did not speed-up the acquisition trajectories of the words across ages.

Finally, the 95% *HDI* of the regression coefficient of the $Age \times Exposure \times Levenshtein$ interaction also overlapped completely with the *ROPE* ($\beta$ = `r percent(post_draws_list[["b_age_std:exposure_std:lv_std"]]$.median, accuracy = 0.01)`, 95% *HDI* = [`r percent(post_draws_list[["b_age_std:exposure_std:lv_std"]]$.lower, accuracy = 0.01)`, `r percent(post_draws_list[["b_age_std:exposure_std:lv_std"]]$.upper, accuracy = 0.01)`]), suggesting that the impact of exposure to the language on the effect of phonological similarity did not differ substantially across ages. 


```{r}
#| label: fig-results-fixed
#| fig-width: 9
#| fig-heigh: 7
#| fig-cap: "Marginal posterior distribution of the regression coefficients of the fixed effects in the extended model. Distributions show the estimated likelihood density of each value in the parameter space (X-axis) of each coefficient (Y-axis). Intervals show the 95% highest density interval (*HDI*) of each distribution. This interval is the narrowest range of values that contains 95% of the distribution, and therefore is 95% likely to contain the true value, given the data. the mean and HDI limits are indicated below each distribution. Coefficients were transformed from the logit scale to the probability scale for interpretability. We used the divide-by-four rule to get the maximum change in probability of correct response associated with a unit increase in this variable, i.e. the derivative of the logistic function in its mid-point."

posterior_draws$draws %>%
    ggplot(aes(.value, fct_rev(.variable_name))) +
    annotate(geom = "rect", ymin = -Inf, ymax = Inf,
             xmin = rope_interval["lower"],
             xmax = rope_interval["upper"],
             colour = NA, alpha = 0.2, fill = clrs[5],) +
    geom_vline(xintercept = 0, size = 1, colour = clrs[5]) +
    stat_slab(
        aes(fill = stat(abs(x) < rope_interval["upper"]),
            colour = stat(abs(x) < rope_interval["upper"]),),
        size = 1, 
        position = position_nudge(y = 0.15)
    ) +
    geom_errorbar(
        data = posterior_draws$summary,
        aes(xmin = .lower, 
            xmax = .upper, 
            x = .median),
        width = 0.15
    ) +
    geom_point(data = posterior_draws$summary, 
               aes(x = .median),
               size = 1.5) +
    geom_text(
        data = posterior_draws$summary,
        aes(x = .median, 
            y = .variable_name,
            label = glue(
                "{round(.median, 1)}",
                "[{round(.lower, 1)}, {round(.upper, 1)}]",
                .sep = " ")),
        colour = "black",
        position = position_nudge(y = -0.3), size = 3
    ) +
    labs(
        x = "Logistic regression coefficient estimate (Logit scale)",
        y = "Variable", 
        fill = "Overlaps with ROPE",
        colour = "Overlaps with ROPE"
    ) +
    scale_x_continuous(breaks = seq(-2, 2, 0.2)) +
    scale_fill_manual(
        values = clrs[c(1, 4)],
        labels = c("No", "Yes")
    ) +
    scale_colour_manual(
        values = clrs[c(1, 4)],
        labels = c("No", "Yes")
    ) +
    theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        axis.title.y = element_blank(),
        panel.grid.major.x = element_line(
            colour = "grey85",
            linetype = "dotted"
        ),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.x = element_blank()
    )
```


## Marginal effects

```{r}
#| label: fig-results-marginal
#| fig-width: 7
#| fig-cap: "Expected posterior predictions. Posterior predictions for the extended model were generated by computing the probability acquisition that resulted from feeding the equation of the regression model with values of the posterior distribution of each coefficient. These values correspond to the 4,000 samples of the posterior distribution that were drawn during the MCMC estimation of the model. Therefore, we generated 4,000 predictions for a series of combination of levels of interest. Each line and interval and in the figure summarises the mean and 95% *HDI* of each combination of levels. The X-axis indicates the age (in months) for which the prediction is generated. The Y-axis indicates the predicted probability of acquisition (*Comprehension* or *Comprehension and Production*). Different colours indicate different levels of phonological similarity (as indicated by the Levenshtein similarity between pairs of translation equivalents). Finally, predictions are presented separately for different degrees of exposure (10%): little exposure to the language (10% DoE, traditionally classified as monolingual), balanced exposure to both languages (50%, traditionally classified as bilingual), and high exposure to the language (90%, traditionally classified as monolingual). Predictions for *Comprehension* are show on top and predictions for *Comprehension and Production* are shown on the bottom."

marginal_effects_epreds %>% 
    ggplot(aes(age, .value, colour = lv, fill = lv)) +
    facet_grid(.category~exposure) +
    # stat_summary(fun.data = median_hdi, geom = "ribbon",
    #              alpha = 0.5, colour = NA) +
    geom_line(aes(group = interaction(lv, .draw)),
              size = 0.75,
              alpha = 0.15) +
    stat_summary(aes(linetype = lv), 
                 fun = median, 
                 geom = "line",
                 size = 1) +
    labs(
        x = "Age (months)",
        y = "Probability of acquisition",
        linetype = "Phonological similarity (Levenshtein)",
        colour = "Phonological similarity (Levenshtein)",
        fill = "Phonological similarity (Levenshtein)"
    ) +
    scale_colour_manual(values = clrs[c(1, 4, 5)]) +
    scale_fill_manual(values = clrs[c(1, 4, 5)]) +
    scale_y_continuous(
        breaks = seq(0, 1, 0.25),
        limits = c(0, 1),
        labels = percent
    ) +
    scale_x_continuous(breaks = seq(10, 32, 4)) +
    theme(
        legend.position = "top",
        panel.grid = element_line(colour = "grey", 
                                  linetype = "dotted"),
        panel.border = element_rect(fill = NA, 
                                    colour = "black",
                                    linewidth = 0.75)
    )


```

## Marginal effects

In order to examine the impact of the word exposure index on the effect of phonological similarity we used the [`marginaleffects`](https://vincentarelbundock.github.io/marginaleffects/index.html) R package to compute the average marginal effect of the Levenshtein distance on the probability of acquisition (comprehension or production) for the range of observed values of the word exposure index in our dataset.


```{r}
#| label: fig-marginal-effect
#| fig-cap: "Average marginal effect of phonological similarity (Levenshtein distance) on the probability of comprehension and production across the range of values of exposure. The observed range of values of the word exposure index is indicated in the X-axis, and the estimated average marginal effect of phonological similarity (Levenshtein distance) is indicated in the Y-axis. This quantity is generated by averaging the derivative of the regression coefficient of the predictor Levenshtein across the range of values of all predictors but Exposure. We represent the uncertainty associated with the resulting estimate by generating multiple values of this marginal effect by drawing multiple samples from the posterior distribution of the model coefficients, calculating the average marginal effect for each posterior draw, and plotting the result as a thin grey line. Closer lines indicate lower uncertainty over the true value of the average marginal effect of Levenshein, while more distant lines indicate higher uncertainty."
nd <- datagrid(
    model = model_fit_4,
    n_phon_std = 0,
    lv_std = 0,
    exposure_std = seq(-1.5, 1.5, length.out = 100),
    age_std = 0,
    id = NA,
    te = NA
)

marg_effects <- marginaleffects(
    model_fit_4,
    newdata = nd, 
    re_formula = NA,
    ndraws = 50,
    vcov = FALSE,
    type = "link"
)

marg_effects %>% 
    posteriordraws() %>%
    as_tibble() %>% 
    filter(term=="lv_std") %>% 
    mutate(draw = draw/4) %>% 
    ggplot(aes(exposure_std, draw)) +
    geom_hline(yintercept = 0, size = 1, colour = "grey") +
    geom_line(aes(group = drawid), 
              alpha = 1, 
              size = 0.75,
              colour = "grey") +
    # stat_summary(fun.data = median_hdi, geom = "ribbon",
    #              colour = NA, alpha = 0.5, fill = clrs[1]) +
    stat_summary(fun = mean, 
                 geom = "line", 
                 size = 1, 
                 color = clrs[1]) +
    labs(
        x = "Word exposure index",
        y = "Marginal effect of phonological similarity\n(Levenshtein distance)"
    ) +
    scale_x_continuous(
        labels = label_number(style_positive = "plus", suffix = " SD"),
        breaks = seq(-2, 2, 0.5)
    ) +
    scale_y_continuous(
        labels = label_percent(style_positive = "plus", ),
        breaks = seq(-1, 1, 0.05)
    ) +
    theme(
        legend.position = "top",
        panel.grid = element_blank(),
        panel.border = element_rect(fill = NA, colour = "black", size = 0.75)
    )

```


## Random effects

### Participant-level effects

::: panel-tabset

#### Intercept

```{r}
#| label: fig-results-random-id-intercept
#| fig-width: 7
#| fig-cap: "Posterior probability of acquisition by participant"
re_id <- ranef(model_fit_4)$id[,,1] %>% 
    as_tibble() %>% 
    rownames_to_column("id") %>%
    mutate(id = as.integer(id)) %>% 
    left_join(distinct(model_fit_4$data, id)) %>% 
    clean_names() %>% 
    mutate(
        across(
            .cols = estimate:q97_5,
            .fns = list(
                Comprehension = ~plogis(. + fixef(model_fit_4)[1]),
                Production = ~plogis(. + fixef(model_fit_4)[2])
            ), 
            .names = "{.col}__{.fn}"
        )
    ) %>% 
    select(id, ends_with("Comprehension"), ends_with("Production")) %>% 
    pivot_longer(
        -id, 
        names_to = c(".value", "type"),
        names_sep = "__"
    ) 

re_id %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate), 
        xmin = q2_5, xmax = q97_5,
        fill = type, colour = type) +
    facet_wrap(~type) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA) +
    geom_line(aes(group = 1), size = 1) +
    geom_vline(xintercept = 0.5, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior probability of acquisition",
        y = "Participant", 
        colour = "Type"
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    scale_x_continuous(limits = c(0, 1), labels = percent) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age slope

```{r}
#| label: fig-results-random-id-age
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_age <- ranef(model_fit_4)$id[,,"age_std"] 

re_age %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(id = unique(model_fit_4$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### # Phonemes slope

```{r}
#| label: fig-results-random-id-nphon
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the number of phonemes by participant"
re_n_phon <- ranef(model_fit_4)$id[,,"n_phon_std"] 

re_n_phon %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(id = unique(model_fit_4$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(
        x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5
    ) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Exposure slope

```{r}
#| label: fig-results-random-id-exposure
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of lexical frequency by participant"
re_freq <- ranef(model_fit_4)$id[,,"exposure_std"] 

re_freq %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(id = unique(model_fit_4$data$id)) %>% 
    relocate(id) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```


#### Levenshtein slope

```{r}
#| label: fig-results-random-id-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of phonological similarity by participant"
re_lv <- ranef(model_fit_4)$id[,,"lv_std"]

re_lv %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(id = unique(model_fit_4$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Doe-by-Levenshtein slope

```{r}
# | label: fig-results-random-id-exposure-lv
# | echo: true
# | message: false
# | warning: false
# | fig-width: 7
# | fig-cap: "Posterior random slope of age by participant"
re_exposure_lv <- ranef(model_fit_4)$id[,,"exposure_std:lv_std"]

re_lv %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(id = unique(model_fit_4$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-DoE slope

```{r}
#| label: fig-results-random-id-age-doe
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-language degree of exposure interaction by participant"
re_age_exposure <- ranef(model_fit_4)$id[,,"age_std:exposure_std"]

re_age_exposure %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(id = unique(model_fit_4$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-Levenshtein slope

```{r}
#| label: fig-results-random-id-age-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-phonological similarity interaction by participant"
re_age_lv <- ranef(model_fit_4)$id[,,"age_std:lv_std"]

re_age_lv %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(id = unique(model_fit_4$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-DoE-by-Levenshtein slope

```{r}
#| label: fig-results-random-id-age-exposure-lv
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the age-by-exposure-by-phonological similarity interaction by participant"
re_age_exposure_lv <- ranef(model_fit_4)$id[,,"age_std:exposure_std:lv_std"]

re_age_exposure_lv %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(id = unique(model_fit_3$data$id)) %>%
    relocate(id) %>%
    ggplot() +
    aes(x = estimate, y = reorder(id, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```


:::



### Item-level effects

::: panel-tabset

#### Intercept

```{r}
#| label: fig-results-random-te
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior probability of acquisition by translation equivalent"
re_te <- ranef(model_fit_4)$te[,,"Intercept"] %>% 
    as_tibble() %>% 
    rownames_to_column("te") %>% 
    clean_names() %>% 
    mutate(
        across(
            .cols = where(is.numeric),
            .fns = list(
                Comprehension = ~inv_logit_scaled(. + fixef(model_fit_4)[1]),
                Production = ~inv_logit_scaled(. + fixef(model_fit_4)[2])
            ), .names = "{.col}__{.fn}"
        )
    ) %>% 
    select(-c(estimate:q97_5)) %>% 
    pivot_longer(
        where(is.numeric), 
        names_to = c(".value", "type"),
        names_sep = "__"
    ) %>% 
    mutate(te = as.numeric(te)) 

re_te %>% 
    ggplot() +
    aes(x = estimate,
        y = reorder(te, estimate), 
        xmin = q2_5,
        xmax = q97_5,
        colour = type, 
        fill = type) +
    facet_wrap(~type) +
    geom_ribbon(aes(group = 1), 
                alpha = 0.5, 
                colour = NA) +
    geom_line(aes(group = 1), size = 1) +
    geom_vline(xintercept = 0.5, 
               colour = "black", 
               linetype = "dotted") +
    labs(x = "Posterior probability of acquisition",
         y = "TE", 
         colour = "Type") +
    scale_x_continuous(limits = c(0, 1),
                       labels = percent) +
    scale_fill_manual(values = clrs[c(1, 4)]) +
    scale_colour_manual(values = clrs[c(1, 4)]) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age slope

```{r}
#| label: fig-results-random-te-age
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by translation equivalent"
re_age <- ranef(model_fit_4)$te[,,"age_std"]

re_age %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(te = unique(model_fit_4$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### # Phonemes slope

```{r}
#| label: fig-results-random-te-nphon
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of the number of phonemes by translation equivalent"
re_n_phon <- ranef(model_fit_3)$te[,,"n_phon_std"]

re_n_phon %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(te = unique(model_fit_3$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Exosure slope

```{r}
#| label: fig-results-random-te-exposure
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_doe <- ranef(model_fit_4)$te[,,"exposure_std"]

re_doe %>%
    as_tibble() %>%
    clean_names() %>%
    mutate(te = unique(model_fit_4$data$te)) %>%
    relocate(te) %>%
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant",
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

#### Age-by-exposure slope

```{r}
#| label: fig-results-random-te-age-exposure
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Posterior random slope of age by participant"
re_age_doe <- ranef(model_fit_4)$te[,,"age_std:exposure_std"]

re_age_doe %>% 
    as_tibble() %>% 
    clean_names() %>% 
    mutate(te = unique(model_fit_4$data$te)) %>% 
    relocate(te) %>% 
    ggplot() +
    aes(x = estimate, y = reorder(te, estimate),
        xmin = q2_5, xmax = q97_5) +
    geom_ribbon(aes(group = 1), alpha = 0.5, color = NA, fill = clrs[1]) +
    geom_line(aes(group = 1), size = 1, colour = clrs[1]) +
    geom_vline(xintercept = 0, colour = "black", linetype = "dotted") +
    labs(
        x = "Posterior random slope estimate",
        y = "Participant", 
    ) +
    theme(
        legend.position = "none",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid = element_line(linetype = "dotted"),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()
    )
```

:::


## Model diagnostics

### Traceplots

```{r}
#| label: fig-diagnostics-traceplots
#| echo: false
#| message: false
#| warning: false
#| fig-width: 12
gather_draws(model_fit_4, `b_.*`, `sd_te__.*`, regex = TRUE) %>%
    mutate(.chain = paste("Chain ", .chain)) %>%
    ggplot(aes(.iteration, .value, colour = .chain)) +
    facet_wrap(~.variable, scales = "free_y") +
    annotate(geom = "rect", colour = NA,
             xmin = 0, xmax = dim(model_fit_4$fit)[1]/2,
             ymin = -Inf, ymax = Inf,
             alpha = 0.25) +
    geom_line() +
    labs(
        x = "Iteration",
        y = "Sample value",
        colour = "Chain"
    ) +
    scale_colour_manual(values = clrs[c(1, 3, 4, 5)]) +
    theme(
        legend.position = "top",
        legend.title = element_blank(),
        panel.grid = element_blank(),
        axis.text.x = element_text(size = 7)
    )
```

### Leave-one-out diagnostics (Pareto-*k* diagnostics)

::: panel-tabset

#### Model 0

```{r}
#| label: fig-loo-diagnostics-0
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Bayesian leave-out-out cross-validation diagnostics of Model 0"
get_loo_plot <- function(x){
    custom_breaks<- seq(0, length(x$pointwise[,5]), 50000)
    
    x$pointwise[,5] %>% 
        data.frame(x = 1:length(.), y = .) %>% 
        ggplot(aes(x, y)) +
        geom_point(
            size = 0.5, 
            alpha = 0.1,
            colour = clrs[4], 
            shape = 1
        ) +
        geom_hline(yintercept = 0.5,
                   linetype = "dotted") +
        labs(x = "Data point",
             y = "Pareto-k value",
             title = "PSIS diagnostic plot") +
        scale_x_continuous(breaks = custom_breaks) +
        scale_y_continuous(limits = c(-0.6, 0.6))
}

get_loo_plot(model_loos$model_fit_0)
```

#### Model 1

```{r}
#| label: fig-loo-diagnostics-1
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Bayesian leave-out-out cross-validation diagnostics of Model 1"
get_loo_plot(model_loos$model_fit_1)
```

#### Model 2

```{r}
#| label: fig-loo-diagnostics-2
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Bayesian leave-out-out cross-validation diagnostics of Model 2"
get_loo_plot(model_loos$model_fit_2)
```

#### Model 3

```{r}
#| label: fig-loo-diagnostics-3
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Bayesian leave-out-out cross-validation diagnostics of Model 3"
get_loo_plot(model_loos$model_fit_3)
```

#### Model 4

```{r}
#| label: fig-loo-diagnostics-4
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| fig-cap: "Bayesian leave-out-out cross-validation diagnostics of Model 4"
get_loo_plot(model_loos$model_fit_4)
```

:::


### Gelman-Rubin diagnostic (R-hat)

```{r}
#| label: fig-diagnostics-rhat
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| eval: false
mcmc_rhat_data(model_rhats$model_fit_4) %>% 
    ggplot() +
    aes(x = value) +
    geom_histogram(bins = 100, na.rm = TRUE, fill = clrs[1], colour = "white") +
    geom_rug(colour = clrs[1]) +
    labs(
        x = "R-hat",
        y = "Number of samples",
        colour = "Description",
        fill = "Description"
    ) +
    theme(
        legend.position = "top"
    )
```

### Effective sample size

```{r}
#| label: fig-diagnostics-neff
#| echo: false
#| message: false
#| warning: false
#| fig-width: 7
#| eval: false
mcmc_neff_data(model_neffs$model_fit_4) %>% 
    ggplot() +
    aes(x = value, fill = description, colour = description) +
    geom_histogram(bins = 100, na.rm = TRUE, colour = "white") +
    geom_rug() +
    geom_vline(xintercept = 1, colour = "black", size = 0.75) +
    labs(
        x = "Effective sample size ratio",
        y = "Number of samples",
        colour = "Rating",
        fill = "Rating"
    ) +
    scale_fill_manual(values = clrs[c(1, 3, 5)]) +
    scale_colour_manual(values = clrs[c(1, 3, 5)]) +
    theme(
        legend.position = "top"
    )
```

# Discussion

## Summary of the study

## Summary of the results

## Results in contrast with the literature

## Mechanistic explanations

## Limitations

## Further steps


# Appendix

## Session info

```{r}
sessioninfo::session_info()
```
