Trajectories
================

# Questionnaires

# Items

<br>

## Lexical frequency

## Cognateness

## 

# Participants

## Age

## Language profile

## 

# Data analysis

We initially fitted a null model (`fit_0`) than only included the
predictors `age` and `frequency` as nuisance parameters, along with
random intercepts by `id` and `item`, and random slopes of `frequency`
by `id`, and `age` by `item`, and their correlation parameter. We then
extended this model (`fit_1`) to include the main effect of `doe`, and
the `doe` by `item` random slope. Finally, we added the main effect
`cognate` (`fit_2`), its interaction with `doe` (`doe:cognate`), and
random slopes for `cognate` by `id`. The models were implemented in
`brms` as:

-   `understands/produces ~ 1 + age + frequency + (1 + age | item) + (1 + frequency | id)`
-   `understands/produces ~ 1 + age + frequency + doe + (1 + age + doe | item) + (1 + frequency | id)`
-   `understands/produces ~ 1 + age + frequency + doe*cognate + (1 + age + doe | item) + (1 + frequency + cognate| id)`

## Model equation

![
\\begin{aligned}
\\log(\\frac{p}{n - q}) &= (\\beta\_{0} + \\beta\_{0p} + \\beta\_{0i}) + ... \\\\
& (\\beta\_{1} + \\beta\_{1p})\\times Cognate\_{pi} + ... \\\\
& (\\beta\_{2} + \\beta\_{2i}) \\times Exposure\_{pi} + ... \\\\
& (\\beta\_{3} + \\beta\_{3i} + \\beta\_{3p}) \\times (Cognate\_{pi} \\times Exposure\_{pi}) + ... \\\\
& (\\beta\_{4} + \\beta\_{4i}) \\times Age\_{pi} + ... \\\\
& (\\beta\_{4} + \\beta\_{4p}) \\times Frequency\_{pi} + ... \\\\
& \\varepsilon\_{pi}
\\end{aligned}
](https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A%5Clog%28%5Cfrac%7Bp%7D%7Bn%20-%20q%7D%29%20%26%3D%20%28%5Cbeta_%7B0%7D%20%2B%20%5Cbeta_%7B0p%7D%20%2B%20%5Cbeta_%7B0i%7D%29%20%2B%20...%20%5C%5C%0A%26%20%28%5Cbeta_%7B1%7D%20%2B%20%5Cbeta_%7B1p%7D%29%5Ctimes%20Cognate_%7Bpi%7D%20%2B%20...%20%5C%5C%0A%26%20%28%5Cbeta_%7B2%7D%20%2B%20%5Cbeta_%7B2i%7D%29%20%5Ctimes%20Exposure_%7Bpi%7D%20%2B%20...%20%5C%5C%0A%26%20%28%5Cbeta_%7B3%7D%20%2B%20%5Cbeta_%7B3i%7D%20%2B%20%5Cbeta_%7B3p%7D%29%20%5Ctimes%20%28Cognate_%7Bpi%7D%20%5Ctimes%20Exposure_%7Bpi%7D%29%20%2B%20...%20%5C%5C%0A%26%20%28%5Cbeta_%7B4%7D%20%2B%20%5Cbeta_%7B4i%7D%29%20%5Ctimes%20Age_%7Bpi%7D%20%2B%20...%20%5C%5C%0A%26%20%28%5Cbeta_%7B4%7D%20%2B%20%5Cbeta_%7B4p%7D%29%20%5Ctimes%20Frequency_%7Bpi%7D%20%2B%20...%20%5C%5C%0A%26%20%5Cvarepsilon_%7Bpi%7D%0A%5Cend%7Baligned%7D%0A "
\begin{aligned}
\log(\frac{p}{n - q}) &= (\beta_{0} + \beta_{0p} + \beta_{0i}) + ... \\
& (\beta_{1} + \beta_{1p})\times Cognate_{pi} + ... \\
& (\beta_{2} + \beta_{2i}) \times Exposure_{pi} + ... \\
& (\beta_{3} + \beta_{3i} + \beta_{3p}) \times (Cognate_{pi} \times Exposure_{pi}) + ... \\
& (\beta_{4} + \beta_{4i}) \times Age_{pi} + ... \\
& (\beta_{4} + \beta_{4p}) \times Frequency_{pi} + ... \\
& \varepsilon_{pi}
\end{aligned}
")

## R code (`brms`)

    understands ~
    1 + age + frequency + lp*cognate +
    (1 + age + lp | te) +
    (1 + frequency + cognate | id),
    family =  bernoulli("logit")

## Stan code

Stan code generated by `brms::stancode`:

## 

# Results

## Vocabulary

### Vocabulary size

#### Comprehension

#### Production

#### 

### Short vs. Long

#### Comprehension

#### Production

#### 

### 

## Raw data

## Prior-predictive checks

## Model selection

We compared the performance of these models using Bayesian leave-one-out
cross-validation (LOO) using the `loo` and `loo_compare` functions of
the `brms` R package (dependent of the `LOO` R package). LOO consists in
computing the average likelihood of each observation after estimating
the model’s parameters leave that same observation out of the data set.
Although the `loo` function uses a particular algorithm that speeds up
the computation of this criterion (pareto-smooth importance sampling,
PSIS), the size of our data set lead us to rely on the computation of
the same criterion using a sampling approach via de `loo_subsample`
function.

## Fixed effects

<br>

## Random effects

### Participant

### Item

### 

## Marginal means

### Area under the curve (AUC)

### Traceplots

## 
