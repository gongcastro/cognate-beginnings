---
title: "Appendix"
output:
  word_document:
    reference_docx: trajectories_template.docx
  pdf_document:
      latex_engine: xelatex
bibliography: trajectories.bib
csl: apa6.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Appendix: Model

The likelihood of our extended model can be formalised as follows:


$$
\begin{aligned}
y_{ip} &\sim Bernoulli(\mu_{ip}) \\
\mu_{ip} &= (\beta_{0} + \beta_{0p} + \beta_{0i}) +(\beta_{1} + \beta_{1i}) \times Age_{pi} + (\beta_{2} + \beta_{2p}) \times Frequency_{pi} + ... \\
&  (\beta_{3} + \beta_{3p})\times Cognate_{pi} + (\beta_{4} + \beta_{4i}) \times DoE_{pi} + ... \\
& (\beta_{5} + \beta_{5i} + \beta_{5p}) \times (Cognate_{pi} \times DoE_{pi}) + \varepsilon_{pi}
\end{aligned}
$$

Where:

* $y_i$ is the probability of participant $p$ to understand translation equivalent $i$
* $n_i$ is the total number of responses for translation equivalent $i$
* $\beta_0$ is the intercept, which corresponds to the probability of a positive response when all predictors equal 0
* $\beta_{1, \dots, 9}$ are the coefficients of the predictors


$$
\begin{aligned}
\beta_0 &\sim Normal(0.5, 0.1) \\
\beta_1 &\sim Normal(0.75, 0.1) \\
\beta_{2-9} &\sim Normal(0, 0.1) \\
\sigma_{0-9i} &\sim HalfNormal(0.2, \Sigma_{i}) \\

\Sigma_i & =
\begin{pmatrix} 
\sigma_0i^2 & \dots & \rho_i \sigma_{0-9i} \\
\vdots & \ddots & \vdots \\
\rho_i \sigma_{0-9i} & \dots &\sigma_9i^2 \\
\end{pmatrix}\\

\Sigma_i & =
\begin{pmatrix} 
\sigma_0i^2 & \dots & \rho_i \sigma_{0-9i} \\
\vdots & \ddots & \vdots \\
\rho_i \sigma_{0-9i} & \dots &\sigma_9i^2 \\
\end{pmatrix}\\

\end{aligned}
$$

## Appendix: Stan code

Stan code generated by `brms::stancode`:

```{stan stan_model, echo=FALSE, output.var="model"}
// generated with brms 2.15.0
functions {
/* compute correlated group-level effects
* Args: 
*   z: matrix of unscaled group-level effects
*   SD: vector of standard deviation parameters
*   L: cholesky factor correlation matrix
* Returns: 
*   matrix of scaled group-level effects
*/ 
matrix scale_r_cor(matrix z, vector SD, matrix L) {
// r is stored in another dimension order than z
return transpose(diag_pre_multiply(SD, L) * z);
}
}
data {
int<lower=1> N;  // total number of observations
int Y[N];  // response variable
int<lower=1> K;  // number of population-level effects
matrix[N, K] X;  // population-level design matrix
// data for group-level effects of ID 1
int<lower=1> N_1;  // number of grouping levels
int<lower=1> M_1;  // number of coefficients per level
int<lower=1> J_1[N];  // grouping indicator per observation
// group-level predictor values
vector[N] Z_1_1;
vector[N] Z_1_2;
vector[N] Z_1_3;
int<lower=1> NC_1;  // number of group-level correlations
// data for group-level effects of ID 2
int<lower=1> N_2;  // number of grouping levels
int<lower=1> M_2;  // number of coefficients per level
int<lower=1> J_2[N];  // grouping indicator per observation
// group-level predictor values
vector[N] Z_2_1;
vector[N] Z_2_2;
vector[N] Z_2_3;
int<lower=1> NC_2;  // number of group-level correlations
int prior_only;  // should the likelihood be ignored?
}
transformed data {
int Kc = K - 1;
matrix[N, Kc] Xc;  // centered version of X without an intercept
vector[Kc] means_X;  // column means of X before centering
for (i in 2:K) {
means_X[i - 1] = mean(X[, i]);
Xc[, i - 1] = X[, i] - means_X[i - 1];
}
}
parameters {
vector[Kc] b;  // population-level effects
real Intercept;  // temporary intercept for centered predictors
matrix[M_1, N_1] z_1;  // standardized group-level effects
cholesky_factor_corr[M_1] L_1;  // cholesky factor of correlation matrix
vector<lower=0>[M_2] sd_2;  // group-level standard deviations
matrix[M_2, N_2] z_2;  // standardized group-level effects
cholesky_factor_corr[M_2] L_2;  // cholesky factor of correlation matrix
}
transformed parameters {
vector<lower=0>[M_1] sd_1;  // group-level standard deviations
matrix[N_1, M_1] r_1;  // actual group-level effects
// using vectors speeds up indexing in loops
vector[N_1] r_1_1;
vector[N_1] r_1_2;
vector[N_1] r_1_3;
matrix[N_2, M_2] r_2;  // actual group-level effects
// using vectors speeds up indexing in loops
vector[N_2] r_2_1;
vector[N_2] r_2_2;
vector[N_2] r_2_3;
sd_1 = rep_vector(1, rows(sd_1));
// compute actual group-level effects
r_1 = scale_r_cor(z_1, sd_1, L_1);
r_1_1 = r_1[, 1];
r_1_2 = r_1[, 2];
r_1_3 = r_1[, 3];
// compute actual group-level effects
r_2 = scale_r_cor(z_2, sd_2, L_2);
r_2_1 = r_2[, 1];
r_2_2 = r_2[, 2];
r_2_3 = r_2[, 3];
}
model {
// likelihood including constants
if (!prior_only) {
// initialize linear predictor term
vector[N] mu = Intercept + rep_vector(0.0, N);
for (n in 1:N) {
// add more terms to the linear predictor
mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_1_2[J_1[n]] * Z_1_2[n] + r_1_3[J_1[n]] * Z_1_3[n] + r_2_1[J_2[n]] * Z_2_1[n] + r_2_2[J_2[n]] * Z_2_2[n] + r_2_3[J_2[n]] * Z_2_3[n];
}
target += bernoulli_logit_glm_lpmf(Y | Xc, mu, b);
}
// priors including constants
target += normal_lpdf(b | 0, 3);
target += normal_lpdf(Intercept | 0, 3);
target += std_normal_lpdf(to_vector(z_1));
target += lkj_corr_cholesky_lpdf(L_1 | 5);
target += normal_lpdf(sd_2 | 0, 0.5)
- 3 * normal_lccdf(0 | 0, 0.5);
target += std_normal_lpdf(to_vector(z_2));
target += lkj_corr_cholesky_lpdf(L_2 | 5);
}
generated quantities {
// actual population-level intercept
real b_Intercept = Intercept - dot_product(means_X, b);
// compute group-level correlations
corr_matrix[M_1] Cor_1 = multiply_lower_tri_self_transpose(L_1);
vector<lower=-1,upper=1>[NC_1] cor_1;
// compute group-level correlations
corr_matrix[M_2] Cor_2 = multiply_lower_tri_self_transpose(L_2);
vector<lower=-1,upper=1>[NC_2] cor_2;
// extract upper diagonal of correlation matrix
for (k in 1:M_1) {
for (j in 1:(k - 1)) {
cor_1[choose(k - 1, 2) + j] = Cor_1[j, k];
}
}
// extract upper diagonal of correlation matrix
for (k in 1:M_2) {
for (j in 1:(k - 1)) {
cor_2[choose(k - 1, 2) + j] = Cor_2[j, k];
}
}
}
```