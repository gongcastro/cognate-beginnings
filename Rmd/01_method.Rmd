---
title: "Method"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r prepare, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

library(tidyverse)
library(papaja)
library(gt)
library(knitr)
library(here)

participants <- read.csv(here("Data", "participants.csv"))
items <- read.csv(here("Data", "items.csv"))
vocabulary <- read.csv(here("Data", "vocabulary.csv"))
responses <- read.csv(here("Data", "responses.csv"))

```

# Method


## Participants

```{r participants}
n_participants <- length(unique(participants$id))
dates <- range(participants$time_stamp, na.rm = TRUE)
sex <- participants %>% drop_na(sex) %>% count(sex) %>% pull(n) %>% set_names(c("female", "male"))

```

We collected data from `r printnum(n_participants)` bilinguals (`r sex[1]` female), from the Metropolitan Area of Barcelona, between `r format(dates[1], "%dth %B, %Y")` and `r format(dates[2], "%dth %B, %Y")`. All families gave informed consent before participating. This study was approved by the Comitè d'Ètica de la Investigació amb Medicaments (CEIm) from Hospital del Mar (Barcelona, Spain), code XXXXXXXXX.


We assessed toddlers' language profile asking parents for an estimated proportion of exposure to each language. We excluded participants with >10% exposure to a third language. Fig. \@ref(tab:lps) illustrates the distribution of participants across language profiles and ages.


```{r lps, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

participants %>%
  mutate(age = cut_width(age, width = 4, boundary = 0),
         doe = round(doe, 1)) %>%
  count(age, doe) %>% 
  mutate(doe = scales::percent(doe)) %>% 
  pivot_wider(names_from = doe, values_from = n) %>% 
  gt() %>% 
  tab_spanner(columns = 2:7, label = md("**Exposure to L2**")) %>% 
  fmt_missing(columns = everything(), missing_text = 0) %>% 
  cols_label(age = md("**Age (months)**"))

```


## Questionnaire

```{r items}
pool <- pool %>% 
  drop_na(cognate)
n_categories <- distinct(pool, category) %>% nrow()
n_items <- length(unique(pool$item))
n_item_language <- count(pool, language) %>% pull(n) %>% set_names(c("catalan", "spanish"))
n_item_cognate <- count(pool, language, cognate) %>% 
  pull(n) %>% 
  set_names(c("catalan-cognate", "catalan-noncognate", "spanish-cognate", "spanish-noncognate"))

```

We implemented an on-line questionnaire using `formr` [@arslan2020], divided in three forms: a (1) language questionnaire, a (2) demographic survey, and a (3) Catalan and a Spanish vocabulary checklists. Vocabulary checklists followed a similar structure as the Oxford Communicative Developmental Inventory [@hamilton2000] and consisted in two lists of words, one in Catalan and one in Spanish). Items in one language were translation equivalents of the items in the other (e.g., whenever *gos* [dog] was included in the Catalan inventory, the word *perro* was included in the Spanish inventory), roughly following a one-to-one mapping. When there were two acceptable translation equivalents for a given word, we included both (e.g., Catalan *acabar* [*to finish*] and Spanish *acabar* and *terminar*), or merged them into the same one (e.g., Spanish *mono* [*monkey*] and Catalan *mono/mico*). We included items from a diverse sample of `r n_categories` semantic/functional categorie (see Appendix 1). We discarded the following categories: adverbs, auxiliary words, connectives, interjections and games and routines. The Catalan inventory contained `r n_item_language["catalan"]` items (`r n_item_cognate["catalan-cognate"]` cognates, `r n_item_cognate["catalan-noncognate"]` non-cognates) and the Spanish inventory contained `r n_item_language["spanish"]` (`r n_item_cognate["spanish-cognate"]` cognates, `r n_item_cognate["spanish-noncognate"]` non-cognates).


For each word in the vocabulary checklists, we asked parents to report whether their child was able to understand it, understand and say it, or did not understand or say it (marked by default). Participants filled a long or a short version of the questionnaire. Participants presented with the long version filled a list of 800 translation equivalents (800 items in Catalan and 800 items in Spanish), while participants presented with a short were randomly allocated into one of four list of items. Each list contained a different set of ~400 translation equivalents (~400 in Catalan, ~400 in Spanish). Semantic/functional categories with less than 16 items--thus resulting in less than four items after dividing it in four lists - were not divided in the short version of the questionnaire: all of their items were included in the four lists. Another subset of items that were part of the trial lists of some experiments in the lab were also included in all versions. Table 2 in Appendix 1 shows the distribution of items accross questionnaire versions.



## Data analysis

```{r n_responses}
n_obs <- nrow(responses)
sum_obs <- responses %>%
  group_by(te) %>%
  summarise(n = n(), .groups = "drop") %>%
  summarise(
    mean = mean(n),
    sd = sd(n),
    min = min(n),
    max = max(n)
  )

```

We gathered `r printnum(n_obs, big.mark = ",")` responses. Translation equivalents received an average of `r printnum(sum_obs$mean, digits = 2)` (*SD* = `r printnum(sum_obs$sd, digits = 2)`, `r Min = printnum(sum_obs$min, digits = 2)`, Max = `r printnum(sum_obs$max, digits = 2)`), both languages summed together. We modelled the probability of participants' being reported to understand/produce a translation equivalent adjusting by:

* $Age$ (in months), calculated as the number of days passed from birth date to the day the questionnaire was completed, divided by 30.
* $Exposure$: composite score of the lexical frequency of the word form in Catalan or Spanish, as extracted from SUBTLEX-ESP [@cuetos2011] or SUBTLEX-CAT [@]

We modelled comprehensive and productive data separately, following a similar procedure. First, we fit a base logistic regression model with a Bernoulli distribution that adjusted by the age of participants. Then we extended this model including the main effect of exposure
To address our hypothesis, we modelled the probability of parents reporting that their child understood and/or produced translation equivalents, conditional to how much the child is exposed to it, and to the phonological similarity between both translation equivalents.
We excluded from the analysis multi-word items (e.g., *barrita de cereales* [cereal bar]) and items that included more than one word-form (e.g., *mono / mico*).

Table \@ref(tab:itemsinfo) shows the classification of items in cognates and non-cognates and their frequency scores across the four lists of the inventories.


```{r itemsinfo, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

pool %>%
  filter(include) %>%
  select(version, cognate, frequency = frequency_zipf, language) %>% 
  mutate(cognate = ifelse(cognate, "Cognate", "Non-cognate")) %>%
  group_by(version, language, cognate) %>% 
  summarise(
    n = sum(n, na.rm = TRUE),
    mean = mean(frequency, na.rm = TRUE),
    sd = sd(frequency, na.rm = TRUE),
    min = min(frequency, na.rm = TRUE),
    max = max(frequency, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  ungroup() %>% 
  relocate(version, language, cognate, n, mean, sd, min, max) %>%
  arrange(version, language, cognate) %>%
  mutate(version = collapse(version, ",")) %>% 
  pivot_wider(names_from = cognate, values_from = c(n, mean, sd, min, max)) %>%
  clean_names() %>%
  gt(groupname_col = c("language")) %>% 
  fmt_number(columns = contains("cognate"), decimals = 2) %>%
  fmt_number(columns = starts_with("n_"), decimals = 0) %>%
  tab_header(title = md("**Questionnaire and item properties**"),
             subtitle = "Participants were randomly allocated on of the the four lists, and completed both the Catalan and the Spanish versions.") %>% 
  tab_spanner(label = "Frequency (Cognates)", columns = vars("n_cognate", "mean_cognate", "sd_cognate", "min_cognate", "max_cognate")) %>% 
  tab_spanner(label = "Frequency (Non-cognates)", columns = contains("non_cognate")) %>% 
  cols_label(list = md("**List**"), 
             n_cognate = md("*N*"),
             mean_cognate = md("*Mean*"),
             sd_cognate = md("*SD*"),
             min_cognate = md("*Min*"),
             max_cognate = md("*Max*"),
             n_non_cognate = md("*N*"),
             mean_non_cognate = md("*Mean*"),
             sd_non_cognate = md("*SD*"),
             min_non_cognate = md("*Min*"),
             max_non_cognate = md("*Max*")) 

```


We fit two separate logistic models on comprehensive and productive data, respectively. Logistic curves are characterised by three parameters[see @mahr2019 and @mahr2020 for an excellent introduction to this approach, in which we based this analysis]: (a) an *asymptote* (`asym`, upper boundary  of the proportion of infants that have acquired the item), (b) the *steepness* (`steep`, how fast the a given item is acquired by infants), and (c) a *mid-point* (`mid`, the age at which steepness is maximum). We work on the assumption that the trajectory of acquisition of items follows a logistic curve shape [@mayor2011], and that the age of acquisition of a word is fairly captured by the position of the mid-point of its curve. This approach allows us to model and estimate the age of acquisition of items explicitly. Our model estimated the asymptote and steepness as grand means across items (i.e., intercepts). Mid-points were estimated by a linear regression model that included our predictors of interest: `age`, `item_dominance` (sum-coded, L2 = -0.5, L1 = 0.5), `cognateness` (sum-coded, Non-cognate = -0.5, Cognate = 0.5). We also included random intercepts and `item dominance` slopes for each translation equivalent (`te`) [@barr2013]. Appendix 1 shows a detailed description of the model.


We estimated the parameters of our model using the Bayesian framework. Bayesian models use the Bayes rule to combine prior knowledge about the distribution of a given parameter, and the likelihood of each of the values it can take given the data. We relied on the available data on Wordbank [@frank2017] to generate our prior (see Appendix 1 for more details about our prior). In order to test the contribution of each predictor on the fit of the model, we started fitting a null model that only included an global intercept and random intercepts for each TE, then fitted a model that also included *bilingualism* and its random slopes by TE, and finally a model that also included *cognateness* and its interaction with *bilingualism*, as well as random slopes for all the fixed effects. We compared how the fit of the model changed in every step [@schad2020] using leave-one-out cross validation. We fit both the null and alternative models using the R environment [@rcoreteam2013; @rstudioteam2015] and the `brms` package [@burkner2017], which relies on the probabilistic language Stan [@carpenter2017] to approximate posterior distributions. We used Pareto-smoothed importance sampling [PSIS; @vehtari2017; @vehtari2019] to compare the null and extended models. Data and model results were processed and visualised using the `tidyverse` family of R packages [@wickham2019] and the `tidybayes` package [@kay2020].


To test Hypothesis 2, we run a Bayesian ANOVA using the difference in mid-points between the two word-forms of each translation equivalent (in Catalan and Spanish, respectively), that included *cognateness* as predictor. Using the `BayesFactor` R package [@morey2018a], we computed a Bayes factor (*BF*) that compared the likelihood of a linear model that included *cognateness* as a predictor against the likelihood of a linear model that did not, under the light of our data.
